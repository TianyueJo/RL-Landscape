==========================================
[Jump & Retrain] Walker2d task 6 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 10:54:03 EST 2025
èŠ‚ç‚¹: node7
==========================================
[Base] task=6, env=Walker2d-v4, best_model=final_model.pt, best_reward=1614.88, train_seed=206
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_6/vec_stats.npz
[J&R] base_task=6, new_task=6_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_6/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 0.8%  DRAM: 0.5%   VRAM: 1.2%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.200  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.659  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.032  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.025  â”‚
â”‚  Uptime             11s      Forwaâ€¦      0s   0%    clipfrac          0.248  â”‚
â”‚  Remainiâ€¦        2m 46s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.377  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.978    episode_length               57.950  â”‚
â”‚  x_position                   -7.186    x_velocity                  -59.626  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=11.90 (best=N/A)
æ­¥æ•° 32,768: Reward=11.90, Best=-1.98@32768, Sharpness=1.2656, Î»_max=-36.7686
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.6%  DRAM: 0.6%   VRAM: 1.5%  â”‚
â”‚                                 18.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.606  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.698  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                2    Train         1s  23%    approx_kl         0.019  â”‚
â”‚  Uptime             26s      Forwaâ€¦      0s   4%    clipfrac          0.196  â”‚
â”‚  Remainiâ€¦        3m 13s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.743    episode_length               91.456  â”‚
â”‚  x_position                  -11.426    x_velocity                  -66.226  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-15.97 (best=-1.98@32768)
æ­¥æ•° 65,536: Reward=-15.97, Best=24.74@65536, Sharpness=1.2687, Î»_max=-41.8094
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.2%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 18.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.416  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.724  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                3    Train         1s  23%    approx_kl         0.015  â”‚
â”‚  Uptime             41s      Forwaâ€¦      0s   4%    clipfrac          0.169  â”‚
â”‚  Remainiâ€¦         3m 4s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.866  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               59.789    episode_length              136.314  â”‚
â”‚  x_position                  -17.577    x_velocity                  -75.796  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-5.78 (best=24.74@65536)
æ­¥æ•° 98,304: Reward=-5.78, Best=59.79@98304, Sharpness=1.2745, Î»_max=-43.0939
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 18.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.345  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.749  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         1s  23%    approx_kl         0.012  â”‚
â”‚  Uptime             56s      Forwaâ€¦      0s   4%    clipfrac          0.140  â”‚
â”‚  Remainiâ€¦        2m 45s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               54.002    episode_length              142.773  â”‚
â”‚  x_position                  -23.186    x_velocity                  -88.010  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-6.55 (best=59.79@98304)
æ­¥æ•° 131,072: Reward=-6.55, Best=59.79@98304, Sharpness=1.2630, Î»_max=-39.0720
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.4%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.285  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.771  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                5    Train         1s  23%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 9s      Forwaâ€¦      0s   4%    clipfrac          0.110  â”‚
â”‚  Remainiâ€¦        2m 19s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               66.574    episode_length              163.785  â”‚
â”‚  x_position                  -28.396    x_velocity                  -96.339  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-7.50 (best=59.79@98304)
æ­¥æ•° 163,840: Reward=-7.50, Best=66.57@163840, Sharpness=1.2651, Î»_max=-41.0254
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.8%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         9s  67%    value_loss        0.237  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.795  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         2s  23%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 22s      Forwaâ€¦      0s   4%    clipfrac          0.121  â”‚
â”‚  Remainiâ€¦         2m 0s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.885  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               81.458    episode_length              178.298  â”‚
â”‚  x_position                  -29.127    x_velocity                  -95.888  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-5.57 (best=66.57@163840)
æ­¥æ•° 196,608: Reward=-5.57, Best=81.46@196608, Sharpness=1.2727, Î»_max=-36.8448
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.7%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.207  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.812  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  15%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 39s      Forwaâ€¦      0s   3%    clipfrac          0.091  â”‚
â”‚  Remainiâ€¦        2m 14s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.880  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              123.726    episode_length              226.784  â”‚
â”‚  x_position                  -38.460    x_velocity                 -101.846  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-5.48 (best=81.46@196608)
æ­¥æ•° 229,376: Reward=-5.48, Best=123.73@229376, Sharpness=1.2586, Î»_max=-36.8183
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.3%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.172  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.824  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         2s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 54s      Forwaâ€¦      0s   3%    clipfrac          0.085  â”‚
â”‚  Remainiâ€¦        1m 52s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.884  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              126.135    episode_length              230.981  â”‚
â”‚  x_position                  -35.323    x_velocity                 -103.613  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-6.69 (best=123.73@229376)
æ­¥æ•° 262,144: Reward=-6.69, Best=126.14@262144, Sharpness=1.2851, Î»_max=-48.3114
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.4%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.161  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.831  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 12s      Forwaâ€¦      0s   3%    clipfrac          0.077  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       1s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.883  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              130.783    episode_length              238.375  â”‚
â”‚  x_position                  -42.162    x_velocity                 -106.321  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-6.96 (best=126.14@262144)
æ­¥æ•° 294,912: Reward=-6.96, Best=130.78@294912, Sharpness=1.3101, Î»_max=-34.1255
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.149  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.839  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         2s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   3%    clipfrac          0.058  â”‚
â”‚  Remainiâ€¦        1m 27s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              141.554    episode_length              255.072  â”‚
â”‚  x_position                  -50.987    x_velocity                 -112.149  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-15.63 (best=130.78@294912)
æ­¥æ•° 327,680: Reward=-15.63, Best=141.55@327680, Sharpness=1.3314, Î»_max=-33.4813
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env        15s  76%    value_loss        0.144  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.847  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         3s  15%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 45s      Forwaâ€¦      0s   3%    clipfrac          0.047  â”‚
â”‚  Remainiâ€¦         1m 7s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.898  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              194.350    episode_length              303.273  â”‚
â”‚  x_position                  -50.988    x_velocity                 -107.303  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-7.57 (best=141.55@327680)
æ­¥æ•° 360,448: Reward=-7.57, Best=194.35@360448, Sharpness=1.3684, Î»_max=-30.9690
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.145  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.854  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  15%    approx_kl         0.003  â”‚
â”‚  Uptime           3m 2s      Forwaâ€¦      0s   3%    clipfrac          0.028  â”‚
â”‚  Remainiâ€¦           55s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.889  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              160.768    episode_length              259.362  â”‚
â”‚  x_position                  -36.016    x_velocity                  -97.202  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-5.28 (best=194.35@360448)
æ­¥æ•° 393,216: Reward=-5.28, Best=194.35@360448, Sharpness=1.2462, Î»_max=-33.9520
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.8%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.147  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.860  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         3s  15%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 18s      Forwaâ€¦      0s   3%    clipfrac          0.019  â”‚
â”‚  Remainiâ€¦           35s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              199.635    episode_length              315.674  â”‚
â”‚  x_position                  -61.721    x_velocity                 -114.347  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-5.60 (best=194.35@360448)
æ­¥æ•° 425,984: Reward=-5.60, Best=199.63@425984, Sharpness=1.2884, Î»_max=-43.8658
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.5%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 18.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.145  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.863  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         3s  15%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 33s      Forwaâ€¦      0s   3%    clipfrac          0.012  â”‚
â”‚  Remainiâ€¦           19s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              186.132    episode_length              296.646  â”‚
â”‚  x_position                  -49.109    x_velocity                 -108.928  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-7.76 (best=199.63@425984)
æ­¥æ•° 458,752: Reward=-7.76, Best=199.63@425984, Sharpness=1.2844, Î»_max=-40.5690
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 19.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.164  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.864  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 47s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.842  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              185.646    episode_length              285.828  â”‚
â”‚  x_position                  -29.021    x_velocity                  -98.651  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-7.77 (best=199.63@425984)
æ­¥æ•° 491,520: Reward=-7.77, Best=199.63@425984, Sharpness=1.3399, Î»_max=-20.5679
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     23s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env        21s  77%    value_loss        0.181  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.864  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         4s  15%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 3s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.828  â”‚
â”‚                              Misc        1s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              226.584    episode_length              329.289  â”‚
â”‚  x_position                  -60.533    x_velocity                 -100.940  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-14.70 (best=199.63@425984)
æ­¥æ•° 524,288: Reward=-14.70, Best=226.58@524288, Sharpness=1.3225, Î»_max=-36.5539

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 6_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_6/vec_stats.npz
[J&R] base_task=6, new_task=6_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_6/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.3%  DRAM: 0.5%   VRAM: 1.4%  â”‚
â”‚                                 20.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         6s   0%    value_loss        1.147  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.563  â”‚
â”‚  SPS               4.0K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              8s      Forwaâ€¦      0s   0%    clipfrac          0.258  â”‚
â”‚  Remainiâ€¦        1m 55s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.415  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.219    episode_length               55.579  â”‚
â”‚  x_position                   -8.014    x_velocity                  -66.510  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=33.18 (best=N/A)
æ­¥æ•° 32,768: Reward=33.18, Best=-11.22@32768, Sharpness=1.2697, Î»_max=-48.5275
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.5%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  83%    value_loss        0.628  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.593  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                2    Train         0s   8%    approx_kl         0.020  â”‚
â”‚  Uptime             26s      Forwaâ€¦      0s   1%    clipfrac          0.211  â”‚
â”‚  Remainiâ€¦         4m 6s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.844  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               19.997    episode_length               91.375  â”‚
â”‚  x_position                  -12.614    x_velocity                  -70.893  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-19.61 (best=-11.22@32768)
æ­¥æ•° 65,536: Reward=-19.61, Best=20.00@65536, Sharpness=1.2664, Î»_max=-46.7997
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         6s  83%    value_loss        0.399  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.614  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         0s   8%    approx_kl         0.013  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   1%    clipfrac          0.156  â”‚
â”‚  Remainiâ€¦        3m 25s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.878  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               43.376    episode_length              138.094  â”‚
â”‚  x_position                  -24.982    x_velocity                  -93.985  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-3.67 (best=20.00@65536)
æ­¥æ•° 98,304: Reward=-3.67, Best=43.38@98304, Sharpness=1.2889, Î»_max=-52.9831
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         6s  83%    value_loss        0.357  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.629  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                4    Train         0s   8%    approx_kl         0.011  â”‚
â”‚  Uptime             59s      Forwaâ€¦      0s   1%    clipfrac          0.136  â”‚
â”‚  Remainiâ€¦        2m 55s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.892  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               40.365    episode_length              141.701  â”‚
â”‚  x_position                  -28.691    x_velocity                 -100.584  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-8.73 (best=43.38@98304)
æ­¥æ•° 131,072: Reward=-8.73, Best=43.38@98304, Sharpness=1.2977, Î»_max=-29.1750
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.6%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env         6s  83%    value_loss        0.308  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.645  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                5    Train         0s   8%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 16s      Forwaâ€¦      0s   1%    clipfrac          0.130  â”‚
â”‚  Remainiâ€¦        2m 51s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.889  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               65.428    episode_length              162.080  â”‚
â”‚  x_position                  -27.830    x_velocity                  -95.787  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-9.91 (best=43.38@98304)
æ­¥æ•° 163,840: Reward=-9.91, Best=65.43@163840, Sharpness=1.2962, Î»_max=-37.1775
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 17.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env        12s  83%    value_loss        0.239  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.660  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         1s   8%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 32s      Forwaâ€¦      0s   1%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦        2m 29s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.899  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               80.463    episode_length              193.563  â”‚
â”‚  x_position                  -40.485    x_velocity                 -112.069  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-5.28 (best=65.43@163840)
æ­¥æ•° 196,608: Reward=-5.28, Best=80.46@196608, Sharpness=1.2985, Î»_max=-39.3709
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 18.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env        12s  85%    value_loss        0.204  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.679  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         1s   6%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 49s      Forwaâ€¦      0s   1%    clipfrac          0.103  â”‚
â”‚  Remainiâ€¦        2m 18s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               92.144    episode_length              204.057  â”‚
â”‚  x_position                  -42.764    x_velocity                 -110.824  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-10.01 (best=80.46@196608)
æ­¥æ•° 229,376: Reward=-10.01, Best=92.14@229376, Sharpness=1.2964, Î»_max=-43.9959
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.6%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env        12s  85%    value_loss        0.176  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.697  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s   6%    approx_kl         0.007  â”‚
â”‚  Uptime           2m 6s      Forwaâ€¦      0s   1%    clipfrac          0.083  â”‚
â”‚  Remainiâ€¦         2m 9s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              120.666    episode_length              228.500  â”‚
â”‚  x_position                  -37.077    x_velocity                 -106.613  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-9.90 (best=92.14@229376)
æ­¥æ•° 262,144: Reward=-9.90, Best=120.67@262144, Sharpness=1.2859, Î»_max=-34.6490
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env        12s  85%    value_loss        0.158  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.716  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s   6%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 23s      Forwaâ€¦      0s   1%    clipfrac          0.081  â”‚
â”‚  Remainiâ€¦        1m 43s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              102.856    episode_length              217.645  â”‚
â”‚  x_position                  -46.392    x_velocity                 -113.629  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-6.86 (best=120.67@262144)
æ­¥æ•° 294,912: Reward=-6.86, Best=120.67@262144, Sharpness=1.2656, Î»_max=-36.8526
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.8%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env        12s  85%    value_loss        0.172  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.731  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s   6%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 42s      Forwaâ€¦      0s   1%    clipfrac          0.061  â”‚
â”‚  Remainiâ€¦        1m 38s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              127.680    episode_length              257.565  â”‚
â”‚  x_position                  -68.322    x_velocity                 -128.514  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-15.56 (best=120.67@262144)
æ­¥æ•° 327,680: Reward=-15.56, Best=127.68@327680, Sharpness=1.2710, Î»_max=-40.0910
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.7%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     21s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env        19s  85%    value_loss        0.141  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.738  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               11    Train         2s   6%    approx_kl         0.004  â”‚
â”‚  Uptime           3m 1s      Forwaâ€¦      0s   1%    clipfrac          0.044  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       1s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              163.237    episode_length              282.078  â”‚
â”‚  x_position                  -55.642    x_velocity                 -117.330  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-13.98 (best=127.68@327680)
æ­¥æ•° 360,448: Reward=-13.98, Best=163.24@360448, Sharpness=1.3028, Î»_max=-47.7501
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     21s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env        19s  77%    value_loss        0.152  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.744  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         2s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          3m 19s      Forwaâ€¦      0s   2%    clipfrac          0.046  â”‚
â”‚  Remainiâ€¦           59s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              168.556    episode_length              285.467  â”‚
â”‚  x_position                  -61.500    x_velocity                 -115.380  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-4.67 (best=163.24@360448)
æ­¥æ•° 393,216: Reward=-4.67, Best=168.56@393216, Sharpness=1.3029, Î»_max=-10.9146
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     21s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        19s  77%    value_loss        0.147  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.749  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 36s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           38s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.878  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              192.022    episode_length              315.110  â”‚
â”‚  x_position                  -68.093    x_velocity                 -121.403  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-8.44 (best=168.56@393216)
æ­¥æ•° 425,984: Reward=-8.44, Best=192.02@425984, Sharpness=1.3201, Î»_max=-41.5953
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.5%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 17.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     21s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env        19s  77%    value_loss        0.157  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.753  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 52s      Forwaâ€¦      0s   2%    clipfrac          0.014  â”‚
â”‚  Remainiâ€¦           19s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.864  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              185.543    episode_length              297.122  â”‚
â”‚  x_position                  -49.505    x_velocity                 -109.986  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-5.53 (best=192.02@425984)
æ­¥æ•° 458,752: Reward=-5.53, Best=192.02@425984, Sharpness=1.3134, Î»_max=-35.1014
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     21s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env        19s  77%    value_loss        0.163  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.754  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 9s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.830  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              170.620    episode_length              293.808  â”‚
â”‚  x_position                  -80.407    x_velocity                 -121.611  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-6.59 (best=192.02@425984)
æ­¥æ•° 491,520: Reward=-6.59, Best=192.02@425984, Sharpness=1.2999, Î»_max=-41.8041
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.3%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     26s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        23s  77%    value_loss        0.162  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.754  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 25s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.835  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              208.561    episode_length              331.284  â”‚
â”‚  x_position                  -78.938    x_velocity                 -120.945  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-11.93 (best=192.02@425984)
æ­¥æ•° 524,288: Reward=-11.93, Best=208.56@524288, Sharpness=1.2782, Î»_max=-32.6611

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 6_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_6/vec_stats.npz
[J&R] base_task=6, new_task=6_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_6/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 1.7%  DRAM: 0.5%   VRAM: 1.5%  â”‚
â”‚                                 25.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         6s   0%    value_loss        1.160  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.272  â”‚
â”‚  SPS               4.2K      Misc        0s   0%    old_approx_kl     0.036  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.027  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.270  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       0s   0%    importance        0.991  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.458  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.386    episode_length               55.355  â”‚
â”‚  x_position                   -6.739    x_velocity                  -58.454  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=12.63 (best=N/A)
æ­¥æ•° 32,768: Reward=12.63, Best=-3.39@32768, Sharpness=1.3753, Î»_max=-72.5737
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.4%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.588  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.295  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.023  â”‚
â”‚  Epoch                2    Train         1s  13%    approx_kl         0.020  â”‚
â”‚  Uptime             26s      Forwaâ€¦      0s   2%    clipfrac          0.199  â”‚
â”‚  Remainiâ€¦         4m 3s      Learn       0s   7%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.835  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               20.687    episode_length               87.148  â”‚
â”‚  x_position                  -11.143    x_velocity                  -66.000  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-17.41 (best=-3.39@32768)
æ­¥æ•° 65,536: Reward=-17.41, Best=20.69@65536, Sharpness=1.3598, Î»_max=-76.6480
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.6%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.421  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.315  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         1s  13%    approx_kl         0.016  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.178  â”‚
â”‚  Remainiâ€¦        3m 32s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.877  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               41.255    episode_length              128.673  â”‚
â”‚  x_position                  -21.141    x_velocity                  -86.738  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-8.35 (best=20.69@65536)
æ­¥æ•° 98,304: Reward=-8.35, Best=41.25@98304, Sharpness=1.3671, Î»_max=-79.2172
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.349  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.335  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         1s  13%    approx_kl         0.013  â”‚
â”‚  Uptime           1m 0s      Forwaâ€¦      0s   2%    clipfrac          0.153  â”‚
â”‚  Remainiâ€¦        3m 11s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.898  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               34.210    episode_length              136.914  â”‚
â”‚  x_position                  -29.796    x_velocity                 -101.981  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-7.25 (best=41.25@98304)
æ­¥æ•° 131,072: Reward=-7.25, Best=41.25@98304, Sharpness=1.3663, Î»_max=-80.0586
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.307  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.352  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  13%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 19s      Forwaâ€¦      0s   2%    clipfrac          0.136  â”‚
â”‚  Remainiâ€¦         3m 8s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               60.064    episode_length              160.811  â”‚
â”‚  x_position                  -30.412    x_velocity                  -99.892  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-10.23 (best=41.25@98304)
æ­¥æ•° 163,840: Reward=-10.23, Best=60.06@163840, Sharpness=1.3644, Î»_max=-86.2053
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.264  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.376  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         2s  13%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 37s      Forwaâ€¦      0s   2%    clipfrac          0.116  â”‚
â”‚  Remainiâ€¦        2m 54s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               68.662    episode_length              179.646  â”‚
â”‚  x_position                  -36.306    x_velocity                 -110.031  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-4.38 (best=60.06@163840)
æ­¥æ•° 196,608: Reward=-4.38, Best=68.66@196608, Sharpness=1.3734, Î»_max=-77.6799
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.219  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.395  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  13%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 55s      Forwaâ€¦      0s   3%    clipfrac          0.107  â”‚
â”‚  Remainiâ€¦        2m 26s      Learn       1s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               71.487    episode_length              181.873  â”‚
â”‚  x_position                  -37.108    x_velocity                 -109.421  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-6.04 (best=68.66@196608)
æ­¥æ•° 229,376: Reward=-6.04, Best=71.49@229376, Sharpness=1.3692, Î»_max=-64.7509
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.207  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.415  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         2s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 12s      Forwaâ€¦      0s   3%    clipfrac          0.086  â”‚
â”‚  Remainiâ€¦         2m 2s      Learn       1s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.887  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              102.949    episode_length              221.843  â”‚
â”‚  x_position                  -48.644    x_velocity                 -117.715  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-46.97 (best=71.49@229376)
æ­¥æ•° 262,144: Reward=-46.97, Best=102.95@262144, Sharpness=1.3903, Î»_max=-56.8867
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.185  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.433  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   3%    clipfrac          0.074  â”‚
â”‚  Remainiâ€¦        1m 45s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               94.247    episode_length              207.791  â”‚
â”‚  x_position                  -40.874    x_velocity                 -112.436  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-30.20 (best=102.95@262144)
æ­¥æ•° 294,912: Reward=-30.20, Best=102.95@262144, Sharpness=1.3768, Î»_max=-73.9116
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.6%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.170  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.443  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         2s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 44s      Forwaâ€¦      0s   3%    clipfrac          0.070  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.898  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               99.878    episode_length              220.633  â”‚
â”‚  x_position                  -53.188    x_velocity                 -119.581  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-44.45 (best=102.95@262144)
æ­¥æ•° 327,680: Reward=-44.45, Best=102.95@262144, Sharpness=1.3539, Î»_max=-75.7050
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env        17s  76%    value_loss        0.162  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.453  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         3s  13%    approx_kl         0.005  â”‚
â”‚  Uptime           3m 1s      Forwaâ€¦      0s   3%    clipfrac          0.056  â”‚
â”‚  Remainiâ€¦        1m 11s      Learn       1s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              128.780    episode_length              247.777  â”‚
â”‚  x_position                  -57.847    x_velocity                 -117.674  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-17.08 (best=102.95@262144)
æ­¥æ•° 360,448: Reward=-17.08, Best=128.78@360448, Sharpness=1.3992, Î»_max=-60.1591
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.7%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        17s  75%    value_loss        0.157  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.464  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         3s  16%    approx_kl         0.004  â”‚
â”‚  Uptime          3m 18s      Forwaâ€¦      0s   3%    clipfrac          0.039  â”‚
â”‚  Remainiâ€¦           55s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.890  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              160.457    episode_length              285.235  â”‚
â”‚  x_position                  -71.629    x_velocity                 -123.253  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-12.16 (best=128.78@360448)
æ­¥æ•° 393,216: Reward=-12.16, Best=160.46@393216, Sharpness=1.4385, Î»_max=-64.8863
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env        17s  75%    value_loss        0.160  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.469  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  16%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 35s      Forwaâ€¦      0s   3%    clipfrac          0.018  â”‚
â”‚  Remainiâ€¦           38s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.871  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              148.946    episode_length              273.256  â”‚
â”‚  x_position                  -58.147    x_velocity                 -122.856  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-5.02 (best=160.46@393216)
æ­¥æ•° 425,984: Reward=-5.02, Best=160.46@393216, Sharpness=1.4056, Î»_max=-60.1738
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.4%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env        17s  75%    value_loss        0.166  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.473  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         3s  16%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 51s      Forwaâ€¦      0s   3%    clipfrac          0.012  â”‚
â”‚  Remainiâ€¦           19s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.870  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              142.617    episode_length              266.675  â”‚
â”‚  x_position                  -69.350    x_velocity                 -122.633  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-5.61 (best=160.46@393216)
æ­¥æ•° 458,752: Reward=-5.61, Best=160.46@393216, Sharpness=1.3858, Î»_max=-62.6677
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.8%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env        17s  75%    value_loss        0.177  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.474  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  16%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 8s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.844  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              162.434    episode_length              285.039  â”‚
â”‚  x_position                  -62.788    x_velocity                 -121.084  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-4.47 (best=160.46@393216)
æ­¥æ•° 491,520: Reward=-4.47, Best=162.43@491520, Sharpness=1.4680, Î»_max=-35.7002
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.8%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     23s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env        21s  75%    value_loss        0.182  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.474  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         4s  16%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 23s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.828  â”‚
â”‚                              Misc        1s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              183.728    episode_length              311.400  â”‚
â”‚  x_position                  -87.598    x_velocity                 -126.003  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-42.45 (best=162.43@491520)
æ­¥æ•° 524,288: Reward=-42.45, Best=183.73@524288, Sharpness=1.3942, Î»_max=-62.6300

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 6_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_6/vec_stats.npz
[J&R] base_task=6, new_task=6_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_6/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.0%  DRAM: 0.5%   VRAM: 1.5%  â”‚
â”‚                                 24.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.522  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.370  â”‚
â”‚  SPS               4.4K      Misc        0s   0%    old_approx_kl     0.056  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.046  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.379  â”‚
â”‚  Remainiâ€¦        1m 45s      Learn       0s   0%    importance        0.990  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.415  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.998    episode_length               45.469  â”‚
â”‚  x_position                   -5.652    x_velocity                  -54.235  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-49.37 (best=N/A)
æ­¥æ•° 32,768: Reward=-49.37, Best=-9.00@32768, Sharpness=1.9265, Î»_max=-132.8123
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 18.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.643  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.403  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.036  â”‚
â”‚  Epoch                2    Train         1s  14%    approx_kl         0.033  â”‚
â”‚  Uptime             20s      Forwaâ€¦      0s   2%    clipfrac          0.286  â”‚
â”‚  Remainiâ€¦        2m 49s      Learn       0s   6%    importance        0.996  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.674  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.230    episode_length               74.239  â”‚
â”‚  x_position                  -15.944    x_velocity                  -83.093  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-37.64 (best=-9.00@32768)
æ­¥æ•° 65,536: Reward=-37.64, Best=-9.00@32768, Sharpness=1.7735, Î»_max=155.2617
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.499  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.425  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                3    Train         1s  14%    approx_kl         0.026  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   2%    clipfrac          0.256  â”‚
â”‚  Remainiâ€¦        3m 33s      Learn       0s   6%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.725  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -17.281    episode_length               82.718  â”‚
â”‚  x_position                  -23.511    x_velocity                  -99.581  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-15.37 (best=-9.00@32768)
æ­¥æ•° 98,304: Reward=-15.37, Best=-9.00@32768, Sharpness=1.8559, Î»_max=-104.1902
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.398  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.444  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                4    Train         1s  14%    approx_kl         0.020  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   2%    clipfrac          0.218  â”‚
â”‚  Remainiâ€¦         3m 5s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.727  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -21.205    episode_length               89.726  â”‚
â”‚  x_position                  -29.508    x_velocity                 -110.478  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-35.74 (best=-9.00@32768)
æ­¥æ•° 131,072: Reward=-35.74, Best=-9.00@32768, Sharpness=1.9192, Î»_max=-93.5993
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.8%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.300  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          11.460  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                5    Train         1s  14%    approx_kl         0.019  â”‚
â”‚  Uptime          1m 10s      Forwaâ€¦      0s   2%    clipfrac          0.203  â”‚
â”‚  Remainiâ€¦        2m 47s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.718  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -18.989    episode_length               92.615  â”‚
â”‚  x_position                  -31.585    x_velocity                 -111.135  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-8.46 (best=-9.00@32768)
æ­¥æ•° 163,840: Reward=-8.46, Best=-9.00@32768, Sharpness=1.8307, Î»_max=-112.1040
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.8%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env        11s  76%    value_loss        0.308  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          11.477  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                6    Train         2s  14%    approx_kl         0.016  â”‚
â”‚  Uptime          1m 28s      Forwaâ€¦      0s   2%    clipfrac          0.173  â”‚
â”‚  Remainiâ€¦        2m 42s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.723  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -21.133    episode_length               94.853  â”‚
â”‚  x_position                  -33.853    x_velocity                 -115.506  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-2.56 (best=-9.00@32768)
æ­¥æ•° 196,608: Reward=-2.56, Best=-9.00@32768, Sharpness=1.8938, Î»_max=-79.0903
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.8%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 18.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env        11s  80%    value_loss        0.275  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.494  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         2s  12%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 42s      Forwaâ€¦      0s   2%    clipfrac          0.155  â”‚
â”‚  Remainiâ€¦        1m 56s      Learn       0s   6%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.732  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -18.735    episode_length               98.857  â”‚
â”‚  x_position                  -36.187    x_velocity                 -117.092  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-2.73 (best=-9.00@32768)
æ­¥æ•° 229,376: Reward=-2.73, Best=-9.00@32768, Sharpness=1.9768, Î»_max=-75.5539
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.5%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.005  â”‚
â”‚  Params          135.3K      Env        11s  80%    value_loss        0.284  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.511  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                8    Train         2s  12%    approx_kl         0.013  â”‚
â”‚  Uptime          1m 58s      Forwaâ€¦      0s   2%    clipfrac          0.151  â”‚
â”‚  Remainiâ€¦         2m 0s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.771  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -16.401    episode_length               99.653  â”‚
â”‚  x_position                  -35.869    x_velocity                 -115.550  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-6.62 (best=-9.00@32768)
æ­¥æ•° 262,144: Reward=-6.62, Best=-9.00@32768, Sharpness=1.9364, Î»_max=-92.8815
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.009  â”‚
â”‚  Params          135.3K      Env        11s  80%    value_loss        0.273  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.522  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         2s  12%    approx_kl         0.010  â”‚
â”‚  Uptime          2m 15s      Forwaâ€¦      0s   2%    clipfrac          0.119  â”‚
â”‚  Remainiâ€¦        1m 44s      Learn       0s   6%    importance        1.003  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.770  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -18.688    episode_length              106.387  â”‚
â”‚  x_position                  -40.688    x_velocity                 -124.536  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=207.08 (best=-9.00@32768)
æ­¥æ•° 294,912: Reward=207.08, Best=-9.00@32768, Sharpness=1.9006, Î»_max=-91.2339
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env        11s  80%    value_loss        0.271  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.534  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         2s  12%    approx_kl         0.008  â”‚
â”‚  Uptime          2m 33s      Forwaâ€¦      0s   2%    clipfrac          0.094  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.776  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -15.085    episode_length              105.039  â”‚
â”‚  x_position                  -38.512    x_velocity                 -119.592  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-12.18 (best=-9.00@32768)
æ­¥æ•° 327,680: Reward=-12.18, Best=-9.00@32768, Sharpness=1.9024, Î»_max=0.9283
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 18.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env        17s  80%    value_loss        0.260  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.545  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         2s  12%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 48s      Forwaâ€¦      0s   2%    clipfrac          0.084  â”‚
â”‚  Remainiâ€¦         1m 4s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.771  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -16.628    episode_length              108.516  â”‚
â”‚  x_position                  -41.732    x_velocity                 -124.594  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-10.58 (best=-9.00@32768)
æ­¥æ•° 360,448: Reward=-10.58, Best=-9.00@32768, Sharpness=1.9404, Î»_max=-82.9273
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 18.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env        17s  80%    value_loss        0.261  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.550  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         2s  12%    approx_kl         0.006  â”‚
â”‚  Uptime           3m 3s      Forwaâ€¦      0s   2%    clipfrac          0.067  â”‚
â”‚  Remainiâ€¦           48s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.791  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -13.421    episode_length              111.556  â”‚
â”‚  x_position                  -42.693    x_velocity                 -124.412  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-11.65 (best=-9.00@32768)
æ­¥æ•° 393,216: Reward=-11.65, Best=-9.00@32768, Sharpness=1.9026, Î»_max=-84.7340
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.5%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.008  â”‚
â”‚  Params          135.3K      Env        17s  80%    value_loss        0.318  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.552  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  12%    approx_kl         0.004  â”‚
â”‚  Uptime          3m 19s      Forwaâ€¦      0s   2%    clipfrac          0.040  â”‚
â”‚  Remainiâ€¦           36s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.784  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.686    episode_length              118.664  â”‚
â”‚  x_position                  -45.320    x_velocity                 -128.749  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-9.75 (best=-9.00@32768)
æ­¥æ•° 425,984: Reward=-9.75, Best=-9.00@32768, Sharpness=2.1340, Î»_max=-92.2780
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.4%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 19.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.026  â”‚
â”‚  Params          135.3K      Env        17s  80%    value_loss        0.337  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.554  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  12%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 33s      Forwaâ€¦      0s   2%    clipfrac          0.020  â”‚
â”‚  Remainiâ€¦           17s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.773  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.545    episode_length              118.766  â”‚
â”‚  x_position                  -45.016    x_velocity                 -125.709  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-2.04 (best=-9.00@32768)
æ­¥æ•° 458,752: Reward=-2.04, Best=-7.55@458752, Sharpness=1.9658, Î»_max=-72.0578
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.040  â”‚
â”‚  Params          135.3K      Env        17s  80%    value_loss        0.355  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.555  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 51s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.739  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.610    episode_length              120.035  â”‚
â”‚  x_position                  -43.574    x_velocity                 -123.037  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-4.37 (best=-7.55@458752)
æ­¥æ•° 491,520: Reward=-4.37, Best=-3.61@491520, Sharpness=2.0974, Î»_max=-72.7791
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 17.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     25s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.034  â”‚
â”‚  Params          135.3K      Env        23s  80%    value_loss        0.397  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.555  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  12%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 8s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.699  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.606    episode_length              124.788  â”‚
â”‚  x_position                  -47.410    x_velocity                 -126.761  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=3.23 (best=-3.61@491520)
æ­¥æ•° 524,288: Reward=3.23, Best=-2.61@524288, Sharpness=1.8860, Î»_max=-88.1401

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 6_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_6/vec_stats.npz
[J&R] base_task=6, new_task=6_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_6/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.4%  DRAM: 0.5%   VRAM: 1.5%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        4.080  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          23.397  â”‚
â”‚  SPS               4.4K      Misc        0s   0%    old_approx_kl     0.041  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.039  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.286  â”‚
â”‚  Remainiâ€¦        1m 45s      Learn       0s   0%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.132  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.018    episode_length               18.106  â”‚
â”‚  x_position                   -1.628    x_velocity                  -24.022  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-14.52 (best=N/A)
æ­¥æ•° 32,768: Reward=-14.52, Best=-6.02@32768, Sharpness=4.3954, Î»_max=31.9655
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        1.797  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          23.435  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                2    Train         1s  15%    approx_kl         0.022  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.189  â”‚
â”‚  Remainiâ€¦        3m 41s      Learn       0s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.137  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.248    episode_length               20.513  â”‚
â”‚  x_position                   -1.936    x_velocity                  -25.644  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-16.68 (best=-6.02@32768)
æ­¥æ•° 65,536: Reward=-16.68, Best=-5.25@65536, Sharpness=3.0023, Î»_max=18.6952
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.5%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        1.081  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          23.474  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                3    Train         1s  15%    approx_kl         0.014  â”‚
â”‚  Uptime             41s      Forwaâ€¦      0s   2%    clipfrac          0.143  â”‚
â”‚  Remainiâ€¦        3m 32s      Learn       0s   9%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.148  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.906    episode_length               21.787  â”‚
â”‚  x_position                   -2.086    x_velocity                  -26.568  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-8.21 (best=-5.25@65536)
æ­¥æ•° 98,304: Reward=-8.21, Best=-4.91@98304, Sharpness=2.1261, Î»_max=11.8817
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 18.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.845  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          23.509  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         1s  15%    approx_kl         0.013  â”‚
â”‚  Uptime             55s      Forwaâ€¦      0s   2%    clipfrac          0.136  â”‚
â”‚  Remainiâ€¦        2m 37s      Learn       0s   9%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.140  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.272    episode_length               22.716  â”‚
â”‚  x_position                   -2.250    x_velocity                  -26.859  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-9.34 (best=-4.91@98304)
æ­¥æ•° 131,072: Reward=-9.34, Best=-4.27@131072, Sharpness=1.9764, Î»_max=10.7461
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.733  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          23.538  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                5    Train         1s  15%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 10s      Forwaâ€¦      0s   2%    clipfrac          0.131  â”‚
â”‚  Remainiâ€¦        2m 30s      Learn       0s   9%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.027  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.368    episode_length               23.852  â”‚
â”‚  x_position                   -2.399    x_velocity                  -27.085  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-7.94 (best=-4.27@131072)
æ­¥æ•° 163,840: Reward=-7.94, Best=-3.37@163840, Sharpness=1.7494, Î»_max=11.4154
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env        10s  76%    value_loss        0.657  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          23.562  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         2s  15%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 25s      Forwaâ€¦      0s   2%    clipfrac          0.112  â”‚
â”‚  Remainiâ€¦        2m 24s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.031  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.709    episode_length               24.758  â”‚
â”‚  x_position                   -2.487    x_velocity                  -27.326  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=54.36 (best=-3.37@163840)
æ­¥æ•° 196,608: Reward=54.36, Best=-2.71@196608, Sharpness=1.3254, Î»_max=2.9373
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env        10s  75%    value_loss        0.626  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          23.595  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         2s  17%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 40s      Forwaâ€¦      0s   3%    clipfrac          0.092  â”‚
â”‚  Remainiâ€¦        1m 59s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.042  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.951    episode_length               26.039  â”‚
â”‚  x_position                   -2.578    x_velocity                  -27.842  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-9.77 (best=-2.71@196608)
æ­¥æ•° 229,376: Reward=-9.77, Best=-1.95@229376, Sharpness=1.4087, Î»_max=7.4184
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.9%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env        10s  75%    value_loss        0.611  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          23.620  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         2s  17%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 57s      Forwaâ€¦      0s   3%    clipfrac          0.086  â”‚
â”‚  Remainiâ€¦         2m 3s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.088  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.461    episode_length               27.108  â”‚
â”‚  x_position                   -2.791    x_velocity                  -28.415  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-16.24 (best=-1.95@229376)
æ­¥æ•° 262,144: Reward=-16.24, Best=-1.46@262144, Sharpness=1.5100, Î»_max=8.0912
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.1%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env        10s  75%    value_loss        0.593  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          23.638  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  17%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 14s      Forwaâ€¦      0s   3%    clipfrac          0.071  â”‚
â”‚  Remainiâ€¦        1m 47s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.142  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.101    episode_length               29.889  â”‚
â”‚  x_position                   -3.283    x_velocity                  -30.819  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=144.40 (best=-1.46@262144)
æ­¥æ•° 294,912: Reward=144.40, Best=-1.10@294912, Sharpness=1.1546, Î»_max=7.9496
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env        10s  75%    value_loss        0.590  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          23.651  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         2s  17%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   3%    clipfrac          0.057  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.152  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.290    episode_length               30.764  â”‚
â”‚  x_position                   -3.449    x_velocity                  -30.878  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-8.03 (best=-1.10@294912)
æ­¥æ•° 327,680: Reward=-8.03, Best=-0.29@327680, Sharpness=1.2396, Î»_max=-7.8553
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env        15s  75%    value_loss        0.635  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          23.659  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               11    Train         2s  17%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 49s      Forwaâ€¦      0s   3%    clipfrac          0.041  â”‚
â”‚  Remainiâ€¦        1m 14s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.143  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.603    episode_length               33.737  â”‚
â”‚  x_position                   -3.995    x_velocity                  -32.941  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-7.71 (best=-0.29@327680)
æ­¥æ•° 360,448: Reward=-7.71, Best=0.60@360448, Sharpness=1.4941, Î»_max=9.7810
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.2%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env        15s  86%    value_loss        0.599  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          23.668  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               12    Train         2s   8%    approx_kl         0.003  â”‚
â”‚  Uptime           3m 7s      Forwaâ€¦      0s   1%    clipfrac          0.025  â”‚
â”‚  Remainiâ€¦           58s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.198  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.635    episode_length               33.998  â”‚
â”‚  x_position                   -4.001    x_velocity                  -33.169  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-16.62 (best=0.60@360448)
æ­¥æ•° 393,216: Reward=-16.62, Best=0.63@393216, Sharpness=1.2629, Î»_max=6.6388
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.3%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.014  â”‚
â”‚  Params          135.3K      Env        15s  86%    value_loss        0.616  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          23.675  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               13    Train         2s   8%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 24s      Forwaâ€¦      0s   1%    clipfrac          0.014  â”‚
â”‚  Remainiâ€¦           39s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.163  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.677    episode_length               36.410  â”‚
â”‚  x_position                   -4.548    x_velocity                  -35.524  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-24.63 (best=0.63@393216)
æ­¥æ•° 425,984: Reward=-24.63, Best=0.68@425984, Sharpness=1.3822, Î»_max=7.7032
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env        15s  86%    value_loss        0.587  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          23.678  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s   8%    approx_kl         0.001  â”‚
â”‚  Uptime          3m 40s      Forwaâ€¦      0s   1%    clipfrac          0.004  â”‚
â”‚  Remainiâ€¦           19s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.115  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                1.217    episode_length               38.404  â”‚
â”‚  x_position                   -5.177    x_velocity                  -36.967  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-21.78 (best=0.68@425984)
æ­¥æ•° 458,752: Reward=-21.78, Best=1.22@458752, Sharpness=1.3245, Î»_max=7.4346
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.6%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.018  â”‚
â”‚  Params          135.3K      Env        15s  86%    value_loss        0.640  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          23.680  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s   8%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 59s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.121  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.689    episode_length               37.337  â”‚
â”‚  x_position                   -4.881    x_velocity                  -36.435  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-30.31 (best=1.22@458752)
æ­¥æ•° 491,520: Reward=-30.31, Best=1.22@458752, Sharpness=1.2579, Î»_max=-4.8134
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.0%  DRAM: 0.6%   VRAM: 1.7%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     23s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss       0.024  â”‚
â”‚  Params          135.3K      Env        21s  86%    value_loss        0.704  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          23.680  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s   8%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 15s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.100  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                1.567    episode_length               38.350  â”‚
â”‚  x_position                   -4.987    x_velocity                  -36.564  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-10.18 (best=1.22@458752)
æ­¥æ•° 524,288: Reward=-10.18, Best=1.57@524288, Sharpness=1.3692, Î»_max=8.5905

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 6_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 6 step sweep å®Œæˆã€‚
