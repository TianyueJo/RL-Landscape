==========================================
[Jump & Retrain] Walker2d task 14 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 11:07:54 EST 2025
èŠ‚ç‚¹: node9
==========================================
[Base] task=14, env=Walker2d-v4, best_model=final_model.pt, best_reward=2507.55, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_14/vec_stats.npz
[J&R] base_task=14, new_task=14_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_14/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.4%  DRAM: 0.3%   VRAM: 1.1%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.157  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.233  â”‚
â”‚  SPS               4.1K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.024  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.266  â”‚
â”‚  Remainiâ€¦        1m 52s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.420  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                1.221    episode_length               51.795  â”‚
â”‚  x_position                   -4.948    x_velocity                  -50.303  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=133.40 (best=N/A)
æ­¥æ•° 32,768: Reward=133.40, Best=1.22@32768, Sharpness=1.1758, Î»_max=-38.9385
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.2%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 11.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   9%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.685  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.263  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.023  â”‚
â”‚  Epoch                2    Train         1s  31%    approx_kl         0.021  â”‚
â”‚  Uptime             18s      Forwaâ€¦      0s   5%    clipfrac          0.213  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s  14%    importance        0.997  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.850  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.445    episode_length               87.969  â”‚
â”‚  x_position                  -14.589    x_velocity                  -77.063  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-6.17 (best=1.22@32768)
æ­¥æ•° 65,536: Reward=-6.17, Best=10.44@65536, Sharpness=1.1656, Î»_max=-38.9008
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   9%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.470  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.289  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                3    Train         1s  31%    approx_kl         0.018  â”‚
â”‚  Uptime             27s      Forwaâ€¦      0s   5%    clipfrac          0.201  â”‚
â”‚  Remainiâ€¦        1m 55s      Learn       0s  14%    importance        0.998  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               16.130    episode_length              112.080  â”‚
â”‚  x_position                  -24.440    x_velocity                  -95.363  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-15.35 (best=10.44@65536)
æ­¥æ•° 98,304: Reward=-15.35, Best=16.13@98304, Sharpness=1.1990, Î»_max=-40.8945
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   9%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.393  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.318  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         1s  31%    approx_kl         0.014  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   5%    clipfrac          0.172  â”‚
â”‚  Remainiâ€¦        1m 48s      Learn       0s  14%    importance        1.001  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               21.608    episode_length              118.904  â”‚
â”‚  x_position                  -26.779    x_velocity                  -96.673  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-22.19 (best=16.13@98304)
æ­¥æ•° 131,072: Reward=-22.19, Best=21.61@131072, Sharpness=1.2091, Î»_max=-38.2880
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   9%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.344  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.335  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                5    Train         1s  31%    approx_kl         0.011  â”‚
â”‚  Uptime             47s      Forwaâ€¦      0s   5%    clipfrac          0.139  â”‚
â”‚  Remainiâ€¦        1m 42s      Learn       0s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.911  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               20.254    episode_length              122.282  â”‚
â”‚  x_position                  -30.314    x_velocity                 -101.389  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-8.96 (best=21.61@131072)
æ­¥æ•° 163,840: Reward=-8.96, Best=21.61@131072, Sharpness=1.2403, Î»_max=-30.0767
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   9%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         5s  56%    value_loss        0.276  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.358  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         2s  31%    approx_kl         0.012  â”‚
â”‚  Uptime             56s      Forwaâ€¦      0s   5%    clipfrac          0.152  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       1s  14%    importance        1.001  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.927  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               27.469    episode_length              132.051  â”‚
â”‚  x_position                  -31.626    x_velocity                 -103.891  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-4.02 (best=21.61@131072)
æ­¥æ•° 196,608: Reward=-4.02, Best=27.47@196608, Sharpness=1.2034, Î»_max=-31.0225
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.264  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.380  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                7    Train         2s  14%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 6s      Forwaâ€¦      0s   2%    clipfrac          0.116  â”‚
â”‚  Remainiâ€¦        1m 21s      Learn       1s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               45.692    episode_length              155.757  â”‚
â”‚  x_position                  -38.787    x_velocity                 -109.252  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-26.27 (best=27.47@196608)
æ­¥æ•° 229,376: Reward=-26.27, Best=45.69@229376, Sharpness=1.2950, Î»_max=-18.6021
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.241  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.394  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         2s  14%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 16s      Forwaâ€¦      0s   2%    clipfrac          0.104  â”‚
â”‚  Remainiâ€¦        1m 11s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.921  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               50.035    episode_length              154.212  â”‚
â”‚  x_position                  -34.449    x_velocity                 -103.372  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-25.99 (best=45.69@229376)
æ­¥æ•° 262,144: Reward=-25.99, Best=50.03@262144, Sharpness=1.2744, Î»_max=-26.9176
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.239  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.409  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  14%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 26s      Forwaâ€¦      0s   2%    clipfrac          0.086  â”‚
â”‚  Remainiâ€¦           59s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               67.778    episode_length              175.909  â”‚
â”‚  x_position                  -34.510    x_velocity                 -107.211  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-31.44 (best=50.03@262144)
æ­¥æ•° 294,912: Reward=-31.44, Best=67.78@294912, Sharpness=1.3117, Î»_max=-22.7556
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.7%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.225  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.420  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         2s  14%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   2%    clipfrac          0.072  â”‚
â”‚  Remainiâ€¦           50s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               85.473    episode_length              189.947  â”‚
â”‚  x_position                  -36.489    x_velocity                 -103.481  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-21.54 (best=67.78@294912)
æ­¥æ•° 327,680: Reward=-21.54, Best=85.47@327680, Sharpness=1.2991, Î»_max=-23.5681
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.7%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         8s  77%    value_loss        0.220  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.429  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         2s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 45s      Forwaâ€¦      0s   2%    clipfrac          0.048  â”‚
â”‚  Remainiâ€¦           39s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.910  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              115.219    episode_length              222.609  â”‚
â”‚  x_position                  -40.760    x_velocity                 -106.227  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-25.62 (best=85.47@327680)
æ­¥æ•° 360,448: Reward=-25.62, Best=115.22@360448, Sharpness=1.3444, Î»_max=-19.9253
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.202  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.435  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         2s  12%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 55s      Forwaâ€¦      0s   2%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦           31s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.906  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              107.862    episode_length              232.761  â”‚
â”‚  x_position                  -54.791    x_velocity                 -123.682  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-3.24 (best=115.22@360448)
æ­¥æ•° 393,216: Reward=-3.24, Best=115.22@360448, Sharpness=1.4797, Î»_max=-26.5384
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.196  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.439  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  12%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 4s      Forwaâ€¦      0s   2%    clipfrac          0.031  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              188.139    episode_length              304.087  â”‚
â”‚  x_position                  -59.800    x_velocity                 -114.363  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-18.96 (best=115.22@360448)
æ­¥æ•° 425,984: Reward=-18.96, Best=188.14@425984, Sharpness=1.2794, Î»_max=-35.6045
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.000  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.199  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.441  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  12%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 13s      Forwaâ€¦      0s   2%    clipfrac          0.008  â”‚
â”‚  Remainiâ€¦           11s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.875  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              183.265    episode_length              301.475  â”‚
â”‚  x_position                  -42.023    x_velocity                 -116.640  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-15.66 (best=188.14@425984)
æ­¥æ•° 458,752: Reward=-15.66, Best=188.14@425984, Sharpness=1.2748, Î»_max=-20.6712
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.217  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.442  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               15    Train         2s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 23s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              247.348    episode_length              351.489  â”‚
â”‚  x_position                  -32.728    x_velocity                 -102.311  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-23.95 (best=188.14@425984)
æ­¥æ•° 491,520: Reward=-23.95, Best=247.35@491520, Sharpness=1.2760, Î»_max=-14.9788
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.223  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.443  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 34s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.815  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              262.715    episode_length              370.579  â”‚
â”‚  x_position                  -44.873    x_velocity                 -105.933  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-27.79 (best=247.35@491520)
æ­¥æ•° 524,288: Reward=-27.79, Best=262.71@524288, Sharpness=1.2414, Î»_max=-22.3680

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 14_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_14/vec_stats.npz
[J&R] base_task=14, new_task=14_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_14/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.160  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.154  â”‚
â”‚  SPS               8.2K      Misc        0s   0%    old_approx_kl     0.034  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.026  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.271  â”‚
â”‚  Remainiâ€¦           57s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.438  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.805    episode_length               53.774  â”‚
â”‚  x_position                   -5.768    x_velocity                  -52.686  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=244.84 (best=N/A)
æ­¥æ•° 32,768: Reward=244.84, Best=0.80@32768, Sharpness=1.2014, Î»_max=-38.1695
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.613  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.189  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                2    Train         0s  13%    approx_kl         0.020  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.204  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s   8%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.852  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.950    episode_length               86.899  â”‚
â”‚  x_position                  -13.603    x_velocity                  -74.493  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=38.30 (best=0.80@32768)
æ­¥æ•° 65,536: Reward=38.30, Best=11.95@65536, Sharpness=1.1997, Î»_max=-42.5088
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.474  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.218  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         0s  13%    approx_kl         0.017  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.195  â”‚
â”‚  Remainiâ€¦         2m 7s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               14.866    episode_length              115.491  â”‚
â”‚  x_position                  -26.291    x_velocity                 -100.020  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-20.13 (best=11.95@65536)
æ­¥æ•° 98,304: Reward=-20.13, Best=14.87@98304, Sharpness=1.2232, Î»_max=-38.9420
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.388  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.245  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                4    Train         0s  13%    approx_kl         0.014  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.172  â”‚
â”‚  Remainiâ€¦        1m 54s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.914  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.959    episode_length              121.143  â”‚
â”‚  x_position                  -25.714    x_velocity                  -95.547  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-7.62 (best=14.87@98304)
æ­¥æ•° 131,072: Reward=-7.62, Best=24.96@131072, Sharpness=1.2249, Î»_max=-35.9707
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.320  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.267  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         0s  13%    approx_kl         0.013  â”‚
â”‚  Uptime             44s      Forwaâ€¦      0s   2%    clipfrac          0.156  â”‚
â”‚  Remainiâ€¦        1m 42s      Learn       0s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.919  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               28.647    episode_length              126.588  â”‚
â”‚  x_position                  -26.488    x_velocity                  -97.277  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-22.05 (best=24.96@131072)
æ­¥æ•° 163,840: Reward=-22.05, Best=28.65@163840, Sharpness=1.2563, Î»_max=-34.2197
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.282  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.285  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         0s  13%    approx_kl         0.010  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   2%    clipfrac          0.128  â”‚
â”‚  Remainiâ€¦        1m 32s      Learn       0s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.757    episode_length              133.854  â”‚
â”‚  x_position                  -31.062    x_velocity                 -102.394  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-21.75 (best=28.65@163840)
æ­¥æ•° 196,608: Reward=-21.75, Best=30.76@196608, Sharpness=1.2723, Î»_max=-27.4831
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.256  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.302  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         0s  12%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 4s      Forwaâ€¦      0s   2%    clipfrac          0.102  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.920  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               38.302    episode_length              142.632  â”‚
â”‚  x_position                  -31.360    x_velocity                 -103.582  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-17.64 (best=30.76@196608)
æ­¥æ•° 229,376: Reward=-17.64, Best=38.30@229376, Sharpness=1.2382, Î»_max=-32.2719
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.242  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.321  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         0s  12%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 13s      Forwaâ€¦      0s   2%    clipfrac          0.097  â”‚
â”‚  Remainiâ€¦         1m 6s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.927  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               49.339    episode_length              155.930  â”‚
â”‚  x_position                  -34.849    x_velocity                 -105.773  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-18.97 (best=38.30@229376)
æ­¥æ•° 262,144: Reward=-18.97, Best=49.34@262144, Sharpness=1.3377, Î»_max=-21.3147
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.243  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.336  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         0s  12%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 23s      Forwaâ€¦      0s   2%    clipfrac          0.079  â”‚
â”‚  Remainiâ€¦           59s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.928  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               61.495    episode_length              171.324  â”‚
â”‚  x_position                  -38.307    x_velocity                 -108.929  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-22.59 (best=49.34@262144)
æ­¥æ•° 294,912: Reward=-22.59, Best=61.49@294912, Sharpness=1.2465, Î»_max=-32.7275
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.238  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.346  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         0s  12%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 33s      Forwaâ€¦      0s   2%    clipfrac          0.065  â”‚
â”‚  Remainiâ€¦           52s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.919  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               91.266    episode_length              199.024  â”‚
â”‚  x_position                  -40.635    x_velocity                 -106.717  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-20.63 (best=61.49@294912)
æ­¥æ•° 327,680: Reward=-20.63, Best=91.27@327680, Sharpness=1.2971, Î»_max=-29.6398
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.238  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.353  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  12%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 42s      Forwaâ€¦      0s   2%    clipfrac          0.055  â”‚
â”‚  Remainiâ€¦           40s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.906  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               98.361    episode_length              201.593  â”‚
â”‚  x_position                  -35.874    x_velocity                 -102.176  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-19.70 (best=91.27@327680)
æ­¥æ•° 360,448: Reward=-19.70, Best=98.36@360448, Sharpness=1.3128, Î»_max=-28.4382
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.197  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.360  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         1s  12%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 53s      Forwaâ€¦      0s   2%    clipfrac          0.045  â”‚
â”‚  Remainiâ€¦           33s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              136.864    episode_length              234.731  â”‚
â”‚  x_position                  -31.941    x_velocity                  -96.640  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-16.24 (best=98.36@360448)
æ­¥æ•° 393,216: Reward=-16.24, Best=136.86@393216, Sharpness=1.3365, Î»_max=-25.9898
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.204  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.364  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  12%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 3s      Forwaâ€¦      0s   2%    clipfrac          0.027  â”‚
â”‚  Remainiâ€¦           22s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.883  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              168.689    episode_length              278.595  â”‚
â”‚  x_position                  -44.332    x_velocity                 -108.449  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=0.29 (best=136.86@393216)
æ­¥æ•° 425,984: Reward=0.29, Best=168.69@425984, Sharpness=1.3088, Î»_max=-32.2280
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.199  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.366  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  12%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 13s      Forwaâ€¦      0s   2%    clipfrac          0.013  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.858  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              208.460    episode_length              304.231  â”‚
â”‚  x_position                  -23.635    x_velocity                  -94.180  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-11.81 (best=168.69@425984)
æ­¥æ•° 458,752: Reward=-11.81, Best=208.46@458752, Sharpness=1.5037, Î»_max=-18.9704
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.201  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.367  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 23s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.828  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              188.606    episode_length              289.216  â”‚
â”‚  x_position                  -39.751    x_velocity                  -99.098  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=6.73 (best=208.46@458752)
æ­¥æ•° 491,520: Reward=6.73, Best=208.46@458752, Sharpness=1.7597, Î»_max=-21.9303
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env        11s  79%    value_loss        0.226  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.367  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         1s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 32s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.797  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              230.773    episode_length              343.424  â”‚
â”‚  x_position                  -51.892    x_velocity                 -110.854  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-9.83 (best=208.46@458752)
æ­¥æ•° 524,288: Reward=-9.83, Best=230.77@524288, Sharpness=1.3195, Î»_max=-26.7770

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 14_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_14/vec_stats.npz
[J&R] base_task=14, new_task=14_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_14/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 0.7%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 21.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.107  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.902  â”‚
â”‚  SPS               7.0K      Misc        0s   0%    old_approx_kl     0.034  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.029  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.301  â”‚
â”‚  Remainiâ€¦         1m 7s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.308  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.006    episode_length               50.938  â”‚
â”‚  x_position                   -5.645    x_velocity                  -51.677  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=159.54 (best=N/A)
æ­¥æ•° 32,768: Reward=159.54, Best=-1.01@32768, Sharpness=1.2533, Î»_max=-50.0794
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        0.716  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.939  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.026  â”‚
â”‚  Epoch                2    Train         0s  12%    approx_kl         0.024  â”‚
â”‚  Uptime             15s      Forwaâ€¦      0s   2%    clipfrac          0.238  â”‚
â”‚  Remainiâ€¦        2m 22s      Learn       0s   7%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.823  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.710    episode_length               86.735  â”‚
â”‚  x_position                  -14.573    x_velocity                  -75.569  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-8.71 (best=-1.01@32768)
æ­¥æ•° 65,536: Reward=-8.71, Best=10.71@65536, Sharpness=1.2409, Î»_max=-64.9082
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        0.484  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.962  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                3    Train         0s  12%    approx_kl         0.018  â”‚
â”‚  Uptime             25s      Forwaâ€¦      0s   2%    clipfrac          0.204  â”‚
â”‚  Remainiâ€¦         2m 4s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.875  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               14.515    episode_length              107.021  â”‚
â”‚  x_position                  -25.051    x_velocity                  -91.945  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-10.94 (best=10.71@65536)
æ­¥æ•° 98,304: Reward=-10.94, Best=14.51@98304, Sharpness=1.2855, Î»_max=-62.0354
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        0.405  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.985  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                4    Train         0s  12%    approx_kl         0.014  â”‚
â”‚  Uptime             35s      Forwaâ€¦      0s   2%    clipfrac          0.170  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.889  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               14.142    episode_length              112.068  â”‚
â”‚  x_position                  -28.378    x_velocity                  -97.340  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-17.37 (best=14.51@98304)
æ­¥æ•° 131,072: Reward=-17.37, Best=14.51@98304, Sharpness=1.2556, Î»_max=-74.6691
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        0.339  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.010  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                5    Train         0s  12%    approx_kl         0.014  â”‚
â”‚  Uptime             45s      Forwaâ€¦      0s   2%    clipfrac          0.171  â”‚
â”‚  Remainiâ€¦        1m 42s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.898  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.214    episode_length              124.008  â”‚
â”‚  x_position                  -33.278    x_velocity                 -101.144  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-24.51 (best=14.51@98304)
æ­¥æ•° 163,840: Reward=-24.51, Best=22.21@163840, Sharpness=1.2841, Î»_max=-55.7437
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.311  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.036  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         1s  12%    approx_kl         0.011  â”‚
â”‚  Uptime             55s      Forwaâ€¦      0s   2%    clipfrac          0.138  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               23.869    episode_length              123.777  â”‚
â”‚  x_position                  -31.683    x_velocity                  -99.261  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-23.29 (best=22.21@163840)
æ­¥æ•° 196,608: Reward=-23.29, Best=23.87@196608, Sharpness=1.2824, Î»_max=-51.6645
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 5.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.264  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.050  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         1s  11%    approx_kl         0.010  â”‚
â”‚  Uptime           1m 4s      Forwaâ€¦      0s   2%    clipfrac          0.128  â”‚
â”‚  Remainiâ€¦        1m 16s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               35.273    episode_length              134.041  â”‚
â”‚  x_position                  -33.444    x_velocity                  -98.064  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-13.60 (best=23.87@196608)
æ­¥æ•° 229,376: Reward=-13.60, Best=35.27@229376, Sharpness=1.3335, Î»_max=-50.7659
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 5.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.261  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.063  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                8    Train         1s  11%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 14s      Forwaâ€¦      0s   2%    clipfrac          0.109  â”‚
â”‚  Remainiâ€¦        1m 11s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.242    episode_length              141.514  â”‚
â”‚  x_position                  -41.183    x_velocity                 -110.532  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-12.59 (best=35.27@229376)
æ­¥æ•° 262,144: Reward=-12.59, Best=35.27@229376, Sharpness=1.3177, Î»_max=-67.8584
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.247  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.079  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch                9    Train         1s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 24s      Forwaâ€¦      0s   2%    clipfrac          0.090  â”‚
â”‚  Remainiâ€¦         1m 3s      Learn       0s   7%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               44.766    episode_length              159.778  â”‚
â”‚  x_position                  -45.708    x_velocity                 -114.176  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-17.20 (best=35.27@229376)
æ­¥æ•° 294,912: Reward=-17.20, Best=44.77@294912, Sharpness=1.2761, Î»_max=-55.3526
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.229  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.091  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   2%    clipfrac          0.074  â”‚
â”‚  Remainiâ€¦           55s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               60.433    episode_length              172.548  â”‚
â”‚  x_position                  -44.776    x_velocity                 -111.212  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-6.41 (best=44.77@294912)
æ­¥æ•° 327,680: Reward=-6.41, Best=60.43@327680, Sharpness=1.3365, Î»_max=-50.0388
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.239  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.098  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 44s      Forwaâ€¦      0s   2%    clipfrac          0.064  â”‚
â”‚  Remainiâ€¦           41s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               66.989    episode_length              187.460  â”‚
â”‚  x_position                  -63.300    x_velocity                 -119.492  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-10.21 (best=60.43@327680)
æ­¥æ•° 360,448: Reward=-10.21, Best=66.99@360448, Sharpness=1.3036, Î»_max=-53.2455
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.231  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.102  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  13%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 54s      Forwaâ€¦      0s   2%    clipfrac          0.040  â”‚
â”‚  Remainiâ€¦           30s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.879  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               82.455    episode_length              201.721  â”‚
â”‚  x_position                  -67.406    x_velocity                 -118.214  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-10.02 (best=66.99@360448)
æ­¥æ•° 393,216: Reward=-10.02, Best=82.46@393216, Sharpness=1.3404, Î»_max=-55.3071
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.218  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.104  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         1s  13%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 3s      Forwaâ€¦      0s   2%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           20s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.855  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               92.404    episode_length              220.313  â”‚
â”‚  x_position                  -74.014    x_velocity                 -126.760  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-4.69 (best=82.46@393216)
æ­¥æ•° 425,984: Reward=-4.69, Best=92.40@425984, Sharpness=1.3328, Î»_max=-50.2290
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.207  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.107  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  13%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 13s      Forwaâ€¦      0s   2%    clipfrac          0.008  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.842  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              102.279    episode_length              221.798  â”‚
â”‚  x_position                  -60.984    x_velocity                 -118.364  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-6.32 (best=92.40@425984)
æ­¥æ•° 458,752: Reward=-6.32, Best=102.28@458752, Sharpness=1.2745, Î»_max=-43.7514
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.221  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.108  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               15    Train         1s  13%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 23s      Forwaâ€¦      0s   2%    clipfrac          0.010  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.850  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              109.148    episode_length              243.202  â”‚
â”‚  x_position                  -89.521    x_velocity                 -132.786  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-6.50 (best=102.28@458752)
æ­¥æ•° 491,520: Reward=-6.50, Best=109.15@491520, Sharpness=1.3884, Î»_max=-49.4170
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.229  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.108  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 33s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.796  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              116.538    episode_length              268.165  â”‚
â”‚  x_position                 -119.568    x_velocity                 -150.230  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-5.60 (best=109.15@491520)
æ­¥æ•° 524,288: Reward=-5.60, Best=116.54@524288, Sharpness=1.3690, Î»_max=-34.5981

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 14_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_14/vec_stats.npz
[J&R] base_task=14, new_task=14_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_14/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.219  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.086  â”‚
â”‚  SPS               7.6K      Misc        0s   0%    old_approx_kl     0.049  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.043  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.363  â”‚
â”‚  Remainiâ€¦         1m 1s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.486  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                3.075    episode_length               36.781  â”‚
â”‚  x_position                   -2.979    x_velocity                  -33.521  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=0.69 (best=N/A)
æ­¥æ•° 32,768: Reward=0.69, Best=3.07@32768, Sharpness=2.5145, Î»_max=-87.7918
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.1%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.630  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.128  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.034  â”‚
â”‚  Epoch                2    Train         0s  14%    approx_kl         0.030  â”‚
â”‚  Uptime             13s      Forwaâ€¦      0s   2%    clipfrac          0.268  â”‚
â”‚  Remainiâ€¦         2m 8s      Learn       0s  11%    importance        0.996  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.719  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               14.305    episode_length               67.385  â”‚
â”‚  x_position                   -8.431    x_velocity                  -52.737  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=3.48 (best=3.07@32768)
æ­¥æ•° 65,536: Reward=3.48, Best=14.30@65536, Sharpness=2.3368, Î»_max=-105.7172
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.486  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.160  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.025  â”‚
â”‚  Epoch                3    Train         0s  14%    approx_kl         0.022  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.225  â”‚
â”‚  Remainiâ€¦         2m 8s      Learn       0s  11%    importance        0.997  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.782  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               21.392    episode_length               79.417  â”‚
â”‚  x_position                  -12.047    x_velocity                  -57.621  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=78.74 (best=14.30@65536)
æ­¥æ•° 98,304: Reward=78.74, Best=21.39@98304, Sharpness=2.3586, Î»_max=-116.5452
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.418  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.187  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                4    Train         0s  14%    approx_kl         0.020  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.217  â”‚
â”‚  Remainiâ€¦        1m 55s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.817  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               25.633    episode_length               86.188  â”‚
â”‚  x_position                  -13.453    x_velocity                  -60.115  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=99.74 (best=21.39@98304)
æ­¥æ•° 131,072: Reward=99.74, Best=25.63@131072, Sharpness=2.4432, Î»_max=-84.5587
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.399  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          11.211  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                5    Train         0s  14%    approx_kl         0.018  â”‚
â”‚  Uptime             44s      Forwaâ€¦      0s   2%    clipfrac          0.195  â”‚
â”‚  Remainiâ€¦        1m 41s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.838  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               23.323    episode_length               87.389  â”‚
â”‚  x_position                  -14.896    x_velocity                  -63.621  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-6.73 (best=25.63@131072)
æ­¥æ•° 163,840: Reward=-6.73, Best=25.63@131072, Sharpness=2.3658, Î»_max=-89.6585
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.350  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          11.237  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                6    Train         1s  14%    approx_kl         0.015  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   2%    clipfrac          0.167  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.840  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               21.073    episode_length               87.040  â”‚
â”‚  x_position                  -17.457    x_velocity                  -65.524  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-8.76 (best=25.63@131072)
æ­¥æ•° 196,608: Reward=-8.76, Best=25.63@131072, Sharpness=2.4394, Î»_max=-79.9334
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.323  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.265  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         1s  11%    approx_kl         0.013  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.154  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       0s   7%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.841  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               26.074    episode_length               90.107  â”‚
â”‚  x_position                  -15.168    x_velocity                  -63.576  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-11.32 (best=25.63@131072)
æ­¥æ•° 229,376: Reward=-11.32, Best=26.07@229376, Sharpness=2.6444, Î»_max=-76.7020
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.324  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.289  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                8    Train         1s  11%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 13s      Forwaâ€¦      0s   2%    clipfrac          0.127  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.864  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               20.395    episode_length               90.358  â”‚
â”‚  x_position                  -18.133    x_velocity                  -69.504  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-12.66 (best=26.07@229376)
æ­¥æ•° 262,144: Reward=-12.66, Best=26.07@229376, Sharpness=2.4158, Î»_max=-72.1784
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.332  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.310  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                9    Train         1s  11%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 23s      Forwaâ€¦      0s   2%    clipfrac          0.133  â”‚
â”‚  Remainiâ€¦         1m 1s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.857  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               26.170    episode_length               92.650  â”‚
â”‚  x_position                  -19.670    x_velocity                  -66.009  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-9.56 (best=26.07@229376)
æ­¥æ•° 294,912: Reward=-9.56, Best=26.17@294912, Sharpness=2.4392, Î»_max=-95.7909
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.314  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.324  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               10    Train         1s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 33s      Forwaâ€¦      0s   2%    clipfrac          0.096  â”‚
â”‚  Remainiâ€¦           52s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.848  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               26.095    episode_length               93.735  â”‚
â”‚  x_position                  -18.930    x_velocity                  -67.164  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-10.80 (best=26.17@294912)
æ­¥æ•° 327,680: Reward=-10.80, Best=26.17@294912, Sharpness=2.3598, Î»_max=-84.6366
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.024  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.337  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.335  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 43s      Forwaâ€¦      0s   2%    clipfrac          0.071  â”‚
â”‚  Remainiâ€¦           42s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.844  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               23.836    episode_length               92.458  â”‚
â”‚  x_position                  -19.430    x_velocity                  -68.152  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-13.17 (best=26.17@294912)
æ­¥æ•° 360,448: Reward=-13.17, Best=26.17@294912, Sharpness=2.3734, Î»_max=-71.9222
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.005  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.349  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.342  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         1s  14%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 53s      Forwaâ€¦      0s   2%    clipfrac          0.055  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.828  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               48.151    episode_length              107.926  â”‚
â”‚  x_position                  -15.472    x_velocity                  -59.226  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-14.60 (best=26.17@294912)
æ­¥æ•° 393,216: Reward=-14.60, Best=48.15@393216, Sharpness=2.3593, Î»_max=-80.7928
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.013  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.351  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.349  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  14%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 2s      Forwaâ€¦      0s   2%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               39.131    episode_length              101.997  â”‚
â”‚  x_position                  -16.586    x_velocity                  -62.346  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-9.88 (best=48.15@393216)
æ­¥æ•° 425,984: Reward=-9.88, Best=48.15@393216, Sharpness=2.3743, Î»_max=-93.4489
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 5.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.020  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.380  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.352  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   2%    clipfrac          0.012  â”‚
â”‚  Remainiâ€¦           11s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.803  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               40.820    episode_length              105.334  â”‚
â”‚  x_position                  -20.142    x_velocity                  -63.979  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-10.65 (best=48.15@393216)
æ­¥æ•° 458,752: Reward=-10.65, Best=48.15@393216, Sharpness=2.2099, Î»_max=-70.6151
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 6.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.391  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.353  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  14%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   2%    clipfrac          0.003  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.774  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               44.668    episode_length              109.707  â”‚
â”‚  x_position                  -18.488    x_velocity                  -64.482  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-12.17 (best=48.15@393216)
æ­¥æ•° 491,520: Reward=-12.17, Best=48.15@393216, Sharpness=2.5003, Î»_max=-103.6677
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.020  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.441  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.353  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.722  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               52.747    episode_length              116.522  â”‚
â”‚  x_position                  -22.689    x_velocity                  -63.182  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-11.70 (best=48.15@393216)
æ­¥æ•° 524,288: Reward=-11.70, Best=52.75@524288, Sharpness=2.4671, Î»_max=-80.7559

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 14_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_14/vec_stats.npz
[J&R] base_task=14, new_task=14_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_14/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.016  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        3.031  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          21.864  â”‚
â”‚  SPS               8.2K      Misc        0s   0%    old_approx_kl     0.061  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.059  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.363  â”‚
â”‚  Remainiâ€¦           56s      Learn       0s   0%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.005  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.035    episode_length               16.291  â”‚
â”‚  x_position                   -1.566    x_velocity                  -26.233  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-9.18 (best=N/A)
æ­¥æ•° 32,768: Reward=-9.18, Best=-10.04@32768, Sharpness=3.0118, Î»_max=30.7823
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.1%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        1.148  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          21.911  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                2    Train         0s  14%    approx_kl         0.027  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.229  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.070  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.342    episode_length               18.358  â”‚
â”‚  x_position                   -1.959    x_velocity                  -29.596  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-14.30 (best=-10.04@32768)
æ­¥æ•° 65,536: Reward=-14.30, Best=-10.04@32768, Sharpness=2.4066, Î»_max=-14.4800
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.729  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          21.964  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                3    Train         0s  14%    approx_kl         0.017  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.169  â”‚
â”‚  Remainiâ€¦         2m 4s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.007  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.837    episode_length               18.302  â”‚
â”‚  x_position                   -1.920    x_velocity                  -29.035  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-16.26 (best=-10.04@32768)
æ­¥æ•° 98,304: Reward=-16.26, Best=-10.04@32768, Sharpness=2.1959, Î»_max=13.8086
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.593  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          22.001  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                4    Train         0s  14%    approx_kl         0.018  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.177  â”‚
â”‚  Remainiâ€¦        1m 49s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.034  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.047    episode_length               18.429  â”‚
â”‚  x_position                   -1.923    x_velocity                  -28.371  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-15.04 (best=-10.04@32768)
æ­¥æ•° 131,072: Reward=-15.04, Best=-10.04@32768, Sharpness=2.0324, Î»_max=6.1062
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.498  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          22.037  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                5    Train         0s  14%    approx_kl         0.016  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.161  â”‚
â”‚  Remainiâ€¦        1m 37s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.037  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.293    episode_length               18.185  â”‚
â”‚  x_position                   -1.839    x_velocity                  -27.375  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-12.77 (best=-10.04@32768)
æ­¥æ•° 163,840: Reward=-12.77, Best=-9.29@163840, Sharpness=2.3813, Î»_max=-10.2520
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.463  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          22.069  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                6    Train         1s  14%    approx_kl         0.013  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   2%    clipfrac          0.141  â”‚
â”‚  Remainiâ€¦        1m 27s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.069  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.149    episode_length               18.007  â”‚
â”‚  x_position                   -1.738    x_velocity                  -26.055  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-10.51 (best=-9.29@163840)
æ­¥æ•° 196,608: Reward=-10.51, Best=-8.15@196608, Sharpness=1.9240, Î»_max=12.9341
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.436  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          22.095  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         1s  15%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.124  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       0s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.038  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.149    episode_length               17.915  â”‚
â”‚  x_position                   -1.664    x_velocity                  -24.962  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-7.70 (best=-8.15@196608)
æ­¥æ•° 229,376: Reward=-7.70, Best=-7.15@229376, Sharpness=1.9561, Î»_max=11.8881
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.404  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          22.118  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                8    Train         1s  15%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.106  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.108  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.380    episode_length               17.937  â”‚
â”‚  x_position                   -1.632    x_velocity                  -24.216  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-5.85 (best=-7.15@229376)
æ­¥æ•° 262,144: Reward=-5.85, Best=-6.38@262144, Sharpness=1.9517, Î»_max=-7.4945
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.395  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          22.143  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                9    Train         1s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.083  â”‚
â”‚  Remainiâ€¦           57s      Learn       0s  12%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.074  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.607    episode_length               17.450  â”‚
â”‚  x_position                   -1.523    x_velocity                  -22.959  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-5.08 (best=-6.38@262144)
æ­¥æ•° 294,912: Reward=-5.08, Best=-5.61@294912, Sharpness=2.4125, Î»_max=2.7187
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 5.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.393  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          22.165  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch               10    Train         1s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   2%    clipfrac          0.080  â”‚
â”‚  Remainiâ€¦           48s      Learn       0s  12%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.094  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.194    episode_length               18.276  â”‚
â”‚  x_position                   -1.641    x_velocity                  -23.366  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-2.86 (best=-5.61@294912)
æ­¥æ•° 327,680: Reward=-2.86, Best=-5.19@327680, Sharpness=2.0813, Î»_max=1.9283
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 5.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.388  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          22.181  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 40s      Forwaâ€¦      0s   2%    clipfrac          0.053  â”‚
â”‚  Remainiâ€¦           42s      Learn       1s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.105  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.395    episode_length               17.848  â”‚
â”‚  x_position                   -1.506    x_velocity                  -22.142  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-1.45 (best=-5.19@327680)
æ­¥æ•° 360,448: Reward=-1.45, Best=-4.39@360448, Sharpness=2.2699, Î»_max=15.8629
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  75%    value_loss        0.388  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          22.187  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  15%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   3%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.094  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.159    episode_length               18.207  â”‚
â”‚  x_position                   -1.599    x_velocity                  -22.263  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=5.54 (best=-4.39@360448)
æ­¥æ•° 393,216: Reward=5.54, Best=-4.16@393216, Sharpness=2.1350, Î»_max=13.5937
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         9s  75%    value_loss        0.392  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          22.191  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         1s  15%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   3%    clipfrac          0.030  â”‚
â”‚  Remainiâ€¦           22s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.076  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.756    episode_length               18.292  â”‚
â”‚  x_position                   -1.553    x_velocity                  -21.944  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=0.05 (best=-4.16@393216)
æ­¥æ•° 425,984: Reward=0.05, Best=-3.76@425984, Sharpness=2.1190, Î»_max=13.7789
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         9s  75%    value_loss        0.396  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          22.194  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  15%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   3%    clipfrac          0.012  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.101  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.895    episode_length               18.922  â”‚
â”‚  x_position                   -1.679    x_velocity                  -22.711  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-5.35 (best=-3.76@425984)
æ­¥æ•° 458,752: Reward=-5.35, Best=-3.76@425984, Sharpness=1.7812, Î»_max=14.7173
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env         9s  75%    value_loss        0.414  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          22.195  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   3%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.052  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.664    episode_length               19.098  â”‚
â”‚  x_position                   -1.703    x_velocity                  -22.654  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-13.70 (best=-3.76@425984)
æ­¥æ•° 491,520: Reward=-13.70, Best=-3.66@491520, Sharpness=2.4720, Î»_max=14.5909
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        12s  75%    value_loss        0.412  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          22.195  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 30s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.030  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.549    episode_length               18.882  â”‚
â”‚  x_position                   -1.664    x_velocity                  -22.325  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-11.10 (best=-3.66@491520)
æ­¥æ•° 524,288: Reward=-11.10, Best=-3.55@524288, Sharpness=2.5618, Î»_max=17.8521

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 14_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 14 step sweep å®Œæˆã€‚
