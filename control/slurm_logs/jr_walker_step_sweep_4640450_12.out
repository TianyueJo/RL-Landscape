==========================================
[Jump & Retrain] Walker2d task 12 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 11:07:30 EST 2025
èŠ‚ç‚¹: node11
==========================================
[Base] task=12, env=Walker2d-v4, best_model=final_model.pt, best_reward=2623.28, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_12/vec_stats.npz
[J&R] base_task=12, new_task=12_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_12/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.8%  DRAM: 0.4%   VRAM: 1.1%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.107  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.429  â”‚
â”‚  SPS               4.1K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.021  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.249  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.344  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.804    episode_length               54.750  â”‚
â”‚  x_position                   -1.522    x_velocity                  -24.668  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-28.08 (best=N/A)
æ­¥æ•° 32,768: Reward=-28.08, Best=29.80@32768, Sharpness=1.1868, Î»_max=-32.3005
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 1.3%  â”‚
â”‚                                 11.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  66%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.557  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.459  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.023  â”‚
â”‚  Epoch                2    Train         1s  33%    approx_kl         0.022  â”‚
â”‚  Uptime             18s      Forwaâ€¦      0s   7%    clipfrac          0.244  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.837  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.484    episode_length               98.805  â”‚
â”‚  x_position                  -24.333    x_velocity                 -100.781  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-40.01 (best=29.80@32768)
æ­¥æ•° 65,536: Reward=-40.01, Best=29.80@32768, Sharpness=1.1989, Î»_max=-30.2398
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  66%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.407  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.485  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         1s  33%    approx_kl         0.016  â”‚
â”‚  Uptime             27s      Forwaâ€¦      0s   7%    clipfrac          0.192  â”‚
â”‚  Remainiâ€¦        1m 57s      Learn       0s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.879  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.107    episode_length              141.346  â”‚
â”‚  x_position                  -42.455    x_velocity                 -130.515  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-5.17 (best=29.80@32768)
æ­¥æ•° 98,304: Reward=-5.17, Best=29.80@32768, Sharpness=1.1912, Î»_max=-28.8755
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 5.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  66%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.405  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.511  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                4    Train         1s  33%    approx_kl         0.014  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   7%    clipfrac          0.173  â”‚
â”‚  Remainiâ€¦        1m 48s      Learn       0s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.887  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                2.429    episode_length              140.455  â”‚
â”‚  x_position                  -49.041    x_velocity                 -137.305  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-1.48 (best=29.80@32768)
æ­¥æ•° 131,072: Reward=-1.48, Best=29.80@32768, Sharpness=1.1978, Î»_max=-29.7378
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  66%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         2s  56%    value_loss        0.295  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.538  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         1s  33%    approx_kl         0.011  â”‚
â”‚  Uptime             47s      Forwaâ€¦      0s   7%    clipfrac          0.138  â”‚
â”‚  Remainiâ€¦        1m 44s      Learn       0s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.813    episode_length              139.568  â”‚
â”‚  x_position                  -50.396    x_velocity                 -139.662  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-6.72 (best=29.80@32768)
æ­¥æ•° 163,840: Reward=-6.72, Best=29.80@32768, Sharpness=1.2396, Î»_max=-24.4761
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  66%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         5s  56%    value_loss        0.249  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.560  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         2s  33%    approx_kl         0.009  â”‚
â”‚  Uptime             57s      Forwaâ€¦      0s   7%    clipfrac          0.120  â”‚
â”‚  Remainiâ€¦        1m 32s      Learn       1s  14%    importance        1.002  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                6.613    episode_length              141.874  â”‚
â”‚  x_position                  -47.475    x_velocity                 -134.530  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-34.15 (best=29.80@32768)
æ­¥æ•° 196,608: Reward=-34.15, Best=29.80@32768, Sharpness=1.2273, Î»_max=-25.2052
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         5s  73%    value_loss        0.210  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.576  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  17%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 7s      Forwaâ€¦      0s   2%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                4.060    episode_length              149.029  â”‚
â”‚  x_position                  -53.606    x_velocity                 -144.204  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-21.64 (best=29.80@32768)
æ­¥æ•° 229,376: Reward=-21.64, Best=29.80@32768, Sharpness=1.2622, Î»_max=-22.6150
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 5.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         5s  73%    value_loss        0.195  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.590  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         2s  17%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 16s      Forwaâ€¦      0s   2%    clipfrac          0.080  â”‚
â”‚  Remainiâ€¦         1m 7s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.882  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.064    episode_length              163.989  â”‚
â”‚  x_position                  -54.055    x_velocity                 -141.087  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-33.02 (best=29.80@32768)
æ­¥æ•° 262,144: Reward=-33.02, Best=29.80@32768, Sharpness=1.2080, Î»_max=-21.5203
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         5s  73%    value_loss        0.175  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.599  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  17%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 26s      Forwaâ€¦      0s   2%    clipfrac          0.088  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       1s  14%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.485    episode_length              168.042  â”‚
â”‚  x_position                  -53.669    x_velocity                 -136.696  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-9.95 (best=29.80@32768)
æ­¥æ•° 294,912: Reward=-9.95, Best=30.48@294912, Sharpness=1.2495, Î»_max=-22.7164
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         5s  73%    value_loss        0.180  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.607  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         2s  17%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 36s      Forwaâ€¦      0s   2%    clipfrac          0.071  â”‚
â”‚  Remainiâ€¦           51s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               32.849    episode_length              187.309  â”‚
â”‚  x_position                  -64.146    x_velocity                 -153.500  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-9.84 (best=30.48@294912)
æ­¥æ•° 327,680: Reward=-9.84, Best=32.85@327680, Sharpness=1.2142, Î»_max=-19.8616
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.7%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         8s  73%    value_loss        0.184  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.614  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         3s  17%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 46s      Forwaâ€¦      0s   2%    clipfrac          0.049  â”‚
â”‚  Remainiâ€¦           41s      Learn       1s  14%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               39.801    episode_length              196.571  â”‚
â”‚  x_position                  -64.737    x_velocity                 -155.766  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-43.79 (best=32.85@327680)
æ­¥æ•° 360,448: Reward=-43.79, Best=39.80@360448, Sharpness=1.2350, Î»_max=-18.4626
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.189  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.619  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  15%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 56s      Forwaâ€¦      0s   2%    clipfrac          0.041  â”‚
â”‚  Remainiâ€¦           34s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               64.921    episode_length              212.080  â”‚
â”‚  x_position                  -62.275    x_velocity                 -146.073  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-35.30 (best=39.80@360448)
æ­¥æ•° 393,216: Reward=-35.30, Best=64.92@393216, Sharpness=1.2287, Î»_max=-23.6543
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.193  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.621  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  15%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 6s      Forwaâ€¦      0s   2%    clipfrac          0.026  â”‚
â”‚  Remainiâ€¦           22s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               53.807    episode_length              217.704  â”‚
â”‚  x_position                  -81.755    x_velocity                 -162.786  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-38.79 (best=64.92@393216)
æ­¥æ•° 425,984: Reward=-38.79, Best=64.92@393216, Sharpness=1.2569, Î»_max=-15.0598
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.205  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.623  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         3s  15%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 16s      Forwaâ€¦      0s   2%    clipfrac          0.012  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.872  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              106.178    episode_length              242.988  â”‚
â”‚  x_position                  -54.130    x_velocity                 -135.566  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-9.30 (best=64.92@393216)
æ­¥æ•° 458,752: Reward=-9.30, Best=106.18@458752, Sharpness=1.2114, Î»_max=-18.2673
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.219  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.623  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 25s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.861  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              100.410    episode_length              247.427  â”‚
â”‚  x_position                  -81.655    x_velocity                 -145.752  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-32.65 (best=106.18@458752)
æ­¥æ•° 491,520: Reward=-32.65, Best=106.18@458752, Sharpness=1.2381, Î»_max=-21.3112
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env        11s  76%    value_loss        0.232  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.623  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 35s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.822  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              137.496    episode_length              298.826  â”‚
â”‚  x_position                 -104.685    x_velocity                 -159.803  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-51.94 (best=106.18@458752)
æ­¥æ•° 524,288: Reward=-51.94, Best=137.50@524288, Sharpness=1.2144, Î»_max=-24.1786

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 12_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_12/vec_stats.npz
[J&R] base_task=12, new_task=12_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_12/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.156  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.342  â”‚
â”‚  SPS               8.1K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.022  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.254  â”‚
â”‚  Remainiâ€¦           57s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.286  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.305    episode_length               52.500  â”‚
â”‚  x_position                   -2.623    x_velocity                  -36.923  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=18.66 (best=N/A)
æ­¥æ•° 32,768: Reward=18.66, Best=15.30@32768, Sharpness=1.1893, Î»_max=-31.8401
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.5%  â”‚
â”‚                                 15.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.553  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.368  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.025  â”‚
â”‚  Epoch                2    Train         0s  14%    approx_kl         0.022  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.247  â”‚
â”‚  Remainiâ€¦        2m 12s      Learn       0s   7%    importance        0.997  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                3.262    episode_length              100.849  â”‚
â”‚  x_position                  -23.648    x_velocity                  -97.067  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-12.91 (best=15.30@32768)
æ­¥æ•° 65,536: Reward=-12.91, Best=15.30@32768, Sharpness=1.2050, Î»_max=-30.8120
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.364  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.392  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                3    Train         0s  14%    approx_kl         0.014  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.165  â”‚
â”‚  Remainiâ€¦         2m 5s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.883  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.281    episode_length              141.816  â”‚
â”‚  x_position                  -42.095    x_velocity                 -130.805  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-6.17 (best=15.30@32768)
æ­¥æ•° 98,304: Reward=-6.17, Best=15.30@32768, Sharpness=1.2379, Î»_max=-30.9742
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.391  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.414  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         0s  14%    approx_kl         0.013  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.161  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                7.783    episode_length              147.064  â”‚
â”‚  x_position                  -52.313    x_velocity                 -138.522  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-4.87 (best=15.30@32768)
æ­¥æ•° 131,072: Reward=-4.87, Best=15.30@32768, Sharpness=1.1911, Î»_max=-28.1746
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.313  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.439  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         0s  14%    approx_kl         0.011  â”‚
â”‚  Uptime             44s      Forwaâ€¦      0s   2%    clipfrac          0.139  â”‚
â”‚  Remainiâ€¦        1m 46s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.909  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               12.436    episode_length              161.386  â”‚
â”‚  x_position                  -58.906    x_velocity                 -148.119  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-6.88 (best=15.30@32768)
æ­¥æ•° 163,840: Reward=-6.88, Best=15.30@32768, Sharpness=1.2554, Î»_max=-26.8282
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.269  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.457  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         1s  14%    approx_kl         0.010  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   2%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.129    episode_length              157.954  â”‚
â”‚  x_position                  -52.233    x_velocity                 -142.012  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-12.21 (best=15.30@32768)
æ­¥æ•° 196,608: Reward=-12.21, Best=15.30@32768, Sharpness=1.2570, Î»_max=-15.7518
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.215  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.468  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         1s  13%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 4s      Forwaâ€¦      0s   2%    clipfrac          0.103  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.062    episode_length              151.625  â”‚
â”‚  x_position                  -53.805    x_velocity                 -142.781  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-25.76 (best=15.30@32768)
æ­¥æ•° 229,376: Reward=-25.76, Best=15.30@32768, Sharpness=1.1793, Î»_max=-20.2780
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.203  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.484  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         1s  13%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 15s      Forwaâ€¦      0s   2%    clipfrac          0.101  â”‚
â”‚  Remainiâ€¦        1m 13s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               31.874    episode_length              171.846  â”‚
â”‚  x_position                  -59.889    x_velocity                 -139.085  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-25.02 (best=15.30@32768)
æ­¥æ•° 262,144: Reward=-25.02, Best=31.87@262144, Sharpness=1.1980, Î»_max=-18.4096
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.188  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.495  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 24s      Forwaâ€¦      0s   2%    clipfrac          0.091  â”‚
â”‚  Remainiâ€¦           59s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               41.056    episode_length              193.800  â”‚
â”‚  x_position                  -63.339    x_velocity                 -151.748  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-24.20 (best=31.87@262144)
æ­¥æ•° 294,912: Reward=-24.20, Best=41.06@294912, Sharpness=1.1725, Î»_max=-24.7244
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.179  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.503  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 34s      Forwaâ€¦      0s   2%    clipfrac          0.063  â”‚
â”‚  Remainiâ€¦           50s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               32.130    episode_length              193.938  â”‚
â”‚  x_position                  -75.773    x_velocity                 -160.810  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-33.95 (best=41.06@294912)
æ­¥æ•° 327,680: Reward=-33.95, Best=41.06@294912, Sharpness=1.2225, Î»_max=-23.1219
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         8s  77%    value_loss        0.176  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.507  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 43s      Forwaâ€¦      0s   2%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦           40s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               70.321    episode_length              226.677  â”‚
â”‚  x_position                  -70.814    x_velocity                 -155.192  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-3.04 (best=41.06@294912)
æ­¥æ•° 360,448: Reward=-3.04, Best=70.32@360448, Sharpness=1.3616, Î»_max=-17.3213
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.188  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.514  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  12%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 53s      Forwaâ€¦      0s   2%    clipfrac          0.043  â”‚
â”‚  Remainiâ€¦           30s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               80.010    episode_length              234.351  â”‚
â”‚  x_position                  -80.453    x_velocity                 -153.135  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-36.74 (best=70.32@360448)
æ­¥æ•° 393,216: Reward=-36.74, Best=80.01@393216, Sharpness=1.1732, Î»_max=-20.4957
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.197  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.520  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  12%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 3s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           22s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.883  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              113.328    episode_length              271.844  â”‚
â”‚  x_position                  -84.340    x_velocity                 -157.122  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-20.53 (best=80.01@393216)
æ­¥æ•° 425,984: Reward=-20.53, Best=113.33@425984, Sharpness=1.2126, Î»_max=-11.4733
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.188  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.523  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  12%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 12s      Forwaâ€¦      0s   2%    clipfrac          0.020  â”‚
â”‚  Remainiâ€¦           11s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              157.048    episode_length              286.973  â”‚
â”‚  x_position                  -82.585    x_velocity                 -128.456  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-25.59 (best=113.33@425984)
æ­¥æ•° 458,752: Reward=-25.59, Best=157.05@458752, Sharpness=1.1716, Î»_max=-19.7344
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.224  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.523  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.841  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              158.947    episode_length              309.361  â”‚
â”‚  x_position                  -93.039    x_velocity                 -148.827  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-17.25 (best=157.05@458752)
æ­¥æ•° 491,520: Reward=-17.25, Best=158.95@491520, Sharpness=1.1903, Î»_max=-16.2878
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env        11s  80%    value_loss        0.229  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.524  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.816  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              198.244    episode_length              356.873  â”‚
â”‚  x_position                 -143.753    x_velocity                 -156.790  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-16.30 (best=158.95@491520)
æ­¥æ•° 524,288: Reward=-16.30, Best=198.24@524288, Sharpness=1.1753, Î»_max=-19.0896

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 12_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_12/vec_stats.npz
[J&R] base_task=12, new_task=12_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_12/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.7%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.118  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.082  â”‚
â”‚  SPS               7.4K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.023  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.260  â”‚
â”‚  Remainiâ€¦         1m 3s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.374  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.110    episode_length               51.700  â”‚
â”‚  x_position                   -3.532    x_velocity                  -36.325  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-6.31 (best=N/A)
æ­¥æ•° 32,768: Reward=-6.31, Best=15.11@32768, Sharpness=1.2823, Î»_max=-38.4170
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.645  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.115  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                2    Train         0s  16%    approx_kl         0.020  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.222  â”‚
â”‚  Remainiâ€¦        2m 16s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.827  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                2.183    episode_length               94.838  â”‚
â”‚  x_position                  -20.600    x_velocity                  -92.171  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-9.62 (best=15.11@32768)
æ­¥æ•° 65,536: Reward=-9.62, Best=15.11@32768, Sharpness=1.2319, Î»_max=-37.3321
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.400  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.135  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                3    Train         0s  16%    approx_kl         0.016  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.189  â”‚
â”‚  Remainiâ€¦        1m 58s      Learn       0s   8%    importance        0.998  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               18.067    episode_length              131.479  â”‚
â”‚  x_position                  -34.772    x_velocity                 -112.741  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-18.49 (best=15.11@32768)
æ­¥æ•° 98,304: Reward=-18.49, Best=18.07@98304, Sharpness=1.2726, Î»_max=-34.2897
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.359  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.152  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                4    Train         0s  16%    approx_kl         0.013  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.164  â”‚
â”‚  Remainiâ€¦        1m 47s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               13.416    episode_length              124.848  â”‚
â”‚  x_position                  -35.736    x_velocity                 -110.794  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-12.34 (best=18.07@98304)
æ­¥æ•° 131,072: Reward=-12.34, Best=18.07@98304, Sharpness=1.2521, Î»_max=-29.0568
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.298  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.169  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                5    Train         0s  16%    approx_kl         0.012  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.148  â”‚
â”‚  Remainiâ€¦        1m 37s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.393    episode_length              140.395  â”‚
â”‚  x_position                  -40.007    x_velocity                 -115.284  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-3.93 (best=18.07@98304)
æ­¥æ•° 163,840: Reward=-3.93, Best=24.39@163840, Sharpness=1.3029, Î»_max=-35.2624
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.261  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.187  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         1s  16%    approx_kl         0.010  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   2%    clipfrac          0.129  â”‚
â”‚  Remainiâ€¦        1m 31s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               38.762    episode_length              154.954  â”‚
â”‚  x_position                  -39.424    x_velocity                 -115.403  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-2.59 (best=24.39@163840)
æ­¥æ•° 196,608: Reward=-2.59, Best=38.76@196608, Sharpness=1.2609, Î»_max=-25.3349
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         6s  74%    value_loss        0.231  â”‚
â”‚  Steps           229.4K      Copy        0s   3%    entropy          12.198  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         1s  15%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.113  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               39.399    episode_length              164.643  â”‚
â”‚  x_position                  -42.647    x_velocity                 -124.406  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-3.44 (best=38.76@196608)
æ­¥æ•° 229,376: Reward=-3.44, Best=39.40@229376, Sharpness=1.2750, Î»_max=-32.0344
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  74%    value_loss        0.211  â”‚
â”‚  Steps           262.1K      Copy        0s   3%    entropy          12.204  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         1s  15%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.101  â”‚
â”‚  Remainiâ€¦         1m 5s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.897  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               76.534    episode_length              189.706  â”‚
â”‚  x_position                  -36.306    x_velocity                 -112.208  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-3.07 (best=39.40@229376)
æ­¥æ•° 262,144: Reward=-3.07, Best=76.53@262144, Sharpness=1.3238, Î»_max=-17.6284
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  74%    value_loss        0.210  â”‚
â”‚  Steps           294.9K      Copy        0s   3%    entropy          12.212  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         1s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.080  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               80.083    episode_length              203.009  â”‚
â”‚  x_position                  -39.470    x_velocity                 -121.895  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-3.79 (best=76.53@262144)
æ­¥æ•° 294,912: Reward=-3.79, Best=80.08@294912, Sharpness=1.2529, Î»_max=-25.1795
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         6s  74%    value_loss        0.203  â”‚
â”‚  Steps           327.7K      Copy        0s   3%    entropy          12.222  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.062  â”‚
â”‚  Remainiâ€¦           52s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               89.930    episode_length              229.216  â”‚
â”‚  x_position                  -58.430    x_velocity                 -138.122  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-3.17 (best=80.08@294912)
æ­¥æ•° 327,680: Reward=-3.17, Best=89.93@327680, Sharpness=1.2670, Î»_max=-23.4885
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.000  â”‚
â”‚  Params          135.3K      Env         9s  74%    value_loss        0.183  â”‚
â”‚  Steps           360.4K      Copy        0s   3%    entropy          12.229  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.051  â”‚
â”‚  Remainiâ€¦           41s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              108.506    episode_length              257.816  â”‚
â”‚  x_position                  -66.246    x_velocity                 -148.001  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-7.31 (best=89.93@327680)
æ­¥æ•° 360,448: Reward=-7.31, Best=108.51@360448, Sharpness=1.2270, Î»_max=-28.3473
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  74%    value_loss        0.176  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.233  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         2s  17%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 51s      Forwaâ€¦      0s   2%    clipfrac          0.034  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              151.500    episode_length              288.220  â”‚
â”‚  x_position                  -65.455    x_velocity                 -135.252  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-5.08 (best=108.51@360448)
æ­¥æ•° 393,216: Reward=-5.08, Best=151.50@393216, Sharpness=1.2683, Î»_max=-24.6602
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 5.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         9s  74%    value_loss        0.185  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.237  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         2s  17%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.024  â”‚
â”‚  Remainiâ€¦           20s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.875  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              129.234    episode_length              283.253  â”‚
â”‚  x_position                  -75.783    x_velocity                 -152.578  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-5.50 (best=151.50@393216)
æ­¥æ•° 425,984: Reward=-5.50, Best=151.50@393216, Sharpness=1.2842, Î»_max=-21.3289
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         9s  74%    value_loss        0.182  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.238  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  17%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.017  â”‚
â”‚  Remainiâ€¦           11s      Learn       1s  14%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.860  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              203.970    episode_length              338.756  â”‚
â”‚  x_position                  -71.939    x_velocity                 -133.065  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-11.50 (best=151.50@393216)
æ­¥æ•° 458,752: Reward=-11.50, Best=203.97@458752, Sharpness=1.2515, Î»_max=-24.3597
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.000  â”‚
â”‚  Params          135.3K      Env         9s  74%    value_loss        0.213  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.239  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.814  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              219.865    episode_length              348.302  â”‚
â”‚  x_position                  -73.246    x_velocity                 -126.665  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-31.84 (best=203.97@458752)
æ­¥æ•° 491,520: Reward=-31.84, Best=219.87@491520, Sharpness=1.2136, Î»_max=-31.1212
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env        12s  74%    value_loss        0.207  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.239  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.801  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              177.421    episode_length              325.550  â”‚
â”‚  x_position                  -58.959    x_velocity                 -146.473  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-24.82 (best=219.87@491520)
æ­¥æ•° 524,288: Reward=-24.82, Best=219.87@491520, Sharpness=1.2256, Î»_max=-27.8233

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 12_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_12/vec_stats.npz
[J&R] base_task=12, new_task=12_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_12/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        2.026  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.245  â”‚
â”‚  SPS               7.6K      Misc        0s   0%    old_approx_kl     0.056  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.050  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.410  â”‚
â”‚  Remainiâ€¦         1m 1s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.429  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.220    episode_length               33.839  â”‚
â”‚  x_position                   -3.813    x_velocity                  -36.896  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-13.82 (best=N/A)
æ­¥æ•° 32,768: Reward=-13.82, Best=-3.22@32768, Sharpness=2.5229, Î»_max=-68.8491
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.940  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.270  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.028  â”‚
â”‚  Epoch                2    Train         0s  15%    approx_kl         0.029  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.293  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s  13%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.494  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.020    episode_length               54.508  â”‚
â”‚  x_position                  -10.204    x_velocity                  -57.262  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-17.91 (best=-3.22@32768)
æ­¥æ•° 65,536: Reward=-17.91, Best=-3.02@65536, Sharpness=2.7075, Î»_max=-50.4644
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.558  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.285  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.026  â”‚
â”‚  Epoch                3    Train         0s  15%    approx_kl         0.024  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.256  â”‚
â”‚  Remainiâ€¦        1m 56s      Learn       0s  13%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.505  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.896    episode_length               62.123  â”‚
â”‚  x_position                  -14.576    x_velocity                  -67.712  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-6.20 (best=-3.02@65536)
æ­¥æ•° 98,304: Reward=-6.20, Best=-3.02@65536, Sharpness=3.0491, Î»_max=-38.7859
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 5.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.398  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.310  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                4    Train         0s  15%    approx_kl         0.018  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.204  â”‚
â”‚  Remainiâ€¦        1m 44s      Learn       0s  13%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.504  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.284    episode_length               66.856  â”‚
â”‚  x_position                  -17.698    x_velocity                  -74.808  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-3.39 (best=-3.02@65536)
æ­¥æ•° 131,072: Reward=-3.39, Best=-3.02@65536, Sharpness=2.8705, Î»_max=-40.2422
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.283  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          11.334  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                5    Train         0s  15%    approx_kl         0.016  â”‚
â”‚  Uptime             42s      Forwaâ€¦      0s   2%    clipfrac          0.180  â”‚
â”‚  Remainiâ€¦        1m 36s      Learn       0s  13%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.573  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.624    episode_length               67.833  â”‚
â”‚  x_position                  -18.816    x_velocity                  -78.120  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-4.28 (best=-3.02@65536)
æ­¥æ•° 163,840: Reward=-4.28, Best=-3.02@65536, Sharpness=3.5821, Î»_max=-43.3116
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.242  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          11.363  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                6    Train         1s  15%    approx_kl         0.014  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.164  â”‚
â”‚  Remainiâ€¦        1m 30s      Learn       0s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.553  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.025    episode_length               68.640  â”‚
â”‚  x_position                  -18.971    x_velocity                  -78.324  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-5.55 (best=-3.02@65536)
æ­¥æ•° 196,608: Reward=-5.55, Best=-3.02@65536, Sharpness=2.8096, Î»_max=34.2533
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.202  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.401  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                7    Train         1s  13%    approx_kl         0.012  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.149  â”‚
â”‚  Remainiâ€¦        1m 19s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.518  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.408    episode_length               67.155  â”‚
â”‚  x_position                  -19.065    x_velocity                  -78.228  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-4.30 (best=-3.02@65536)
æ­¥æ•° 229,376: Reward=-4.30, Best=-3.02@65536, Sharpness=2.3693, Î»_max=49.8144
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.169  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.430  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         1s  13%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 11s      Forwaâ€¦      0s   2%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       0s   6%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.501  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.616    episode_length               66.907  â”‚
â”‚  x_position                  -18.926    x_velocity                  -77.189  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-5.04 (best=-3.02@65536)
æ­¥æ•° 262,144: Reward=-5.04, Best=-3.02@65536, Sharpness=2.4475, Î»_max=62.9632
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.169  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.451  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                9    Train         1s  13%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 22s      Forwaâ€¦      0s   2%    clipfrac          0.110  â”‚
â”‚  Remainiâ€¦         1m 4s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.548  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.601    episode_length               64.432  â”‚
â”‚  x_position                  -18.041    x_velocity                  -74.712  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-4.80 (best=-3.02@65536)
æ­¥æ•° 294,912: Reward=-4.80, Best=-3.02@65536, Sharpness=3.6096, Î»_max=-21.0061
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.172  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.464  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         1s  13%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.096  â”‚
â”‚  Remainiâ€¦           50s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.570  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.026    episode_length               65.162  â”‚
â”‚  x_position                  -17.967    x_velocity                  -74.862  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-4.08 (best=-3.02@65536)
æ­¥æ•° 327,680: Reward=-4.08, Best=-3.02@65536, Sharpness=4.6994, Î»_max=-25.3898
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.183  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.475  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         1s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.069  â”‚
â”‚  Remainiâ€¦           42s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.556  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.566    episode_length               64.832  â”‚
â”‚  x_position                  -17.902    x_velocity                  -75.074  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-7.63 (best=-3.02@65536)
æ­¥æ•° 360,448: Reward=-7.63, Best=-3.02@65536, Sharpness=3.2204, Î»_max=-17.8331
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.167  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.483  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         1s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 51s      Forwaâ€¦      0s   2%    clipfrac          0.059  â”‚
â”‚  Remainiâ€¦           31s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.550  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.673    episode_length               66.083  â”‚
â”‚  x_position                  -18.397    x_velocity                  -75.427  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-7.45 (best=-3.02@65536)
æ­¥æ•° 393,216: Reward=-7.45, Best=-3.02@65536, Sharpness=2.3855, Î»_max=49.7486
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.175  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.488  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         1s  13%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 1s      Forwaâ€¦      0s   2%    clipfrac          0.034  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.587  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.538    episode_length               65.177  â”‚
â”‚  x_position                  -18.394    x_velocity                  -74.389  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-5.65 (best=-3.02@65536)
æ­¥æ•° 425,984: Reward=-5.65, Best=-3.02@65536, Sharpness=2.3582, Î»_max=48.6778
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.174  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.491  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               14    Train         1s  13%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.572  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.779    episode_length               65.898  â”‚
â”‚  x_position                  -18.587    x_velocity                  -75.347  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-9.26 (best=-3.02@65536)
æ­¥æ•° 458,752: Reward=-9.26, Best=-3.02@65536, Sharpness=2.6687, Î»_max=-34.8851
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.193  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.493  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.546  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.121    episode_length               65.314  â”‚
â”‚  x_position                  -18.371    x_velocity                  -75.108  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-10.79 (best=-3.02@65536)
æ­¥æ•° 491,520: Reward=-10.79, Best=-3.02@65536, Sharpness=2.4210, Î»_max=53.0750
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.213  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.493  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 30s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.489  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.854    episode_length               65.773  â”‚
â”‚  x_position                  -18.530    x_velocity                  -75.298  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-13.21 (best=-3.02@65536)
æ­¥æ•° 524,288: Reward=-13.21, Best=-3.02@65536, Sharpness=2.4013, Î»_max=29.4168

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 12_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_12/vec_stats.npz
[J&R] base_task=12, new_task=12_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_12/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 5.5%  GPU: 0.0%  DRAM: 0.2%   VRAM: 0.8%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.2%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 19.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        3.391  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          22.309  â”‚
â”‚  SPS               7.0K      Misc        0s   0%    old_approx_kl     0.055  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.050  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.314  â”‚
â”‚  Remainiâ€¦         1m 6s      Learn       0s   0%    importance        0.996  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.017  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.807    episode_length               18.350  â”‚
â”‚  x_position                   -1.740    x_velocity                  -25.053  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-4.67 (best=N/A)
æ­¥æ•° 32,768: Reward=-4.67, Best=-6.81@32768, Sharpness=1.5711, Î»_max=6.1092
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        1.594  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          22.345  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.027  â”‚
â”‚  Epoch                2    Train         0s  15%    approx_kl         0.025  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.205  â”‚
â”‚  Remainiâ€¦         2m 9s      Learn       0s  12%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.110  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.428    episode_length               23.667  â”‚
â”‚  x_position                   -2.677    x_velocity                  -30.961  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-21.67 (best=-6.81@32768)
æ­¥æ•° 65,536: Reward=-21.67, Best=-6.81@32768, Sharpness=1.6385, Î»_max=3.2015
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        1.097  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          22.376  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                3    Train         0s  15%    approx_kl         0.019  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.169  â”‚
â”‚  Remainiâ€¦         2m 3s      Learn       0s  12%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.172  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.704    episode_length               25.770  â”‚
â”‚  x_position                   -3.076    x_velocity                  -32.328  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-19.20 (best=-6.81@32768)
æ­¥æ•° 98,304: Reward=-19.20, Best=-6.70@98304, Sharpness=1.7224, Î»_max=-13.0968
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.863  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          22.402  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                4    Train         0s  15%    approx_kl         0.016  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.154  â”‚
â”‚  Remainiâ€¦        1m 48s      Learn       0s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.134  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.327    episode_length               27.125  â”‚
â”‚  x_position                   -3.316    x_velocity                  -33.298  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-19.33 (best=-6.70@98304)
æ­¥æ•° 131,072: Reward=-19.33, Best=-6.33@131072, Sharpness=1.5181, Î»_max=-13.3865
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.737  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          22.434  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                5    Train         0s  15%    approx_kl         0.013  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.136  â”‚
â”‚  Remainiâ€¦        1m 37s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.155  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.988    episode_length               30.203  â”‚
â”‚  x_position                   -4.026    x_velocity                  -36.020  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-18.27 (best=-6.33@131072)
æ­¥æ•° 163,840: Reward=-18.27, Best=-5.99@163840, Sharpness=1.3058, Î»_max=-13.2621
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.667  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          22.463  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                6    Train         1s  15%    approx_kl         0.013  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   2%    clipfrac          0.130  â”‚
â”‚  Remainiâ€¦        1m 32s      Learn       1s  12%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.120  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.449    episode_length               31.348  â”‚
â”‚  x_position                   -4.178    x_velocity                  -36.619  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-22.15 (best=-5.99@163840)
æ­¥æ•° 196,608: Reward=-22.15, Best=-5.45@196608, Sharpness=1.6420, Î»_max=-14.5913
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.627  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          22.488  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         1s  15%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.107  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.091  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.892    episode_length               32.746  â”‚
â”‚  x_position                   -4.563    x_velocity                  -37.452  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-17.57 (best=-5.45@196608)
æ­¥æ•° 229,376: Reward=-17.57, Best=-4.89@229376, Sharpness=1.8551, Î»_max=-15.3470
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.584  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          22.510  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         1s  15%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 13s      Forwaâ€¦      0s   2%    clipfrac          0.086  â”‚
â”‚  Remainiâ€¦         1m 8s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.070  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.598    episode_length               33.438  â”‚
â”‚  x_position                   -4.597    x_velocity                  -37.846  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-16.53 (best=-4.89@229376)
æ­¥æ•° 262,144: Reward=-16.53, Best=-4.60@262144, Sharpness=1.9660, Î»_max=-14.3564
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.584  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          22.529  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                9    Train         1s  15%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 23s      Forwaâ€¦      0s   2%    clipfrac          0.084  â”‚
â”‚  Remainiâ€¦         1m 4s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.072  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.363    episode_length               35.112  â”‚
â”‚  x_position                   -4.955    x_velocity                  -39.276  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-18.68 (best=-4.60@262144)
æ­¥æ•° 294,912: Reward=-18.68, Best=-4.36@294912, Sharpness=1.5139, Î»_max=-14.9820
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.556  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          22.546  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 33s      Forwaâ€¦      0s   2%    clipfrac          0.052  â”‚
â”‚  Remainiâ€¦           52s      Learn       1s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.033  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.103    episode_length               36.626  â”‚
â”‚  x_position                   -5.393    x_velocity                  -40.521  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-19.79 (best=-4.36@294912)
æ­¥æ•° 327,680: Reward=-19.79, Best=-4.10@327680, Sharpness=1.4257, Î»_max=-13.2365
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.532  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          22.557  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  15%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 43s      Forwaâ€¦      0s   2%    clipfrac          0.049  â”‚
â”‚  Remainiâ€¦           42s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.056  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.721    episode_length               37.894  â”‚
â”‚  x_position                   -5.729    x_velocity                  -41.400  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-18.49 (best=-4.10@327680)
æ­¥æ•° 360,448: Reward=-18.49, Best=-3.72@360448, Sharpness=1.7251, Î»_max=-11.2852
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.564  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          22.568  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  11%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 52s      Forwaâ€¦      0s   2%    clipfrac          0.027  â”‚
â”‚  Remainiâ€¦           29s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.014  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.877    episode_length               37.448  â”‚
â”‚  x_position                   -5.647    x_velocity                  -41.113  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-17.27 (best=-3.72@360448)
æ­¥æ•° 393,216: Reward=-17.27, Best=-3.72@360448, Sharpness=1.6933, Î»_max=-12.1926
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.563  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          22.575  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  11%    approx_kl         0.001  â”‚
â”‚  Uptime           2m 2s      Forwaâ€¦      0s   2%    clipfrac          0.013  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.037  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.123    episode_length               38.980  â”‚
â”‚  x_position                   -6.155    x_velocity                  -42.882  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-10.03 (best=-3.72@360448)
æ­¥æ•° 425,984: Reward=-10.03, Best=-3.72@360448, Sharpness=2.0328, Î»_max=-13.6390
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.005  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.576  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          22.578  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               14    Train         1s  11%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   2%    clipfrac          0.004  â”‚
â”‚  Remainiâ€¦           11s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.007  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.213    episode_length               38.092  â”‚
â”‚  x_position                   -5.785    x_velocity                  -41.089  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-14.47 (best=-3.72@360448)
æ­¥æ•° 458,752: Reward=-14.47, Best=-3.21@458752, Sharpness=2.3918, Î»_max=-15.3560
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.564  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          22.580  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  11%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.091  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.629    episode_length               39.039  â”‚
â”‚  x_position                   -5.993    x_velocity                  -41.446  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-15.40 (best=-3.21@458752)
æ­¥æ•° 491,520: Reward=-15.40, Best=-2.63@491520, Sharpness=1.7312, Î»_max=-8.9802
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.579  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          22.580  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  11%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 30s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.095  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.294    episode_length               38.367  â”‚
â”‚  x_position                   -6.022    x_velocity                  -42.443  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-14.99 (best=-2.63@491520)
æ­¥æ•° 524,288: Reward=-14.99, Best=-2.63@491520, Sharpness=1.7138, Î»_max=0.7806

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 12_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 12 step sweep å®Œæˆã€‚
