==========================================
[Jump & Retrain] Walker2d task 0 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 10:54:03 EST 2025
èŠ‚ç‚¹: node1
==========================================
[Base] task=0, env=Walker2d-v4, best_model=final_model.pt, best_reward=2012.08, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_0/vec_stats.npz
[J&R] base_task=0, new_task=0_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_0/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 0.3%  DRAM: 0.2%   VRAM: 2.3%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.266  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.311  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.028  â”‚
â”‚  Epoch                1    Train         2s   0%    approx_kl         0.023  â”‚
â”‚  Uptime             12s      Forwaâ€¦      0s   0%    clipfrac          0.255  â”‚
â”‚  Remainiâ€¦        2m 53s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.390  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                4.370    episode_length               51.444  â”‚
â”‚  x_position                   -4.958    x_velocity                  -46.810  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=89.98 (best=N/A)
æ­¥æ•° 32,768: Reward=89.98, Best=4.37@32768, Sharpness=1.1328, Î»_max=-27.9901
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.2%   VRAM: 3.0%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.579  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.334  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                2    Train         2s  23%    approx_kl         0.018  â”‚
â”‚  Uptime             28s      Forwaâ€¦      0s   4%    clipfrac          0.198  â”‚
â”‚  Remainiâ€¦        3m 33s      Learn       0s   5%    importance        0.998  â”‚
â”‚                              Copy        0s   6%    explained_varâ€¦    0.855  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.056    episode_length               92.618  â”‚
â”‚  x_position                  -10.697    x_velocity                  -62.072  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=80.66 (best=4.37@32768)
æ­¥æ•° 65,536: Reward=80.66, Best=30.06@65536, Sharpness=1.1455, Î»_max=-26.9983
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.8%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.338  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.361  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         2s  23%    approx_kl         0.013  â”‚
â”‚  Uptime             46s      Forwaâ€¦      0s   4%    clipfrac          0.151  â”‚
â”‚  Remainiâ€¦        3m 40s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   6%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               69.489    episode_length              142.613  â”‚
â”‚  x_position                  -17.862    x_velocity                  -72.367  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=227.32 (best=30.06@65536)
æ­¥æ•° 98,304: Reward=227.32, Best=69.49@98304, Sharpness=1.1535, Î»_max=-17.1870
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.299  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.391  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                4    Train         2s  23%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 1s      Forwaâ€¦      0s   4%    clipfrac          0.137  â”‚
â”‚  Remainiâ€¦        2m 53s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   6%    explained_varâ€¦    0.917  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               91.304    episode_length              167.084  â”‚
â”‚  x_position                  -19.005    x_velocity                  -74.889  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=304.99 (best=69.49@98304)
æ­¥æ•° 131,072: Reward=304.99, Best=91.30@131072, Sharpness=1.1583, Î»_max=-24.9504
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.6%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         5s  67%    value_loss        0.234  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.413  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         2s  23%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 20s      Forwaâ€¦      0s   4%    clipfrac          0.124  â”‚
â”‚  Remainiâ€¦         3m 6s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   6%    explained_varâ€¦    0.920  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              109.757    episode_length              184.177  â”‚
â”‚  x_position                  -13.355    x_velocity                  -73.437  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=175.00 (best=91.30@131072)
æ­¥æ•° 163,840: Reward=175.00, Best=109.76@163840, Sharpness=1.1682, Î»_max=-27.2618
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.5%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 17.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        11s  67%    value_loss        0.190  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.435  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         2s  23%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   4%    clipfrac          0.120  â”‚
â”‚  Remainiâ€¦        2m 25s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   6%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              128.922    episode_length              205.100  â”‚
â”‚  x_position                  -15.796    x_velocity                  -75.082  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=164.12 (best=109.76@163840)
æ­¥æ•° 196,608: Reward=164.12, Best=128.92@196608, Sharpness=1.1819, Î»_max=-28.3816
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env        11s  83%    value_loss        0.157  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          12.453  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         2s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 52s      Forwaâ€¦      0s   1%    clipfrac          0.102  â”‚
â”‚  Remainiâ€¦        2m 14s      Learn       1s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.927  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              161.568    episode_length              250.239  â”‚
â”‚  x_position                  -21.041    x_velocity                  -87.341  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=126.42 (best=128.92@196608)
æ­¥æ•° 229,376: Reward=126.42, Best=161.57@229376, Sharpness=1.1923, Î»_max=-26.5271
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.3%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        11s  83%    value_loss        0.141  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          12.465  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         2s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   1%    clipfrac          0.090  â”‚
â”‚  Remainiâ€¦        2m 19s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.922  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              157.487    episode_length              236.876  â”‚
â”‚  x_position                  -14.123    x_velocity                  -78.129  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=138.74 (best=161.57@229376)
æ­¥æ•° 262,144: Reward=138.74, Best=161.57@229376, Sharpness=1.1850, Î»_max=-27.7676
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        11s  83%    value_loss        0.121  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          12.476  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   1%    clipfrac          0.088  â”‚
â”‚  Remainiâ€¦        1m 54s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.928  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              189.190    episode_length              256.906  â”‚
â”‚  x_position                   -1.928    x_velocity                  -66.351  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=135.28 (best=161.57@229376)
æ­¥æ•° 294,912: Reward=135.28, Best=189.19@294912, Sharpness=1.3092, Î»_max=-16.3516
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.2%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        11s  83%    value_loss        0.114  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          12.485  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         2s  11%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 46s      Forwaâ€¦      0s   1%    clipfrac          0.065  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.926  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              192.215    episode_length              259.395  â”‚
â”‚  x_position                   -1.235    x_velocity                  -65.803  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=143.93 (best=189.19@294912)
æ­¥æ•° 327,680: Reward=143.93, Best=192.21@327680, Sharpness=1.1501, Î»_max=-26.6161
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env        17s  83%    value_loss        0.124  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          12.492  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               11    Train         3s  11%    approx_kl         0.004  â”‚
â”‚  Uptime           3m 3s      Forwaâ€¦      0s   1%    clipfrac          0.039  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.916  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              195.661    episode_length              257.541  â”‚
â”‚  x_position                    5.807    x_velocity                  -60.512  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=482.93 (best=192.21@327680)
æ­¥æ•° 360,448: Reward=482.93, Best=195.66@360448, Sharpness=1.2257, Î»_max=-24.6768
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env        17s  87%    value_loss        0.120  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          12.498  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s   6%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 22s      Forwaâ€¦      0s   1%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦         1m 3s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              200.957    episode_length              271.478  â”‚
â”‚  x_position                   -2.340    x_velocity                  -69.078  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=286.08 (best=195.66@360448)
æ­¥æ•° 393,216: Reward=286.08, Best=200.96@393216, Sharpness=1.1576, Î»_max=-25.5305
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 20.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        17s  87%    value_loss        0.106  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          12.502  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         3s   6%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 36s      Forwaâ€¦      0s   1%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           30s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              210.487    episode_length              274.267  â”‚
â”‚  x_position                    5.051    x_velocity                  -62.322  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=173.76 (best=200.96@393216)
æ­¥æ•° 425,984: Reward=173.76, Best=210.49@425984, Sharpness=1.1571, Î»_max=-25.9777
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        17s  87%    value_loss        0.123  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          12.505  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         3s   6%    approx_kl         0.001  â”‚
â”‚  Uptime          3m 53s      Forwaâ€¦      0s   1%    clipfrac          0.008  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.910  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              216.011    episode_length              280.617  â”‚
â”‚  x_position                   10.141    x_velocity                  -63.106  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=172.71 (best=210.49@425984)
æ­¥æ•° 458,752: Reward=172.71, Best=216.01@458752, Sharpness=1.1659, Î»_max=-28.7125
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.1%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 18.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss      -0.000  â”‚
â”‚  Params          135.3K      Env        17s  87%    value_loss        0.137  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          12.507  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s   6%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 7s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              228.570    episode_length              290.476  â”‚
â”‚  x_position                   17.868    x_velocity                  -60.358  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=204.46 (best=216.01@458752)
æ­¥æ•° 491,520: Reward=204.46, Best=228.57@491520, Sharpness=1.1988, Î»_max=-32.0242
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     23s  93%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        21s  87%    value_loss        0.148  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          12.507  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s   6%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 20s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.873  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              292.927    episode_length              319.978  â”‚
â”‚  x_position                   51.787    x_velocity                  -25.358  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=975.35 (best=228.57@491520)
æ­¥æ•° 524,288: Reward=975.35, Best=292.93@524288, Sharpness=1.1944, Î»_max=-17.1323

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 0_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_0/vec_stats.npz
[J&R] base_task=0, new_task=0_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_0/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.2%  DRAM: 0.2%   VRAM: 2.9%  â”‚
â”‚                                 25.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         7s   0%    value_loss        1.265  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.226  â”‚
â”‚  SPS               4.0K      Misc        0s   0%    old_approx_kl     0.028  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.023  â”‚
â”‚  Uptime              8s      Forwaâ€¦      0s   0%    clipfrac          0.259  â”‚
â”‚  Remainiâ€¦        1m 57s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.402  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.336    episode_length               51.098  â”‚
â”‚  x_position                   -3.880    x_velocity                  -40.499  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=219.19 (best=N/A)
æ­¥æ•° 32,768: Reward=219.19, Best=10.34@32768, Sharpness=1.1726, Î»_max=-27.0072
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         7s  86%    value_loss        0.562  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.251  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                2    Train         0s   8%    approx_kl         0.016  â”‚
â”‚  Uptime             27s      Forwaâ€¦      0s   1%    clipfrac          0.193  â”‚
â”‚  Remainiâ€¦        4m 13s      Learn       0s   6%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.854  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               32.241    episode_length               90.864  â”‚
â”‚  x_position                   -9.905    x_velocity                  -58.143  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=582.32 (best=10.34@32768)
æ­¥æ•° 65,536: Reward=582.32, Best=32.24@65536, Sharpness=1.1607, Î»_max=-22.4373
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         7s  86%    value_loss        0.330  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.279  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         0s   8%    approx_kl         0.014  â”‚
â”‚  Uptime             44s      Forwaâ€¦      0s   1%    clipfrac          0.159  â”‚
â”‚  Remainiâ€¦        3m 31s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               71.119    episode_length              138.729  â”‚
â”‚  x_position                  -15.694    x_velocity                  -66.872  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=55.71 (best=32.24@65536)
æ­¥æ•° 98,304: Reward=55.71, Best=71.12@98304, Sharpness=1.1803, Î»_max=-30.8906
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         7s  86%    value_loss        0.279  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.308  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                4    Train         0s   8%    approx_kl         0.011  â”‚
â”‚  Uptime             59s      Forwaâ€¦      0s   1%    clipfrac          0.134  â”‚
â”‚  Remainiâ€¦        2m 50s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               82.877    episode_length              153.946  â”‚
â”‚  x_position                  -17.190    x_velocity                  -70.244  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=856.74 (best=71.12@98304)
æ­¥æ•° 131,072: Reward=856.74, Best=82.88@131072, Sharpness=1.1676, Î»_max=-30.5168
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 11.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         7s  86%    value_loss        0.227  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.329  â”‚
â”‚  SPS               1.6K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         0s   8%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 20s      Forwaâ€¦      0s   1%    clipfrac          0.124  â”‚
â”‚  Remainiâ€¦        3m 31s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              119.292    episode_length              192.893  â”‚
â”‚  x_position                  -17.624    x_velocity                  -72.568  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=162.75 (best=82.88@131072)
æ­¥æ•° 163,840: Reward=162.75, Best=119.29@163840, Sharpness=1.1717, Î»_max=-27.7475
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env        11s  86%    value_loss        0.187  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.351  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         1s   8%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 37s      Forwaâ€¦      0s   1%    clipfrac          0.106  â”‚
â”‚  Remainiâ€¦        2m 34s      Learn       1s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.921  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              145.304    episode_length              214.682  â”‚
â”‚  x_position                  -10.982    x_velocity                  -68.237  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=703.74 (best=119.29@163840)
æ­¥æ•° 196,608: Reward=703.74, Best=145.30@196608, Sharpness=1.1956, Î»_max=-29.6048
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.3%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.153  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          12.376  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                7    Train         1s  18%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 55s      Forwaâ€¦      0s   4%    clipfrac          0.087  â”‚
â”‚  Remainiâ€¦        2m 28s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              158.273    episode_length              225.355  â”‚
â”‚  x_position                   -8.330    x_velocity                  -65.886  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=832.32 (best=145.30@196608)
æ­¥æ•° 229,376: Reward=832.32, Best=158.27@229376, Sharpness=1.1724, Î»_max=-31.7360
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.143  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          12.396  â”‚
â”‚  SPS               1.5K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s  18%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 16s      Forwaâ€¦      0s   4%    clipfrac          0.090  â”‚
â”‚  Remainiâ€¦        2m 35s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.919  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              178.263    episode_length              241.738  â”‚
â”‚  x_position                    3.644    x_velocity                  -62.193  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=105.42 (best=158.27@229376)
æ­¥æ•° 262,144: Reward=105.42, Best=178.26@262144, Sharpness=1.1989, Î»_max=-31.4738
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.123  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          12.411  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s  18%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 32s      Forwaâ€¦      0s   4%    clipfrac          0.065  â”‚
â”‚  Remainiâ€¦        1m 37s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.925  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              191.193    episode_length              257.782  â”‚
â”‚  x_position                   -2.427    x_velocity                  -65.225  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=716.33 (best=178.26@262144)
æ­¥æ•° 294,912: Reward=716.33, Best=191.19@294912, Sharpness=1.2670, Î»_max=-30.0003
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.3%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 11.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.120  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          12.421  â”‚
â”‚  SPS               1.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               10    Train         1s  18%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 54s      Forwaâ€¦      0s   4%    clipfrac          0.061  â”‚
â”‚  Remainiâ€¦        1m 55s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              224.693    episode_length              281.104  â”‚
â”‚  x_position                    6.097    x_velocity                  -54.925  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=857.25 (best=191.19@294912)
æ­¥æ•° 327,680: Reward=857.25, Best=224.69@327680, Sharpness=1.1960, Î»_max=-30.0495
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env        16s  74%    value_loss        0.111  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          12.430  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         3s  18%    approx_kl         0.004  â”‚
â”‚  Uptime          3m 13s      Forwaâ€¦      0s   4%    clipfrac          0.050  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.925  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              214.441    episode_length              274.258  â”‚
â”‚  x_position                    5.940    x_velocity                  -58.363  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=609.80 (best=224.69@327680)
æ­¥æ•° 360,448: Reward=609.80, Best=224.69@327680, Sharpness=1.2762, Î»_max=-21.3684
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 11.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env        16s  76%    value_loss        0.113  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          12.438  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  18%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 32s      Forwaâ€¦      0s   3%    clipfrac          0.027  â”‚
â”‚  Remainiâ€¦         1m 2s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              247.520    episode_length              289.364  â”‚
â”‚  x_position                   31.156    x_velocity                  -40.312  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=773.52 (best=224.69@327680)
æ­¥æ•° 393,216: Reward=773.52, Best=247.52@393216, Sharpness=1.3523, Î»_max=-19.3279
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env        16s  76%    value_loss        0.128  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          12.443  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  18%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 47s      Forwaâ€¦      0s   3%    clipfrac          0.024  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              260.224    episode_length              299.720  â”‚
â”‚  x_position                   37.273    x_velocity                  -37.911  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=1186.24 (best=247.52@393216)
æ­¥æ•° 425,984: Reward=1186.24, Best=260.22@425984, Sharpness=1.3419, Î»_max=-24.8432
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 11.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        16s  76%    value_loss        0.120  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          12.446  â”‚
â”‚  SPS               1.5K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         3s  18%    approx_kl         0.002  â”‚
â”‚  Uptime           4m 8s      Forwaâ€¦      0s   3%    clipfrac          0.013  â”‚
â”‚  Remainiâ€¦           27s      Learn       1s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              247.209    episode_length              285.606  â”‚
â”‚  x_position                   42.607    x_velocity                  -36.886  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=828.68 (best=260.22@425984)
æ­¥æ•° 458,752: Reward=828.68, Best=260.22@425984, Sharpness=1.2586, Î»_max=-29.1858
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env        16s  76%    value_loss        0.145  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          12.447  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  18%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 27s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.859  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              283.065    episode_length              329.818  â”‚
â”‚  x_position                   43.802    x_velocity                  -45.008  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=956.15 (best=260.22@425984)
æ­¥æ•° 491,520: Reward=956.15, Best=283.07@491520, Sharpness=1.2213, Î»_max=-25.5282
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡      CPU: 9.8%  GPU: 2.2%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     22s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env        21s  76%    value_loss        0.136  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          12.447  â”‚
â”‚  SPS               1.6K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s  18%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 48s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.870  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              281.439    episode_length              319.911  â”‚
â”‚  x_position                   61.592    x_velocity                  -36.786  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=472.81 (best=283.07@491520)
æ­¥æ•° 524,288: Reward=472.81, Best=283.07@491520, Sharpness=1.2037, Î»_max=-26.5458

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 0_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_0/vec_stats.npz
[J&R] base_task=0, new_task=0_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_0/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.0%  DRAM: 0.2%   VRAM: 2.9%  â”‚
â”‚                                 23.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         4s   0%    value_loss        1.223  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.979  â”‚
â”‚  SPS               6.3K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.023  â”‚
â”‚  Uptime              5s      Forwaâ€¦      0s   0%    clipfrac          0.259  â”‚
â”‚  Remainiâ€¦        1m 13s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.384  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                9.618    episode_length               47.800  â”‚
â”‚  x_position                   -3.719    x_velocity                  -37.936  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=71.56 (best=N/A)
æ­¥æ•° 32,768: Reward=71.56, Best=9.62@32768, Sharpness=1.1906, Î»_max=-28.2383
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         4s  85%    value_loss        0.593  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.017  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                2    Train         0s   9%    approx_kl         0.020  â”‚
â”‚  Uptime             22s      Forwaâ€¦      0s   1%    clipfrac          0.211  â”‚
â”‚  Remainiâ€¦        3m 55s      Learn       0s   4%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.848  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               23.446    episode_length               90.972  â”‚
â”‚  x_position                  -12.280    x_velocity                  -67.045  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=28.22 (best=9.62@32768)
æ­¥æ•° 65,536: Reward=28.22, Best=23.45@65536, Sharpness=1.1969, Î»_max=-38.5964
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.5%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         4s  85%    value_loss        0.352  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.033  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         0s   9%    approx_kl         0.015  â”‚
â”‚  Uptime             39s      Forwaâ€¦      0s   1%    clipfrac          0.170  â”‚
â”‚  Remainiâ€¦        3m 20s      Learn       0s   4%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.898  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               61.238    episode_length              140.515  â”‚
â”‚  x_position                  -19.939    x_velocity                  -78.531  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=146.18 (best=23.45@65536)
æ­¥æ•° 98,304: Reward=146.18, Best=61.24@98304, Sharpness=1.2053, Î»_max=-30.2019
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 18.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.035  â”‚
â”‚  Params          135.3K      Env         4s  85%    value_loss        0.305  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.050  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         0s   9%    approx_kl         0.013  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   1%    clipfrac          0.160  â”‚
â”‚  Remainiâ€¦        2m 33s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.921  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               67.444    episode_length              151.597  â”‚
â”‚  x_position                  -22.680    x_velocity                  -83.344  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=120.84 (best=61.24@98304)
æ­¥æ•° 131,072: Reward=120.84, Best=67.44@131072, Sharpness=1.2119, Î»_max=-37.3146
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         4s  85%    value_loss        0.249  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.070  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         0s   9%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 10s      Forwaâ€¦      0s   1%    clipfrac          0.135  â”‚
â”‚  Remainiâ€¦        2m 58s      Learn       0s   4%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.925  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               88.177    episode_length              168.640  â”‚
â”‚  x_position                  -19.652    x_velocity                  -79.559  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=98.18 (best=67.44@131072)
æ­¥æ•° 163,840: Reward=98.18, Best=88.18@163840, Sharpness=1.1880, Î»_max=-40.5441
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         9s  85%    value_loss        0.217  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.088  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         1s   9%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 27s      Forwaâ€¦      0s   1%    clipfrac          0.118  â”‚
â”‚  Remainiâ€¦        2m 38s      Learn       1s   4%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.922  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              118.729    episode_length              198.536  â”‚
â”‚  x_position                  -18.451    x_velocity                  -78.753  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=131.51 (best=88.18@163840)
æ­¥æ•° 196,608: Reward=131.51, Best=118.73@196608, Sharpness=1.1822, Î»_max=-37.1705
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.5%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.175  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          12.103  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         1s  11%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 44s      Forwaâ€¦      0s   2%    clipfrac          0.111  â”‚
â”‚  Remainiâ€¦        2m 16s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.925  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              135.705    episode_length              213.893  â”‚
â”‚  x_position                  -18.071    x_velocity                  -77.047  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=136.80 (best=118.73@196608)
æ­¥æ•° 229,376: Reward=136.80, Best=135.70@229376, Sharpness=1.1970, Î»_max=-27.2192
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.153  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          12.116  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s  11%    approx_kl         0.007  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.083  â”‚
â”‚  Remainiâ€¦        1m 57s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              164.783    episode_length              239.486  â”‚
â”‚  x_position                  -13.006    x_velocity                  -73.434  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=298.89 (best=135.70@229376)
æ­¥æ•° 262,144: Reward=298.89, Best=164.78@262144, Sharpness=1.2117, Î»_max=-35.2209
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.140  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          12.128  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.076  â”‚
â”‚  Remainiâ€¦        1m 59s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.927  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              183.305    episode_length              251.727  â”‚
â”‚  x_position                   -8.134    x_velocity                  -67.080  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=162.46 (best=164.78@262144)
æ­¥æ•° 294,912: Reward=162.46, Best=183.31@294912, Sharpness=1.1973, Î»_max=-35.6396
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.131  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          12.141  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  11%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 35s      Forwaâ€¦      0s   2%    clipfrac          0.060  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.921  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              191.442    episode_length              262.913  â”‚
â”‚  x_position                   -8.328    x_velocity                  -70.078  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=165.33 (best=183.31@294912)
æ­¥æ•° 327,680: Reward=165.33, Best=191.44@327680, Sharpness=1.3513, Î»_max=-37.9658
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.7%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env        14s  81%    value_loss        0.122  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          12.149  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         2s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 54s      Forwaâ€¦      0s   2%    clipfrac          0.066  â”‚
â”‚  Remainiâ€¦        1m 19s      Learn       1s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.930  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              230.202    episode_length              295.593  â”‚
â”‚  x_position                    5.986    x_velocity                  -63.822  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=115.85 (best=191.44@327680)
æ­¥æ•° 360,448: Reward=115.85, Best=230.20@360448, Sharpness=1.3555, Î»_max=-32.1590
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env        14s  73%    value_loss        0.115  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          12.155  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         2s  20%    approx_kl         0.004  â”‚
â”‚  Uptime          3m 11s      Forwaâ€¦      0s   4%    clipfrac          0.048  â”‚
â”‚  Remainiâ€¦           56s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.929  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              204.484    episode_length              278.430  â”‚
â”‚  x_position                   -9.632    x_velocity                  -72.473  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=117.52 (best=230.20@360448)
æ­¥æ•° 393,216: Reward=117.52, Best=230.20@360448, Sharpness=1.2066, Î»_max=-38.4472
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        14s  73%    value_loss        0.125  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          12.159  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  20%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 29s      Forwaâ€¦      0s   4%    clipfrac          0.031  â”‚
â”‚  Remainiâ€¦           41s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              224.169    episode_length              289.362  â”‚
â”‚  x_position                   -7.832    x_velocity                  -63.654  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=276.31 (best=230.20@360448)
æ­¥æ•° 425,984: Reward=276.31, Best=230.20@360448, Sharpness=1.3243, Î»_max=-15.5289
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 20.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        14s  73%    value_loss        0.142  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          12.161  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  20%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 44s      Forwaâ€¦      0s   4%    clipfrac          0.010  â”‚
â”‚  Remainiâ€¦           18s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              248.405    episode_length              302.885  â”‚
â”‚  x_position                   26.847    x_velocity                  -52.874  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=294.65 (best=230.20@360448)
æ­¥æ•° 458,752: Reward=294.65, Best=248.41@458752, Sharpness=1.2637, Î»_max=-28.6183
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.042  â”‚
â”‚  Params          135.3K      Env        14s  73%    value_loss        0.139  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          12.163  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  20%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 0s      Forwaâ€¦      0s   4%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.898  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              260.304    episode_length              305.483  â”‚
â”‚  x_position                   30.473    x_velocity                  -43.559  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=383.60 (best=248.41@458752)
æ­¥æ•° 491,520: Reward=383.60, Best=260.30@491520, Sharpness=1.3237, Î»_max=-29.4322
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     20s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env        18s  73%    value_loss        0.167  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          12.163  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  20%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 18s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.884  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              302.996    episode_length              336.667  â”‚
â”‚  x_position                   45.099    x_velocity                  -31.883  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=190.43 (best=260.30@491520)
æ­¥æ•° 524,288: Reward=190.43, Best=303.00@524288, Sharpness=1.3400, Î»_max=-29.8702

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 0_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_0/vec_stats.npz
[J&R] base_task=0, new_task=0_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_0/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 0.5%  DRAM: 0.2%   VRAM: 2.8%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.543  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.173  â”‚
â”‚  SPS               7.0K      Misc        0s   0%    old_approx_kl     0.047  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.038  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.347  â”‚
â”‚  Remainiâ€¦         1m 6s      Learn       0s   0%    importance        0.991  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.514  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.329    episode_length               37.657  â”‚
â”‚  x_position                   -3.960    x_velocity                  -43.796  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=77.62 (best=N/A)
æ­¥æ•° 32,768: Reward=77.62, Best=-6.33@32768, Sharpness=1.9721, Î»_max=65.8433
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         3s  83%    value_loss        0.601  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          11.210  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.026  â”‚
â”‚  Epoch                2    Train         0s  10%    approx_kl         0.024  â”‚
â”‚  Uptime             21s      Forwaâ€¦      0s   2%    clipfrac          0.240  â”‚
â”‚  Remainiâ€¦        3m 47s      Learn       0s   5%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.717  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.581    episode_length               71.179  â”‚
â”‚  x_position                   -8.461    x_velocity                  -59.236  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=417.54 (best=-6.33@32768)
æ­¥æ•° 65,536: Reward=417.54, Best=11.58@65536, Sharpness=1.9440, Î»_max=-62.8997
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         3s  83%    value_loss        0.486  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          11.231  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                3    Train         0s  10%    approx_kl         0.020  â”‚
â”‚  Uptime             40s      Forwaâ€¦      0s   2%    clipfrac          0.215  â”‚
â”‚  Remainiâ€¦        3m 46s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.727  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.118    episode_length               89.468  â”‚
â”‚  x_position                  -12.082    x_velocity                  -66.896  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=111.73 (best=11.58@65536)
æ­¥æ•° 98,304: Reward=111.73, Best=22.12@98304, Sharpness=1.9713, Î»_max=-66.5780
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.5%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         3s  83%    value_loss        0.373  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          11.258  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                4    Train         0s  10%    approx_kl         0.017  â”‚
â”‚  Uptime           1m 0s      Forwaâ€¦      0s   2%    clipfrac          0.190  â”‚
â”‚  Remainiâ€¦        3m 42s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.747  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               25.201    episode_length               98.327  â”‚
â”‚  x_position                  -15.866    x_velocity                  -72.629  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=143.86 (best=22.12@98304)
æ­¥æ•° 131,072: Reward=143.86, Best=25.20@131072, Sharpness=1.8739, Î»_max=-71.3468
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         3s  83%    value_loss        0.314  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          11.288  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                5    Train         0s  10%    approx_kl         0.015  â”‚
â”‚  Uptime          1m 19s      Forwaâ€¦      0s   2%    clipfrac          0.170  â”‚
â”‚  Remainiâ€¦        3m 18s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.763  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.543    episode_length               99.122  â”‚
â”‚  x_position                  -17.248    x_velocity                  -76.078  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=179.18 (best=25.20@131072)
æ­¥æ•° 163,840: Reward=179.18, Best=25.20@131072, Sharpness=1.9425, Î»_max=-61.2638
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 17.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  83%    value_loss        0.291  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          11.316  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                6    Train         1s  10%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   2%    clipfrac          0.159  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.779  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               28.769    episode_length              103.972  â”‚
â”‚  x_position                  -19.020    x_velocity                  -74.679  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=215.63 (best=25.20@131072)
æ­¥æ•° 196,608: Reward=215.63, Best=28.77@196608, Sharpness=1.8747, Î»_max=-64.7915
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.1%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 18.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         9s  84%    value_loss        0.291  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          11.344  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                7    Train         1s   9%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   1%    clipfrac          0.140  â”‚
â”‚  Remainiâ€¦        2m 10s      Learn       0s   6%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.777  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.638    episode_length              109.721  â”‚
â”‚  x_position                  -20.542    x_velocity                  -79.529  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=93.27 (best=28.77@196608)
æ­¥æ•° 229,376: Reward=93.27, Best=29.64@229376, Sharpness=2.0673, Î»_max=-15.6604
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env         9s  84%    value_loss        0.320  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          11.367  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                8    Train         1s   9%    approx_kl         0.011  â”‚
â”‚  Uptime           2m 9s      Forwaâ€¦      0s   1%    clipfrac          0.127  â”‚
â”‚  Remainiâ€¦        2m 14s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.784  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               33.487    episode_length              109.053  â”‚
â”‚  x_position                  -19.861    x_velocity                  -75.016  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=98.12 (best=29.64@229376)
æ­¥æ•° 262,144: Reward=98.12, Best=33.49@262144, Sharpness=1.9001, Î»_max=-61.0056
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.2%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         9s  84%    value_loss        0.258  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          11.388  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                9    Train         1s   9%    approx_kl         0.010  â”‚
â”‚  Uptime          2m 27s      Forwaâ€¦      0s   1%    clipfrac          0.117  â”‚
â”‚  Remainiâ€¦        1m 50s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.770  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               31.810    episode_length              113.281  â”‚
â”‚  x_position                  -23.393    x_velocity                  -80.900  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=319.88 (best=33.49@262144)
æ­¥æ•° 294,912: Reward=319.88, Best=33.49@262144, Sharpness=1.8599, Î»_max=5.8010
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         9s  84%    value_loss        0.259  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          11.403  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         1s   9%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 46s      Forwaâ€¦      0s   1%    clipfrac          0.083  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.763  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               33.345    episode_length              110.585  â”‚
â”‚  x_position                  -20.521    x_velocity                  -76.683  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=139.02 (best=33.49@262144)
æ­¥æ•° 327,680: Reward=139.02, Best=33.49@262144, Sharpness=1.8930, Î»_max=-68.6366
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env        16s  84%    value_loss        0.265  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          11.418  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         1s   9%    approx_kl         0.006  â”‚
â”‚  Uptime           3m 4s      Forwaâ€¦      0s   1%    clipfrac          0.075  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.762  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               33.079    episode_length              116.914  â”‚
â”‚  x_position                  -24.418    x_velocity                  -83.248  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=264.87 (best=33.49@262144)
æ­¥æ•° 360,448: Reward=264.87, Best=33.49@262144, Sharpness=1.9064, Î»_max=-54.1429
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env        16s  86%    value_loss        0.249  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          11.427  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         1s   9%    approx_kl         0.004  â”‚
â”‚  Uptime          3m 22s      Forwaâ€¦      0s   1%    clipfrac          0.048  â”‚
â”‚  Remainiâ€¦           57s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.763  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               34.980    episode_length              118.683  â”‚
â”‚  x_position                  -24.749    x_velocity                  -83.109  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=165.48 (best=33.49@262144)
æ­¥æ•° 393,216: Reward=165.48, Best=34.98@393216, Sharpness=1.8598, Î»_max=-69.3662
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env        16s  86%    value_loss        0.257  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          11.432  â”‚
â”‚  SPS               1.6K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         1s   9%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 42s      Forwaâ€¦      0s   1%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           45s      Learn       1s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.741  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               28.980    episode_length              110.746  â”‚
â”‚  x_position                  -22.294    x_velocity                  -81.211  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=131.47 (best=34.98@393216)
æ­¥æ•° 425,984: Reward=131.47, Best=34.98@393216, Sharpness=1.8725, Î»_max=-64.8054
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.5%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.000  â”‚
â”‚  Params          135.3K      Env        16s  86%    value_loss        0.279  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          11.435  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s   9%    approx_kl         0.002  â”‚
â”‚  Uptime           4m 1s      Forwaâ€¦      0s   1%    clipfrac          0.014  â”‚
â”‚  Remainiâ€¦           23s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.735  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               36.616    episode_length              123.745  â”‚
â”‚  x_position                  -27.520    x_velocity                  -86.509  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=171.03 (best=34.98@393216)
æ­¥æ•° 458,752: Reward=171.03, Best=36.62@458752, Sharpness=1.9563, Î»_max=-52.0666
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.9%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env        16s  86%    value_loss        0.309  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          11.437  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s   9%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 17s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.701  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               40.778    episode_length              126.792  â”‚
â”‚  x_position                  -26.398    x_velocity                  -85.378  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=134.61 (best=36.62@458752)
æ­¥æ•° 491,520: Reward=134.61, Best=40.78@491520, Sharpness=1.8975, Î»_max=-56.1132
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.3%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     23s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   3%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        22s  86%    value_loss        0.288  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          11.437  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s   9%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 35s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.676  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               39.413    episode_length              127.075  â”‚
â”‚  x_position                  -29.574    x_velocity                  -87.025  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=106.03 (best=40.78@491520)
æ­¥æ•° 524,288: Reward=106.03, Best=40.78@491520, Sharpness=1.8968, Î»_max=-54.2966

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 0_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_0/vec_stats.npz
[J&R] base_task=0, new_task=0_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_0/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 6.0%  GPU: 0.0%  DRAM: 0.1%   VRAM: 1.7%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 2.9%  â”‚
â”‚                                 24.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env         4s   0%    value_loss        4.288  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          21.824  â”‚
â”‚  SPS               5.2K      Misc        0s   0%    old_approx_kl     0.058  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.051  â”‚
â”‚  Uptime              6s      Forwaâ€¦      0s   0%    clipfrac          0.326  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.093  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.068    episode_length               20.736  â”‚
â”‚  x_position                   -2.375    x_velocity                  -28.686  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-9.38 (best=N/A)
æ­¥æ•° 32,768: Reward=-9.38, Best=-8.07@32768, Sharpness=1.7962, Î»_max=23.0618
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.2%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 20.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env         4s  76%    value_loss        2.080  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          21.858  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.035  â”‚
â”‚  Epoch                2    Train         0s  13%    approx_kl         0.032  â”‚
â”‚  Uptime             20s      Forwaâ€¦      0s   2%    clipfrac          0.237  â”‚
â”‚  Remainiâ€¦         3m 6s      Learn       0s   8%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.143  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.079    episode_length               27.584  â”‚
â”‚  x_position                   -3.932    x_velocity                  -35.507  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-11.33 (best=-8.07@32768)
æ­¥æ•° 65,536: Reward=-11.33, Best=-8.07@32768, Sharpness=1.5415, Î»_max=18.1385
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.7%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 21.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         4s  76%    value_loss        1.219  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          21.899  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                3    Train         0s  13%    approx_kl         0.020  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.185  â”‚
â”‚  Remainiâ€¦        2m 47s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.186  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.190    episode_length               31.041  â”‚
â”‚  x_position                   -4.799    x_velocity                  -39.054  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-3.84 (best=-8.07@32768)
æ­¥æ•° 98,304: Reward=-3.84, Best=-8.07@32768, Sharpness=1.2336, Î»_max=-4.1202
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.0%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         4s  76%    value_loss        0.862  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          21.949  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                4    Train         0s  13%    approx_kl         0.016  â”‚
â”‚  Uptime             49s      Forwaâ€¦      0s   2%    clipfrac          0.151  â”‚
â”‚  Remainiâ€¦        2m 54s      Learn       0s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.121  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.492    episode_length               32.499  â”‚
â”‚  x_position                   -5.106    x_velocity                  -39.806  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-23.38 (best=-8.07@32768)
æ­¥æ•° 131,072: Reward=-23.38, Best=-7.49@131072, Sharpness=1.2082, Î»_max=-7.1216
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         4s  76%    value_loss        0.689  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          21.992  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                5    Train         0s  13%    approx_kl         0.014  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.138  â”‚
â”‚  Remainiâ€¦        2m 26s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.188  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.954    episode_length               33.959  â”‚
â”‚  x_position                   -5.515    x_velocity                  -40.719  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-11.66 (best=-7.49@131072)
æ­¥æ•° 163,840: Reward=-11.66, Best=-6.95@163840, Sharpness=1.1447, Î»_max=4.8556
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.1%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.608  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          22.025  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                6    Train         2s  13%    approx_kl         0.013  â”‚
â”‚  Uptime          1m 19s      Forwaâ€¦      0s   2%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.140  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.970    episode_length               34.311  â”‚
â”‚  x_position                   -5.577    x_velocity                  -41.084  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-20.86 (best=-6.95@163840)
æ­¥æ•° 196,608: Reward=-20.86, Best=-6.95@163840, Sharpness=1.1761, Î»_max=-7.5155
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.546  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          22.048  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                7    Train         2s  18%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   4%    clipfrac          0.097  â”‚
â”‚  Remainiâ€¦        1m 43s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.086  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.741    episode_length               34.697  â”‚
â”‚  x_position                   -5.685    x_velocity                  -41.240  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-18.92 (best=-6.95@163840)
æ­¥æ•° 229,376: Reward=-18.92, Best=-6.74@229376, Sharpness=1.5695, Î»_max=-7.4497
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 17.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.521  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          22.069  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                8    Train         2s  18%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 48s      Forwaâ€¦      0s   4%    clipfrac          0.088  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       1s  10%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.014  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.288    episode_length               35.682  â”‚
â”‚  x_position                   -5.910    x_velocity                  -41.766  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-11.29 (best=-6.74@229376)
æ­¥æ•° 262,144: Reward=-11.29, Best=-6.29@262144, Sharpness=1.1892, Î»_max=-0.9083
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.5%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.490  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          22.086  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  18%    approx_kl         0.007  â”‚
â”‚  Uptime           2m 4s      Forwaâ€¦      0s   4%    clipfrac          0.071  â”‚
â”‚  Remainiâ€¦        1m 41s      Learn       1s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.074  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.011    episode_length               36.455  â”‚
â”‚  x_position                   -5.979    x_velocity                  -42.258  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-10.13 (best=-6.29@262144)
æ­¥æ•° 294,912: Reward=-10.13, Best=-6.01@294912, Sharpness=1.5430, Î»_max=-7.2334
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.6%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.493  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          22.106  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         2s  18%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   4%    clipfrac          0.064  â”‚
â”‚  Remainiâ€¦        1m 27s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.067  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.651    episode_length               36.368  â”‚
â”‚  x_position                   -5.951    x_velocity                  -41.811  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-8.16 (best=-6.01@294912)
æ­¥æ•° 327,680: Reward=-8.16, Best=-5.65@327680, Sharpness=1.2160, Î»_max=-7.1421
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.3%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env        14s  73%    value_loss        0.487  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          22.118  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  18%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 38s      Forwaâ€¦      0s   4%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.078  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.792    episode_length               37.393  â”‚
â”‚  x_position                   -6.041    x_velocity                  -41.972  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-8.07 (best=-5.65@327680)
æ­¥æ•° 360,448: Reward=-8.07, Best=-4.79@360448, Sharpness=1.2628, Î»_max=-9.5735
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.1%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        14s  77%    value_loss        0.503  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          22.129  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         2s  14%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 55s      Forwaâ€¦      0s   2%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           56s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.109  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.054    episode_length               38.041  â”‚
â”‚  x_position                   -6.411    x_velocity                  -42.878  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-8.18 (best=-4.79@360448)
æ­¥æ•° 393,216: Reward=-8.18, Best=-4.79@360448, Sharpness=1.2363, Î»_max=-8.1182
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.1%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env        14s  77%    value_loss        0.493  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          22.136  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               13    Train         2s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 11s      Forwaâ€¦      0s   2%    clipfrac          0.015  â”‚
â”‚  Remainiâ€¦           35s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.091  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.928    episode_length               37.825  â”‚
â”‚  x_position                   -6.265    x_velocity                  -42.537  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-11.65 (best=-4.79@360448)
æ­¥æ•° 425,984: Reward=-11.65, Best=-4.79@360448, Sharpness=1.2811, Î»_max=-7.6155
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.8%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env        14s  77%    value_loss        0.493  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          22.139  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  14%    approx_kl         0.001  â”‚
â”‚  Uptime          3m 27s      Forwaâ€¦      0s   2%    clipfrac          0.008  â”‚
â”‚  Remainiâ€¦           20s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.064  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.305    episode_length               38.249  â”‚
â”‚  x_position                   -6.321    x_velocity                  -42.335  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-7.50 (best=-4.79@360448)
æ­¥æ•° 458,752: Reward=-7.50, Best=-4.31@458752, Sharpness=1.2620, Î»_max=-8.4742
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.4%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.022  â”‚
â”‚  Params          135.3K      Env        14s  77%    value_loss        0.578  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          22.141  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 45s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.066  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.368    episode_length               37.930  â”‚
â”‚  x_position                   -6.269    x_velocity                  -42.081  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-6.42 (best=-4.31@458752)
æ­¥æ•° 491,520: Reward=-6.42, Best=-4.31@458752, Sharpness=1.7030, Î»_max=-8.0196
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.7%  DRAM: 0.2%   VRAM: 3.3%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     21s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env        19s  77%    value_loss        0.533  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          22.141  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  14%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 1s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.057  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.680    episode_length               39.177  â”‚
â”‚  x_position                   -6.412    x_velocity                  -42.633  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-12.69 (best=-4.31@458752)
æ­¥æ•° 524,288: Reward=-12.69, Best=-3.68@524288, Sharpness=1.1218, Î»_max=-7.8531

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 0_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 0 step sweep å®Œæˆã€‚
