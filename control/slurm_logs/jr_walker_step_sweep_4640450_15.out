==========================================
[Jump & Retrain] Walker2d task 15 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 11:10:57 EST 2025
èŠ‚ç‚¹: node8
==========================================
[Base] task=15, env=Walker2d-v4, best_model=final_model.pt, best_reward=1993.01, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_15/vec_stats.npz
[J&R] base_task=15, new_task=15_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_15/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.2%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         6s   0%    value_loss        1.236  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.363  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.028  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.021  â”‚
â”‚  Uptime             12s      Forwaâ€¦      0s   0%    clipfrac          0.240  â”‚
â”‚  Remainiâ€¦         3m 0s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.416  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.046    episode_length               49.377  â”‚
â”‚  x_position                   -3.876    x_velocity                  -41.076  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=8.66 (best=N/A)
æ­¥æ•° 32,768: Reward=8.66, Best=8.05@32768, Sharpness=1.2308, Î»_max=-24.3878
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.7%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         6s  69%    value_loss        0.557  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.401  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                2    Train         1s  21%    approx_kl         0.017  â”‚
â”‚  Uptime             25s      Forwaâ€¦      0s   4%    clipfrac          0.189  â”‚
â”‚  Remainiâ€¦        2m 50s      Learn       0s   4%    importance        1.001  â”‚
â”‚                              Copy        0s   4%    explained_varâ€¦    0.837  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.366    episode_length               83.140  â”‚
â”‚  x_position                  -10.275    x_velocity                  -58.333  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-22.69 (best=8.05@32768)
æ­¥æ•° 65,536: Reward=-22.69, Best=24.37@65536, Sharpness=1.3007, Î»_max=-27.1080
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         6s  69%    value_loss        0.395  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.426  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         1s  21%    approx_kl         0.017  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   4%    clipfrac          0.191  â”‚
â”‚  Remainiâ€¦        2m 29s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   4%    explained_varâ€¦    0.897  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.063    episode_length              106.685  â”‚
â”‚  x_position                  -20.701    x_velocity                  -82.065  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-18.69 (best=24.37@65536)
æ­¥æ•° 98,304: Reward=-18.69, Best=24.37@65536, Sharpness=1.2498, Î»_max=-29.1741
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         6s  69%    value_loss        0.370  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.444  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                4    Train         1s  21%    approx_kl         0.011  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   4%    clipfrac          0.138  â”‚
â”‚  Remainiâ€¦        2m 53s      Learn       0s   4%    importance        1.002  â”‚
â”‚                              Copy        0s   4%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               53.524    episode_length              133.350  â”‚
â”‚  x_position                  -20.637    x_velocity                  -79.125  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=11.64 (best=24.37@65536)
æ­¥æ•° 131,072: Reward=11.64, Best=53.52@131072, Sharpness=1.2461, Î»_max=-12.8151
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         6s  69%    value_loss        0.296  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.460  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  21%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   4%    clipfrac          0.129  â”‚
â”‚  Remainiâ€¦        1m 47s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   4%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               64.324    episode_length              152.361  â”‚
â”‚  x_position                  -26.213    x_velocity                  -87.238  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-11.30 (best=53.52@131072)
æ­¥æ•° 163,840: Reward=-11.30, Best=64.32@163840, Sharpness=1.2177, Î»_max=-25.5860
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   7%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env        10s  69%    value_loss        0.256  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.484  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         2s  21%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 18s      Forwaâ€¦      0s   4%    clipfrac          0.120  â”‚
â”‚  Remainiâ€¦        2m 10s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   4%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               94.459    episode_length              170.948  â”‚
â”‚  x_position                  -20.253    x_velocity                  -75.596  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-7.67 (best=64.32@163840)
æ­¥æ•° 196,608: Reward=-7.67, Best=94.46@196608, Sharpness=1.2288, Î»_max=-27.2084
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env        10s  80%    value_loss        0.206  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.501  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                7    Train         2s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   2%    clipfrac          0.102  â”‚
â”‚  Remainiâ€¦        1m 42s      Learn       0s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.917  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              101.198    episode_length              186.757  â”‚
â”‚  x_position                  -24.563    x_velocity                  -84.582  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-8.01 (best=94.46@196608)
æ­¥æ•° 229,376: Reward=-8.01, Best=101.20@229376, Sharpness=1.2796, Î»_max=-24.7986
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env        10s  80%    value_loss        0.193  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.524  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         2s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 43s      Forwaâ€¦      0s   2%    clipfrac          0.090  â”‚
â”‚  Remainiâ€¦        1m 32s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.910  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              109.221    episode_length              198.427  â”‚
â”‚  x_position                  -27.659    x_velocity                  -88.175  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-4.35 (best=101.20@229376)
æ­¥æ•° 262,144: Reward=-4.35, Best=109.22@262144, Sharpness=1.2804, Î»_max=-23.7320
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        10s  80%    value_loss        0.167  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.542  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 53s      Forwaâ€¦      0s   2%    clipfrac          0.075  â”‚
â”‚  Remainiâ€¦         1m 5s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              130.050    episode_length              214.525  â”‚
â”‚  x_position                  -22.354    x_velocity                  -83.359  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-2.25 (best=109.22@262144)
æ­¥æ•° 294,912: Reward=-2.25, Best=130.05@294912, Sharpness=1.2594, Î»_max=-27.0466
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.1%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        10s  80%    value_loss        0.145  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.560  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               10    Train         2s  11%    approx_kl         0.005  â”‚
â”‚  Uptime           2m 6s      Forwaâ€¦      0s   2%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦         1m 4s      Learn       0s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              141.811    episode_length              230.430  â”‚
â”‚  x_position                  -29.123    x_velocity                  -87.413  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-0.80 (best=130.05@294912)
æ­¥æ•° 327,680: Reward=-0.80, Best=141.81@327680, Sharpness=1.2834, Î»_max=-21.0115
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 17.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env        14s  80%    value_loss        0.140  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.571  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         3s  11%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.062  â”‚
â”‚  Remainiâ€¦           56s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              154.369    episode_length              241.600  â”‚
â”‚  x_position                  -26.600    x_velocity                  -85.972  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-12.93 (best=141.81@327680)
æ­¥æ•° 360,448: Reward=-12.93, Best=154.37@360448, Sharpness=1.2620, Î»_max=-18.7525
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.147  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.577  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  15%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   2%    clipfrac          0.042  â”‚
â”‚  Remainiâ€¦           39s      Learn       1s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              199.172    episode_length              266.240  â”‚
â”‚  x_position                  -10.485    x_velocity                  -65.693  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=3.26 (best=154.37@360448)
æ­¥æ•° 393,216: Reward=3.26, Best=199.17@393216, Sharpness=1.2199, Î»_max=-20.4950
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.1%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.143  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.584  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  15%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 43s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           26s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              209.682    episode_length              278.636  â”‚
â”‚  x_position                  -16.370    x_velocity                  -67.519  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=2.04 (best=199.17@393216)
æ­¥æ•° 425,984: Reward=2.04, Best=209.68@425984, Sharpness=1.2517, Î»_max=-21.8908
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.148  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.588  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         3s  15%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 54s      Forwaâ€¦      0s   2%    clipfrac          0.009  â”‚
â”‚  Remainiâ€¦           14s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.884  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              197.067    episode_length              268.198  â”‚
â”‚  x_position                  -18.574    x_velocity                  -69.746  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-27.73 (best=209.68@425984)
æ­¥æ•° 458,752: Reward=-27.73, Best=209.68@425984, Sharpness=1.3336, Î»_max=-17.3439
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.150  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.589  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  15%    approx_kl         0.000  â”‚
â”‚  Uptime           3m 6s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.858  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              248.346    episode_length              313.946  â”‚
â”‚  x_position                  -19.175    x_velocity                  -63.979  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-11.80 (best=209.68@425984)
æ­¥æ•° 491,520: Reward=-11.80, Best=248.35@491520, Sharpness=1.3099, Î»_max=9.8618
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.9%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env        17s  75%    value_loss        0.154  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.590  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         4s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 17s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.833  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              248.816    episode_length              297.099  â”‚
â”‚  x_position                  -10.092    x_velocity                  -46.751  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-3.45 (best=248.35@491520)
æ­¥æ•° 524,288: Reward=-3.45, Best=248.82@524288, Sharpness=1.4009, Î»_max=-18.4133

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 15_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_15/vec_stats.npz
[J&R] base_task=15, new_task=15_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_15/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.4%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 23.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         4s   0%    value_loss        1.222  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.276  â”‚
â”‚  SPS               5.7K      Misc        0s   0%    old_approx_kl     0.028  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.021  â”‚
â”‚  Uptime              5s      Forwaâ€¦      0s   0%    clipfrac          0.239  â”‚
â”‚  Remainiâ€¦        1m 21s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.393  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               13.720    episode_length               49.185  â”‚
â”‚  x_position                   -3.002    x_velocity                  -35.209  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=38.40 (best=N/A)
æ­¥æ•° 32,768: Reward=38.40, Best=13.72@32768, Sharpness=1.2238, Î»_max=-31.7600
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.4%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         4s  73%    value_loss        0.538  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.309  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         1s  19%    approx_kl         0.018  â”‚
â”‚  Uptime             16s      Forwaâ€¦      0s   3%    clipfrac          0.199  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.830  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               27.462    episode_length               83.735  â”‚
â”‚  x_position                   -9.501    x_velocity                  -55.828  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=31.49 (best=13.72@32768)
æ­¥æ•° 65,536: Reward=31.49, Best=27.46@65536, Sharpness=1.2247, Î»_max=-23.5771
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         4s  73%    value_loss        0.422  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.333  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                3    Train         1s  19%    approx_kl         0.015  â”‚
â”‚  Uptime             28s      Forwaâ€¦      0s   3%    clipfrac          0.171  â”‚
â”‚  Remainiâ€¦        2m 20s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.897  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.936    episode_length              109.931  â”‚
â”‚  x_position                  -20.234    x_velocity                  -79.416  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-38.70 (best=27.46@65536)
æ­¥æ•° 98,304: Reward=-38.70, Best=29.94@98304, Sharpness=1.2976, Î»_max=-23.8895
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env         4s  73%    value_loss        0.371  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.357  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                4    Train         1s  19%    approx_kl         0.012  â”‚
â”‚  Uptime             39s      Forwaâ€¦      0s   3%    clipfrac          0.140  â”‚
â”‚  Remainiâ€¦         2m 4s      Learn       0s   8%    importance        1.002  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.909  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               43.170    episode_length              129.729  â”‚
â”‚  x_position                  -23.703    x_velocity                  -85.871  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-1.02 (best=29.94@98304)
æ­¥æ•° 131,072: Reward=-1.02, Best=43.17@131072, Sharpness=1.2745, Î»_max=-28.1137
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         4s  73%    value_loss        0.311  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.387  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  19%    approx_kl         0.009  â”‚
â”‚  Uptime             50s      Forwaâ€¦      0s   3%    clipfrac          0.115  â”‚
â”‚  Remainiâ€¦        1m 59s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               76.908    episode_length              155.682  â”‚
â”‚  x_position                  -19.960    x_velocity                  -77.954  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=0.13 (best=43.17@131072)
æ­¥æ•° 163,840: Reward=0.13, Best=76.91@163840, Sharpness=1.2691, Î»_max=-26.9481
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         7s  73%    value_loss        0.251  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.416  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         1s  19%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 1s      Forwaâ€¦      0s   3%    clipfrac          0.108  â”‚
â”‚  Remainiâ€¦        1m 36s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               86.221    episode_length              168.974  â”‚
â”‚  x_position                  -23.478    x_velocity                  -81.865  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-5.28 (best=76.91@163840)
æ­¥æ•° 196,608: Reward=-5.28, Best=86.22@196608, Sharpness=1.3272, Î»_max=-26.8169
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         7s  81%    value_loss        0.206  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.442  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         1s  10%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.096  â”‚
â”‚  Remainiâ€¦        1m 30s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               97.126    episode_length              181.573  â”‚
â”‚  x_position                  -23.260    x_velocity                  -83.490  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=3.34 (best=86.22@196608)
æ­¥æ•° 229,376: Reward=3.34, Best=97.13@229376, Sharpness=1.2668, Î»_max=-26.6329
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env         7s  81%    value_loss        0.187  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.458  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         1s  10%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 24s      Forwaâ€¦      0s   2%    clipfrac          0.081  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              111.810    episode_length              193.964  â”‚
â”‚  x_position                  -25.992    x_velocity                  -81.135  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=0.06 (best=97.13@229376)
æ­¥æ•° 262,144: Reward=0.06, Best=111.81@262144, Sharpness=1.2390, Î»_max=-26.6825
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         7s  81%    value_loss        0.160  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.470  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         1s  10%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 38s      Forwaâ€¦      0s   2%    clipfrac          0.084  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              147.231    episode_length              223.048  â”‚
â”‚  x_position                  -21.553    x_velocity                  -74.642  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-18.19 (best=111.81@262144)
æ­¥æ•° 294,912: Reward=-18.19, Best=147.23@294912, Sharpness=1.2224, Î»_max=-22.4225
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 20.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         7s  81%    value_loss        0.152  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.477  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  10%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 54s      Forwaâ€¦      0s   2%    clipfrac          0.061  â”‚
â”‚  Remainiâ€¦        1m 23s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              150.875    episode_length              224.757  â”‚
â”‚  x_position                  -20.619    x_velocity                  -72.706  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-13.59 (best=147.23@294912)
æ­¥æ•° 327,680: Reward=-13.59, Best=150.88@327680, Sharpness=1.2232, Î»_max=-21.6101
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 21.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env        11s  81%    value_loss        0.154  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.485  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  10%    approx_kl         0.004  â”‚
â”‚  Uptime           2m 6s      Forwaâ€¦      0s   2%    clipfrac          0.042  â”‚
â”‚  Remainiâ€¦           47s      Learn       1s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.906  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              153.313    episode_length              225.723  â”‚
â”‚  x_position                  -15.883    x_velocity                  -71.230  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-15.03 (best=150.88@327680)
æ­¥æ•° 360,448: Reward=-15.03, Best=153.31@360448, Sharpness=1.4282, Î»_max=-22.1269
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        11s  72%    value_loss        0.157  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.493  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         2s  19%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 17s      Forwaâ€¦      0s   4%    clipfrac          0.046  â”‚
â”‚  Remainiâ€¦           38s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.897  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              173.801    episode_length              245.402  â”‚
â”‚  x_position                  -15.107    x_velocity                  -70.317  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-28.41 (best=153.31@360448)
æ­¥æ•° 393,216: Reward=-28.41, Best=173.80@393216, Sharpness=1.2675, Î»_max=-20.7204
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env        11s  72%    value_loss        0.144  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.498  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  19%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   4%    clipfrac          0.020  â”‚
â”‚  Remainiâ€¦           27s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              207.308    episode_length              276.967  â”‚
â”‚  x_position                  -30.718    x_velocity                  -68.219  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-22.91 (best=173.80@393216)
æ­¥æ•° 425,984: Reward=-22.91, Best=207.31@425984, Sharpness=1.2597, Î»_max=-24.9111
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env        11s  72%    value_loss        0.161  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.501  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  19%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 43s      Forwaâ€¦      0s   4%    clipfrac          0.005  â”‚
â”‚  Remainiâ€¦           17s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.870  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              224.108    episode_length              271.420  â”‚
â”‚  x_position                   12.454    x_velocity                  -45.896  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-33.55 (best=207.31@425984)
æ­¥æ•° 458,752: Reward=-33.55, Best=224.11@458752, Sharpness=1.4193, Î»_max=-18.4649
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env        11s  72%    value_loss        0.171  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.503  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  19%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 55s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.862  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              205.530    episode_length              276.096  â”‚
â”‚  x_position                  -35.733    x_velocity                  -69.126  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-30.71 (best=224.11@458752)
æ­¥æ•° 491,520: Reward=-30.71, Best=224.11@458752, Sharpness=1.2943, Î»_max=-25.4397
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env        15s  72%    value_loss        0.191  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.503  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s  19%    approx_kl         0.000  â”‚
â”‚  Uptime           3m 7s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              239.918    episode_length              280.404  â”‚
â”‚  x_position                   14.429    x_velocity                  -39.034  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-35.61 (best=224.11@458752)
æ­¥æ•° 524,288: Reward=-35.61, Best=239.92@524288, Sharpness=1.2629, Î»_max=-18.1368

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 15_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_15/vec_stats.npz
[J&R] base_task=15, new_task=15_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_15/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.536  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.014  â”‚
â”‚  SPS               8.2K      Misc        0s   0%    old_approx_kl     0.034  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.028  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.290  â”‚
â”‚  Remainiâ€¦           56s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.619  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.255    episode_length               50.047  â”‚
â”‚  x_position                   -5.895    x_velocity                  -54.045  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-73.47 (best=N/A)
æ­¥æ•° 32,768: Reward=-73.47, Best=-4.26@32768, Sharpness=1.4045, Î»_max=-41.1618
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.638  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.053  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.024  â”‚
â”‚  Epoch                2    Train         0s  11%    approx_kl         0.022  â”‚
â”‚  Uptime             15s      Forwaâ€¦      0s   2%    clipfrac          0.234  â”‚
â”‚  Remainiâ€¦        2m 26s      Learn       0s   7%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.887  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                3.262    episode_length               72.949  â”‚
â”‚  x_position                  -11.677    x_velocity                  -69.310  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-14.79 (best=-4.26@32768)
æ­¥æ•° 65,536: Reward=-14.79, Best=3.26@65536, Sharpness=1.4751, Î»_max=-36.8639
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.515  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.084  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                3    Train         0s  11%    approx_kl         0.016  â”‚
â”‚  Uptime             27s      Forwaâ€¦      0s   2%    clipfrac          0.193  â”‚
â”‚  Remainiâ€¦        2m 32s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                6.209    episode_length               84.292  â”‚
â”‚  x_position                  -15.758    x_velocity                  -77.646  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-12.99 (best=3.26@65536)
æ­¥æ•° 98,304: Reward=-12.99, Best=6.21@98304, Sharpness=1.4317, Î»_max=-38.7111
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 18.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.409  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.110  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         0s  11%    approx_kl         0.012  â”‚
â”‚  Uptime             39s      Forwaâ€¦      0s   2%    clipfrac          0.151  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.147    episode_length              105.818  â”‚
â”‚  x_position                  -18.035    x_velocity                  -81.118  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-11.28 (best=6.21@98304)
æ­¥æ•° 131,072: Reward=-11.28, Best=24.15@131072, Sharpness=1.3920, Î»_max=-33.1837
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.370  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.132  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         0s  11%    approx_kl         0.011  â”‚
â”‚  Uptime             51s      Forwaâ€¦      0s   2%    clipfrac          0.138  â”‚
â”‚  Remainiâ€¦         2m 5s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               25.044    episode_length              114.198  â”‚
â”‚  x_position                  -22.334    x_velocity                  -88.555  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-13.17 (best=24.15@131072)
æ­¥æ•° 163,840: Reward=-13.17, Best=25.04@163840, Sharpness=1.7398, Î»_max=-24.1340
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.327  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.151  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         1s  11%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.132  â”‚
â”‚  Remainiâ€¦        1m 49s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.351    episode_length              117.992  â”‚
â”‚  x_position                  -21.751    x_velocity                  -88.024  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-13.97 (best=25.04@163840)
æ­¥æ•° 196,608: Reward=-13.97, Best=29.35@196608, Sharpness=1.5663, Î»_max=-27.2146
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 18.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  71%    value_loss        0.269  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.167  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                7    Train         1s  19%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 17s      Forwaâ€¦      0s   3%    clipfrac          0.115  â”‚
â”‚  Remainiâ€¦        1m 52s      Learn       0s  10%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               46.361    episode_length              135.807  â”‚
â”‚  x_position                  -22.432    x_velocity                  -88.738  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-24.99 (best=29.35@196608)
æ­¥æ•° 229,376: Reward=-24.99, Best=46.36@229376, Sharpness=1.4617, Î»_max=-30.8935
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  71%    value_loss        0.258  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.178  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                8    Train         1s  19%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 29s      Forwaâ€¦      0s   3%    clipfrac          0.112  â”‚
â”‚  Remainiâ€¦        1m 26s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               45.207    episode_length              142.384  â”‚
â”‚  x_position                  -28.043    x_velocity                  -96.432  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-8.47 (best=46.36@229376)
æ­¥æ•° 262,144: Reward=-8.47, Best=46.36@229376, Sharpness=1.3931, Î»_max=-24.5786
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         6s  71%    value_loss        0.252  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.189  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         1s  19%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 39s      Forwaâ€¦      0s   3%    clipfrac          0.093  â”‚
â”‚  Remainiâ€¦         1m 2s      Learn       0s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.910  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               63.452    episode_length              162.443  â”‚
â”‚  x_position                  -29.090    x_velocity                  -98.143  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=0.33 (best=46.36@229376)
æ­¥æ•° 294,912: Reward=0.33, Best=63.45@294912, Sharpness=1.4364, Î»_max=-28.5721
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         6s  71%    value_loss        0.226  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.199  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  19%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 53s      Forwaâ€¦      0s   3%    clipfrac          0.075  â”‚
â”‚  Remainiâ€¦        1m 12s      Learn       0s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               70.578    episode_length              172.651  â”‚
â”‚  x_position                  -30.665    x_velocity                 -101.173  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-2.44 (best=63.45@294912)
æ­¥æ•° 327,680: Reward=-2.44, Best=70.58@327680, Sharpness=1.7565, Î»_max=9.4434
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 18.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  80%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        10s  71%    value_loss        0.227  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.207  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  19%    approx_kl         0.005  â”‚
â”‚  Uptime           2m 5s      Forwaâ€¦      0s   3%    clipfrac          0.052  â”‚
â”‚  Remainiâ€¦           52s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              102.310    episode_length              190.950  â”‚
â”‚  x_position                  -17.114    x_velocity                  -87.649  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=5.98 (best=70.58@327680)
æ­¥æ•° 360,448: Reward=5.98, Best=102.31@360448, Sharpness=1.7103, Î»_max=-22.2855
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env        10s  73%    value_loss        0.219  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.215  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         2s  18%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   3%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦           50s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              124.401    episode_length              213.000  â”‚
â”‚  x_position                  -19.006    x_velocity                  -87.493  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=0.33 (best=102.31@360448)
æ­¥æ•° 393,216: Reward=0.33, Best=124.40@393216, Sharpness=1.8101, Î»_max=-19.7780
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 18.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env        10s  73%    value_loss        0.196  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.221  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  18%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 36s      Forwaâ€¦      0s   3%    clipfrac          0.030  â”‚
â”‚  Remainiâ€¦           34s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              128.624    episode_length              208.474  â”‚
â”‚  x_position                  -19.959    x_velocity                  -78.762  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-22.03 (best=124.40@393216)
æ­¥æ•° 425,984: Reward=-22.03, Best=128.62@425984, Sharpness=1.6706, Î»_max=-22.0946
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 19.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env        10s  73%    value_loss        0.228  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.225  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  18%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 51s      Forwaâ€¦      0s   3%    clipfrac          0.007  â”‚
â”‚  Remainiâ€¦           19s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.873  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              166.862    episode_length              236.675  â”‚
â”‚  x_position                  -12.631    x_velocity                  -68.589  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=8.42 (best=128.62@425984)
æ­¥æ•° 458,752: Reward=8.42, Best=166.86@458752, Sharpness=1.4864, Î»_max=-15.1688
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 20.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env        10s  73%    value_loss        0.208  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.227  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  18%    approx_kl         0.000  â”‚
â”‚  Uptime           3m 4s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.862  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              172.984    episode_length              256.977  â”‚
â”‚  x_position                  -21.108    x_velocity                  -82.656  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-3.76 (best=166.86@458752)
æ­¥æ•° 491,520: Reward=-3.76, Best=172.98@491520, Sharpness=1.9087, Î»_max=-25.0605
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.040  â”‚
â”‚  Params          135.3K      Env        14s  73%    value_loss        0.261  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.227  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  18%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 15s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.818  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              219.780    episode_length              289.657  â”‚
â”‚  x_position                  -11.232    x_velocity                  -68.379  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=8.36 (best=172.98@491520)
æ­¥æ•° 524,288: Reward=8.36, Best=219.78@524288, Sharpness=1.6343, Î»_max=16.8776

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 15_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_15/vec_stats.npz
[J&R] base_task=15, new_task=15_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_15/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 5.8%  GPU: 0.0%  DRAM: 0.2%   VRAM: 0.8%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.0%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 24.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.472  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.175  â”‚
â”‚  SPS               5.0K      Misc        0s   0%    old_approx_kl     0.060  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.054  â”‚
â”‚  Uptime              6s      Forwaâ€¦      0s   0%    clipfrac          0.398  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.530  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.870    episode_length               27.672  â”‚
â”‚  x_position                   -1.855    x_velocity                  -29.404  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-10.23 (best=N/A)
æ­¥æ•° 32,768: Reward=-10.23, Best=-1.87@32768, Sharpness=2.7447, Î»_max=-71.3497
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 17.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         5s  81%    value_loss        0.435  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          11.208  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.034  â”‚
â”‚  Epoch                2    Train         0s  12%    approx_kl         0.029  â”‚
â”‚  Uptime             16s      Forwaâ€¦      0s   2%    clipfrac          0.239  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s   8%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.697  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               35.594    episode_length               69.488  â”‚
â”‚  x_position                   -4.463    x_velocity                  -33.543  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=92.35 (best=-1.87@32768)
æ­¥æ•° 65,536: Reward=92.35, Best=35.59@65536, Sharpness=2.3987, Î»_max=58.6735
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 17.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         5s  81%    value_loss        0.358  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          11.216  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                3    Train         0s  12%    approx_kl         0.025  â”‚
â”‚  Uptime             31s      Forwaâ€¦      0s   2%    clipfrac          0.229  â”‚
â”‚  Remainiâ€¦        2m 57s      Learn       0s   8%    importance        0.996  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.753  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               97.104    episode_length              116.721  â”‚
â”‚  x_position                    0.685    x_velocity                  -19.012  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=164.25 (best=35.59@65536)
æ­¥æ•° 98,304: Reward=164.25, Best=97.10@98304, Sharpness=2.0990, Î»_max=-70.0086
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env         5s  81%    value_loss        0.284  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          11.229  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.025  â”‚
â”‚  Epoch                4    Train         0s  12%    approx_kl         0.021  â”‚
â”‚  Uptime             41s      Forwaâ€¦      0s   2%    clipfrac          0.203  â”‚
â”‚  Remainiâ€¦        1m 54s      Learn       0s   8%    importance        0.996  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.803  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              143.809    episode_length              146.568  â”‚
â”‚  x_position                    8.843    x_velocity                   -1.995  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=216.15 (best=97.10@98304)
æ­¥æ•° 131,072: Reward=216.15, Best=143.81@131072, Sharpness=2.3816, Î»_max=-62.7240
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         5s  81%    value_loss        0.205  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          11.246  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.024  â”‚
â”‚  Epoch                5    Train         0s  12%    approx_kl         0.022  â”‚
â”‚  Uptime             55s      Forwaâ€¦      0s   2%    clipfrac          0.199  â”‚
â”‚  Remainiâ€¦        2m 19s      Learn       0s   8%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.807  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              162.612    episode_length              165.053  â”‚
â”‚  x_position                   11.293    x_velocity                   -1.587  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=231.27 (best=143.81@131072)
æ­¥æ•° 163,840: Reward=231.27, Best=162.61@163840, Sharpness=2.5368, Î»_max=-90.7340
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env         8s  81%    value_loss        0.183  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          11.263  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                6    Train         1s  12%    approx_kl         0.016  â”‚
â”‚  Uptime           1m 5s      Forwaâ€¦      0s   2%    clipfrac          0.163  â”‚
â”‚  Remainiâ€¦        1m 36s      Learn       1s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.808  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              169.950    episode_length              159.366  â”‚
â”‚  x_position                   17.928    x_velocity                   11.407  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=830.47 (best=162.61@163840)
æ­¥æ•° 196,608: Reward=830.47, Best=169.95@196608, Sharpness=2.8859, Î»_max=-83.4721
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.159  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.285  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                7    Train         1s  14%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 19s      Forwaâ€¦      0s   3%    clipfrac          0.149  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       1s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.790  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              204.266    episode_length              184.618  â”‚
â”‚  x_position                   27.057    x_velocity                   20.600  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=298.69 (best=169.95@196608)
æ­¥æ•° 229,376: Reward=298.69, Best=204.27@229376, Sharpness=2.6680, Î»_max=85.1928
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 17.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.038  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.148  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.307  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                8    Train         1s  14%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   3%    clipfrac          0.129  â”‚
â”‚  Remainiâ€¦        1m 56s      Learn       1s  14%    importance        0.998  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.795  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              220.897    episode_length              188.113  â”‚
â”‚  x_position                   36.563    x_velocity                   33.747  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=101.29 (best=204.27@229376)
æ­¥æ•° 262,144: Reward=101.29, Best=220.90@262144, Sharpness=2.2937, Î»_max=-39.0891
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.136  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.327  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                9    Train         1s  14%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 47s      Forwaâ€¦      0s   3%    clipfrac          0.118  â”‚
â”‚  Remainiâ€¦        1m 15s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.790  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              248.992    episode_length              206.494  â”‚
â”‚  x_position                   53.539    x_velocity                   43.556  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=577.35 (best=220.90@262144)
æ­¥æ•° 294,912: Reward=577.35, Best=248.99@294912, Sharpness=2.3319, Î»_max=-106.9463
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         8s  76%    value_loss        0.131  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.344  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               10    Train         1s  14%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 59s      Forwaâ€¦      0s   3%    clipfrac          0.095  â”‚
â”‚  Remainiâ€¦         1m 2s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.794  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              247.247    episode_length              205.341  â”‚
â”‚  x_position                   47.673    x_velocity                   42.959  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=202.49 (best=248.99@294912)
æ­¥æ•° 327,680: Reward=202.49, Best=248.99@294912, Sharpness=2.1815, Î»_max=-74.5395
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env        11s  76%    value_loss        0.132  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.353  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               11    Train         2s  14%    approx_kl         0.008  â”‚
â”‚  Uptime          2m 13s      Forwaâ€¦      0s   3%    clipfrac          0.079  â”‚
â”‚  Remainiâ€¦           58s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.779  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              279.581    episode_length              222.146  â”‚
â”‚  x_position                   67.207    x_velocity                   58.574  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=493.17 (best=248.99@294912)
æ­¥æ•° 360,448: Reward=493.17, Best=279.58@360448, Sharpness=2.2170, Î»_max=-89.4939
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.047  â”‚
â”‚  Params          135.3K      Env        11s  67%    value_loss        0.137  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.359  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         2s  23%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 25s      Forwaâ€¦      0s   4%    clipfrac          0.056  â”‚
â”‚  Remainiâ€¦           39s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.781  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              310.856    episode_length              236.180  â”‚
â”‚  x_position                   77.975    x_velocity                   75.891  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=287.60 (best=279.58@360448)
æ­¥æ•° 393,216: Reward=287.60, Best=310.86@393216, Sharpness=2.1664, Î»_max=-103.8630
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.036  â”‚
â”‚  Params          135.3K      Env        11s  67%    value_loss        0.126  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.364  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         2s  23%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 37s      Forwaâ€¦      0s   4%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦           27s      Learn       1s  13%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.771  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              308.906    episode_length              235.810  â”‚
â”‚  x_position                   80.153    x_velocity                   74.301  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=284.25 (best=310.86@393216)
æ­¥æ•° 425,984: Reward=284.25, Best=310.86@393216, Sharpness=2.1168, Î»_max=-114.6623
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.039  â”‚
â”‚  Params          135.3K      Env        11s  67%    value_loss        0.146  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.366  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               14    Train         2s  23%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 50s      Forwaâ€¦      0s   4%    clipfrac          0.016  â”‚
â”‚  Remainiâ€¦           16s      Learn       1s  13%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.745  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              317.013    episode_length              243.711  â”‚
â”‚  x_position                   78.927    x_velocity                   74.546  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=992.56 (best=310.86@393216)
æ­¥æ•° 458,752: Reward=992.56, Best=317.01@458752, Sharpness=2.0311, Î»_max=-57.5396
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.048  â”‚
â”‚  Params          135.3K      Env        11s  67%    value_loss        0.135  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.368  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  23%    approx_kl         0.000  â”‚
â”‚  Uptime           3m 2s      Forwaâ€¦      0s   4%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.759  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              361.665    episode_length              247.127  â”‚
â”‚  x_position                  120.482    x_velocity                  115.793  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=651.30 (best=317.01@458752)
æ­¥æ•° 491,520: Reward=651.30, Best=361.67@491520, Sharpness=2.6071, Î»_max=-106.7277
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  76%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env        17s  67%    value_loss        0.158  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.368  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  23%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 16s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.713  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              316.404    episode_length              243.942  â”‚
â”‚  x_position                   87.443    x_velocity                   73.710  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=692.66 (best=361.67@491520)
æ­¥æ•° 524,288: Reward=692.66, Best=361.67@491520, Sharpness=2.5295, Î»_max=-96.5238

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 15_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_15/vec_stats.npz
[J&R] base_task=15, new_task=15_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_15/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.7%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 21.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        3.476  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          22.229  â”‚
â”‚  SPS               7.0K      Misc        0s   0%    old_approx_kl     0.066  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.061  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.345  â”‚
â”‚  Remainiâ€¦         1m 7s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.152  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.617    episode_length               17.105  â”‚
â”‚  x_position                   -1.598    x_velocity                  -25.624  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-13.94 (best=N/A)
æ­¥æ•° 32,768: Reward=-13.94, Best=-8.62@32768, Sharpness=5.1355, Î»_max=27.6079
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  73%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         3s  65%    value_loss        1.463  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          22.273  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.032  â”‚
â”‚  Epoch                2    Train         1s  26%    approx_kl         0.029  â”‚
â”‚  Uptime             15s      Forwaâ€¦      0s   7%    clipfrac          0.230  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       0s  10%    importance        0.997  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.228  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.868    episode_length               19.198  â”‚
â”‚  x_position                   -1.958    x_velocity                  -27.957  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-8.84 (best=-8.62@32768)
æ­¥æ•° 65,536: Reward=-8.84, Best=-8.62@32768, Sharpness=3.9013, Î»_max=27.7176
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  73%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         3s  65%    value_loss        1.015  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          22.317  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                3    Train         1s  26%    approx_kl         0.020  â”‚
â”‚  Uptime             26s      Forwaâ€¦      0s   7%    clipfrac          0.176  â”‚
â”‚  Remainiâ€¦         2m 9s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.134  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.844    episode_length               19.738  â”‚
â”‚  x_position                   -2.023    x_velocity                  -28.470  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-2.23 (best=-8.62@32768)
æ­¥æ•° 98,304: Reward=-2.23, Best=-8.62@32768, Sharpness=4.0302, Î»_max=23.6282
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  73%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         3s  65%    value_loss        0.824  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          22.355  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                4    Train         1s  26%    approx_kl         0.017  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   7%    clipfrac          0.164  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s  10%    importance        1.002  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.097  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.900    episode_length               19.966  â”‚
â”‚  x_position                   -2.007    x_velocity                  -27.752  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-8.83 (best=-8.62@32768)
æ­¥æ•° 131,072: Reward=-8.83, Best=-7.90@131072, Sharpness=4.4237, Î»_max=22.1291
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  73%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  65%    value_loss        0.701  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          22.395  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                5    Train         1s  26%    approx_kl         0.015  â”‚
â”‚  Uptime             47s      Forwaâ€¦      0s   7%    clipfrac          0.143  â”‚
â”‚  Remainiâ€¦        1m 48s      Learn       0s  10%    importance        0.998  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.099  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.518    episode_length               19.873  â”‚
â”‚  x_position                   -1.960    x_velocity                  -27.277  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-17.72 (best=-7.90@131072)
æ­¥æ•° 163,840: Reward=-17.72, Best=-7.52@163840, Sharpness=3.1096, Î»_max=27.8313
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  73%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         6s  65%    value_loss        0.641  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          22.429  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                6    Train         1s  26%    approx_kl         0.014  â”‚
â”‚  Uptime             57s      Forwaâ€¦      0s   7%    clipfrac          0.136  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       0s  10%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.079  â”‚
â”‚                              Misc        0s   6%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.432    episode_length               20.230  â”‚
â”‚  x_position                   -2.013    x_velocity                  -27.546  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=3.74 (best=-7.52@163840)
æ­¥æ•° 196,608: Reward=3.74, Best=-7.43@196608, Sharpness=4.1582, Î»_max=22.3257
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.598  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          22.456  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                7    Train         1s  12%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 9s      Forwaâ€¦      0s   2%    clipfrac          0.118  â”‚
â”‚  Remainiâ€¦        1m 38s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.035  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.792    episode_length               20.168  â”‚
â”‚  x_position                   -1.922    x_velocity                  -26.844  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=6.30 (best=-7.43@196608)
æ­¥æ•° 229,376: Reward=6.30, Best=-6.79@229376, Sharpness=4.3099, Î»_max=24.2808
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.564  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          22.478  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                8    Train         1s  12%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 19s      Forwaâ€¦      0s   2%    clipfrac          0.105  â”‚
â”‚  Remainiâ€¦        1m 13s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.027  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.173    episode_length               20.142  â”‚
â”‚  x_position                   -1.867    x_velocity                  -26.200  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-7.31 (best=-6.79@229376)
æ­¥æ•° 262,144: Reward=-7.31, Best=-6.17@262144, Sharpness=3.2637, Î»_max=18.2168
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.526  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          22.498  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                9    Train         1s  12%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 32s      Forwaâ€¦      0s   2%    clipfrac          0.089  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.001  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.848    episode_length               20.410  â”‚
â”‚  x_position                   -1.899    x_velocity                  -26.141  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-3.07 (best=-6.17@262144)
æ­¥æ•° 294,912: Reward=-3.07, Best=-5.85@294912, Sharpness=3.1116, Î»_max=23.4291
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.526  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          22.516  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  12%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 43s      Forwaâ€¦      0s   2%    clipfrac          0.068  â”‚
â”‚  Remainiâ€¦           57s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.069  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.704    episode_length               20.772  â”‚
â”‚  x_position                   -1.969    x_velocity                  -26.357  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=1.10 (best=-5.85@294912)
æ­¥æ•° 327,680: Reward=1.10, Best=-5.70@327680, Sharpness=3.2736, Î»_max=19.9786
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 11.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.509  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          22.527  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         2s  12%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 54s      Forwaâ€¦      0s   2%    clipfrac          0.055  â”‚
â”‚  Remainiâ€¦           45s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.026  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.383    episode_length               19.815  â”‚
â”‚  x_position                   -1.770    x_velocity                  -25.084  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-2.22 (best=-5.70@327680)
æ­¥æ•° 360,448: Reward=-2.22, Best=-5.38@360448, Sharpness=3.0850, Î»_max=20.6278
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.509  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          22.538  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         2s  14%    approx_kl         0.004  â”‚
â”‚  Uptime           2m 7s      Forwaâ€¦      0s   2%    clipfrac          0.040  â”‚
â”‚  Remainiâ€¦           42s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.052  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.171    episode_length               20.380  â”‚
â”‚  x_position                   -1.842    x_velocity                  -25.435  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=1.56 (best=-5.38@360448)
æ­¥æ•° 393,216: Reward=1.56, Best=-5.17@393216, Sharpness=3.2718, Î»_max=15.9630
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.512  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          22.547  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         2s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 17s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           22s      Learn       1s  13%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.024  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.681    episode_length               20.334  â”‚
â”‚  x_position                   -1.777    x_velocity                  -24.898  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=2.93 (best=-5.17@393216)
æ­¥æ•° 425,984: Reward=2.93, Best=-4.68@425984, Sharpness=3.3111, Î»_max=14.7129
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.527  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          22.551  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  14%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   2%    clipfrac          0.006  â”‚
â”‚  Remainiâ€¦           15s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.026  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.602    episode_length               20.245  â”‚
â”‚  x_position                   -1.760    x_velocity                  -24.732  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=3.66 (best=-4.68@425984)
æ­¥æ•° 458,752: Reward=3.66, Best=-4.60@458752, Sharpness=3.6072, Î»_max=18.6069
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 18.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.524  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          22.553  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 40s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.045  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.681    episode_length               20.431  â”‚
â”‚  x_position                   -1.796    x_velocity                  -24.995  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-1.16 (best=-4.60@458752)
æ­¥æ•° 491,520: Reward=-1.16, Best=-4.60@458752, Sharpness=3.4164, Î»_max=21.1947
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env        13s  76%    value_loss        0.563  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          22.553  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 56s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.062  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.766    episode_length               20.423  â”‚
â”‚  x_position                   -1.832    x_velocity                  -25.072  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-1.03 (best=-4.60@458752)
æ­¥æ•° 524,288: Reward=-1.03, Best=-4.60@458752, Sharpness=3.1166, Î»_max=18.4489

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 15_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 15 step sweep å®Œæˆã€‚
