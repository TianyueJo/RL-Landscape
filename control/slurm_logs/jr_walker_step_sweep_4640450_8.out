==========================================
[Jump & Retrain] Walker2d task 8 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 10:54:03 EST 2025
èŠ‚ç‚¹: node9
==========================================
[Base] task=8, env=Walker2d-v4, best_model=final_model.pt, best_reward=838.25, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_8/vec_stats.npz
[J&R] base_task=8, new_task=8_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_8/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.3%  DRAM: 0.3%   VRAM: 1.2%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.247  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.665  â”‚
â”‚  SPS               3.8K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         2s   0%    approx_kl         0.024  â”‚
â”‚  Uptime              8s      Forwaâ€¦      0s   0%    clipfrac          0.244  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.240  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               19.734    episode_length               45.571  â”‚
â”‚  x_position                   -0.771    x_velocity                  -25.594  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=266.89 (best=N/A)
æ­¥æ•° 32,768: Reward=266.89, Best=19.73@32768, Sharpness=1.1680, Î»_max=-15.8883
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.0%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  64%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         2s  51%    value_loss        0.462  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.696  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         2s  35%    approx_kl         0.018  â”‚
â”‚  Uptime             18s      Forwaâ€¦      0s   7%    clipfrac          0.193  â”‚
â”‚  Remainiâ€¦        2m 16s      Learn       0s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.815  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               45.927    episode_length               88.248  â”‚
â”‚  x_position                   -5.572    x_velocity                  -41.846  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=1136.48 (best=19.73@32768)
æ­¥æ•° 65,536: Reward=1136.48, Best=45.93@65536, Sharpness=1.2324, Î»_max=-26.5537
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.1%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  64%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         2s  51%    value_loss        0.286  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.717  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         2s  35%    approx_kl         0.012  â”‚
â”‚  Uptime             30s      Forwaâ€¦      0s   7%    clipfrac          0.140  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s  14%    importance        0.998  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.882  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               86.186    episode_length              145.205  â”‚
â”‚  x_position                  -14.009    x_velocity                  -58.244  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-0.84 (best=45.93@65536)
æ­¥æ•° 98,304: Reward=-0.84, Best=86.19@98304, Sharpness=1.1622, Î»_max=-20.1402
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  64%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.035  â”‚
â”‚  Params          135.3K      Env         2s  51%    value_loss        0.225  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.739  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         2s  35%    approx_kl         0.011  â”‚
â”‚  Uptime             40s      Forwaâ€¦      0s   7%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦        1m 55s      Learn       0s  14%    importance        0.999  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               98.167    episode_length              176.346  â”‚
â”‚  x_position                  -25.262    x_velocity                  -77.248  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=28.00 (best=86.19@98304)
æ­¥æ•° 131,072: Reward=28.00, Best=98.17@131072, Sharpness=1.1856, Î»_max=-20.0950
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  64%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         2s  51%    value_loss        0.210  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.764  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         2s  35%    approx_kl         0.010  â”‚
â”‚  Uptime             50s      Forwaâ€¦      0s   7%    clipfrac          0.120  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.916  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              123.642    episode_length              193.397  â”‚
â”‚  x_position                  -20.956    x_velocity                  -68.743  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=92.07 (best=98.17@131072)
æ­¥æ•° 163,840: Reward=92.07, Best=123.64@163840, Sharpness=1.2433, Î»_max=-14.5580
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.7%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  64%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         6s  51%    value_loss        0.160  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.781  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         2s  35%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 0s      Forwaâ€¦      0s   7%    clipfrac          0.103  â”‚
â”‚  Remainiâ€¦        1m 34s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   5%    explained_varâ€¦    0.916  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              159.737    episode_length              221.771  â”‚
â”‚  x_position                  -12.424    x_velocity                  -60.871  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=1070.89 (best=123.64@163840)
æ­¥æ•° 196,608: Reward=1070.89, Best=159.74@196608, Sharpness=1.2630, Î»_max=-24.1193
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.158  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.805  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  14%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 11s      Forwaâ€¦      0s   2%    clipfrac          0.084  â”‚
â”‚  Remainiâ€¦        1m 31s      Learn       1s  11%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.916  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              146.421    episode_length              213.546  â”‚
â”‚  x_position                   -8.104    x_velocity                  -66.003  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=28.49 (best=159.74@196608)
æ­¥æ•° 229,376: Reward=28.49, Best=159.74@196608, Sharpness=1.1941, Î»_max=-20.5395
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.126  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.825  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         2s  14%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 20s      Forwaâ€¦      0s   2%    clipfrac          0.070  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              190.816    episode_length              243.045  â”‚
â”‚  x_position                    4.492    x_velocity                  -50.955  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=48.16 (best=159.74@196608)
æ­¥æ•° 262,144: Reward=48.16, Best=190.82@262144, Sharpness=1.2351, Î»_max=-19.7739
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.036  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.137  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.846  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch                9    Train         2s  14%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   2%    clipfrac          0.055  â”‚
â”‚  Remainiâ€¦           58s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.911  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              196.799    episode_length              264.713  â”‚
â”‚  x_position                    0.253    x_velocity                  -66.520  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=76.39 (best=190.82@262144)
æ­¥æ•° 294,912: Reward=76.39, Best=196.80@294912, Sharpness=1.2071, Î»_max=-16.6970
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.130  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.863  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               10    Train         2s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 39s      Forwaâ€¦      0s   2%    clipfrac          0.045  â”‚
â”‚  Remainiâ€¦           50s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              214.108    episode_length              273.280  â”‚
â”‚  x_position                   13.567    x_velocity                  -57.738  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=76.05 (best=196.80@294912)
æ­¥æ•° 327,680: Reward=76.05, Best=214.11@327680, Sharpness=1.2354, Î»_max=-19.3242
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.043  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.126  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.872  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         3s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 49s      Forwaâ€¦      0s   2%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦           41s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.910  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              271.643    episode_length              313.458  â”‚
â”‚  x_position                   35.722    x_velocity                  -40.168  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=601.62 (best=214.11@327680)
æ­¥æ•° 360,448: Reward=601.62, Best=271.64@360448, Sharpness=1.1477, Î»_max=-15.8193
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.117  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.879  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 59s      Forwaâ€¦      0s   2%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              295.882    episode_length              340.254  â”‚
â”‚  x_position                   38.478    x_velocity                  -42.585  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=1134.31 (best=271.64@360448)
æ­¥æ•° 393,216: Reward=1134.31, Best=295.88@393216, Sharpness=1.1388, Î»_max=-19.1027
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.7%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.048  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.123  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.882  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.016  â”‚
â”‚  Remainiâ€¦           25s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              263.813    episode_length              313.551  â”‚
â”‚  x_position                   31.467    x_velocity                  -48.090  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=50.20 (best=295.88@393216)
æ­¥æ•° 425,984: Reward=50.20, Best=295.88@393216, Sharpness=1.2558, Î»_max=-19.7288
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.125  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.885  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         3s  14%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   2%    clipfrac          0.010  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.893  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              290.428    episode_length              341.162  â”‚
â”‚  x_position                   23.244    x_velocity                  -48.945  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=1126.92 (best=295.88@393216)
æ­¥æ•° 458,752: Reward=1126.92, Best=295.88@393216, Sharpness=1.2564, Î»_max=-20.4229
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.062  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.145  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.886  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 32s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.875  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              319.424    episode_length              352.110  â”‚
â”‚  x_position                   46.985    x_velocity                  -30.838  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=41.26 (best=295.88@393216)
æ­¥æ•° 491,520: Reward=41.26, Best=319.42@491520, Sharpness=1.2036, Î»_max=-13.4412
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 11.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.145  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.886  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 42s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.857  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              363.837    episode_length              394.387  â”‚
â”‚  x_position                   45.545    x_velocity                  -28.474  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=42.21 (best=319.42@491520)
æ­¥æ•° 524,288: Reward=42.21, Best=363.84@524288, Sharpness=1.2554, Î»_max=-15.4690

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 8_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_8/vec_stats.npz
[J&R] base_task=8, new_task=8_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_8/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.253  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.577  â”‚
â”‚  SPS               8.8K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.249  â”‚
â”‚  Remainiâ€¦           52s      Learn       0s   0%    importance        0.996  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.277  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                7.944    episode_length               53.250  â”‚
â”‚  x_position                   -4.144    x_velocity                  -45.022  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=127.55 (best=N/A)
æ­¥æ•° 32,768: Reward=127.55, Best=7.94@32768, Sharpness=1.2231, Î»_max=-29.2691
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.1%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         2s  79%    value_loss        0.432  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.613  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         0s  12%    approx_kl         0.018  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.184  â”‚
â”‚  Remainiâ€¦        2m 17s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.809  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               47.266    episode_length               86.892  â”‚
â”‚  x_position                   -4.704    x_velocity                  -39.155  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=49.59 (best=7.94@32768)
æ­¥æ•° 65,536: Reward=49.59, Best=47.27@65536, Sharpness=1.2321, Î»_max=-29.5158
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         2s  79%    value_loss        0.277  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.639  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         0s  12%    approx_kl         0.013  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.142  â”‚
â”‚  Remainiâ€¦         2m 3s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.890  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               80.732    episode_length              147.558  â”‚
â”‚  x_position                  -17.254    x_velocity                  -66.038  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=826.53 (best=47.27@65536)
æ­¥æ•° 98,304: Reward=826.53, Best=80.73@98304, Sharpness=1.2262, Î»_max=-29.1681
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.9%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.039  â”‚
â”‚  Params          135.3K      Env         2s  79%    value_loss        0.248  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.673  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                4    Train         0s  12%    approx_kl         0.010  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.117  â”‚
â”‚  Remainiâ€¦        1m 56s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              112.252    episode_length              189.818  â”‚
â”‚  x_position                  -26.114    x_velocity                  -76.553  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=1074.00 (best=80.73@98304)
æ­¥æ•° 131,072: Reward=1074.00, Best=112.25@131072, Sharpness=1.2012, Î»_max=-25.9556
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.9%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         2s  79%    value_loss        0.198  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.702  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                5    Train         0s  12%    approx_kl         0.009  â”‚
â”‚  Uptime             45s      Forwaâ€¦      0s   2%    clipfrac          0.107  â”‚
â”‚  Remainiâ€¦        1m 50s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              108.135    episode_length              189.558  â”‚
â”‚  x_position                  -29.403    x_velocity                  -80.410  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=30.20 (best=112.25@131072)
æ­¥æ•° 163,840: Reward=30.20, Best=112.25@131072, Sharpness=1.2507, Î»_max=-29.1319
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.177  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.724  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         1s  12%    approx_kl         0.009  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   2%    clipfrac          0.101  â”‚
â”‚  Remainiâ€¦        1m 27s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.920  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              164.266    episode_length              214.284  â”‚
â”‚  x_position                   -3.081    x_velocity                  -48.881  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=159.99 (best=112.25@131072)
æ­¥æ•° 196,608: Reward=159.99, Best=164.27@196608, Sharpness=1.1944, Î»_max=-24.5229
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.159  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.741  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         1s  14%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 5s      Forwaâ€¦      0s   2%    clipfrac          0.094  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       0s  11%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.919  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              163.879    episode_length              231.034  â”‚
â”‚  x_position                  -15.582    x_velocity                  -65.928  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=1130.08 (best=164.27@196608)
æ­¥æ•° 229,376: Reward=1130.08, Best=164.27@196608, Sharpness=1.2257, Î»_max=-14.6551
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.136  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.759  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         1s  14%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 15s      Forwaâ€¦      0s   2%    clipfrac          0.070  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       0s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.922  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              216.545    episode_length              273.626  â”‚
â”‚  x_position                    0.478    x_velocity                  -55.629  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=104.98 (best=164.27@196608)
æ­¥æ•° 262,144: Reward=104.98, Best=216.55@262144, Sharpness=1.2303, Î»_max=-18.1329
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.030  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.119  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.774  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch                9    Train         1s  14%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 25s      Forwaâ€¦      0s   2%    clipfrac          0.058  â”‚
â”‚  Remainiâ€¦         1m 1s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.915  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              220.098    episode_length              271.111  â”‚
â”‚  x_position                   11.271    x_velocity                  -49.566  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=1073.58 (best=216.55@262144)
æ­¥æ•° 294,912: Reward=1073.58, Best=220.10@294912, Sharpness=1.2169, Î»_max=-7.1693
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         5s  77%    value_loss        0.114  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.789  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  14%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 36s      Forwaâ€¦      0s   2%    clipfrac          0.049  â”‚
â”‚  Remainiâ€¦           58s      Learn       0s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.914  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              252.757    episode_length              300.030  â”‚
â”‚  x_position                   13.645    x_velocity                  -45.678  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=706.37 (best=220.10@294912)
æ­¥æ•° 327,680: Reward=706.37, Best=252.76@327680, Sharpness=1.2642, Î»_max=-25.3436
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         8s  77%    value_loss        0.124  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.800  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 47s      Forwaâ€¦      0s   2%    clipfrac          0.040  â”‚
â”‚  Remainiâ€¦           43s      Learn       0s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.909  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              294.273    episode_length              318.700  â”‚
â”‚  x_position                   48.596    x_velocity                  -22.735  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=500.31 (best=252.76@327680)
æ­¥æ•° 360,448: Reward=500.31, Best=294.27@360448, Sharpness=1.2265, Î»_max=-28.4050
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.105  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.807  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               12    Train         1s  12%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 57s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           33s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.917  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              236.568    episode_length              287.507  â”‚
â”‚  x_position                   18.955    x_velocity                  -49.403  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=697.53 (best=294.27@360448)
æ­¥æ•° 393,216: Reward=697.53, Best=294.27@360448, Sharpness=1.2285, Î»_max=-25.6969
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.058  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.106  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.812  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  12%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 7s      Forwaâ€¦      0s   2%    clipfrac          0.018  â”‚
â”‚  Remainiâ€¦           22s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              323.503    episode_length              354.725  â”‚
â”‚  x_position                   49.492    x_velocity                  -29.322  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=71.18 (best=294.27@360448)
æ­¥æ•° 425,984: Reward=71.18, Best=323.50@425984, Sharpness=1.1891, Î»_max=-22.6181
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.120  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.814  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  12%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 17s      Forwaâ€¦      0s   2%    clipfrac          0.007  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.894  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              405.481    episode_length              386.565  â”‚
â”‚  x_position                  109.702    x_velocity                   20.971  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=559.15 (best=323.50@425984)
æ­¥æ•° 458,752: Reward=559.15, Best=405.48@458752, Sharpness=1.2438, Î»_max=-11.8192
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         8s  79%    value_loss        0.134  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.816  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               15    Train         1s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 27s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.875  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              330.597    episode_length              336.747  â”‚
â”‚  x_position                   68.450    x_velocity                   -4.347  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=75.53 (best=405.48@458752)
æ­¥æ•° 491,520: Reward=75.53, Best=405.48@458752, Sharpness=1.2908, Î»_max=-16.9241
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.037  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.137  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.816  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         1s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 37s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.863  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              372.827    episode_length              389.047  â”‚
â”‚  x_position                   87.292    x_velocity                  -14.151  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=127.62 (best=405.48@458752)
æ­¥æ•° 524,288: Reward=127.62, Best=405.48@458752, Sharpness=1.2524, Î»_max=-16.6557

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 8_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_8/vec_stats.npz
[J&R] base_task=8, new_task=8_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_8/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.184  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.297  â”‚
â”‚  SPS               7.7K      Misc        0s   0%    old_approx_kl     0.038  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.030  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.285  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.232  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               17.308    episode_length               55.333  â”‚
â”‚  x_position                   -2.608    x_velocity                  -37.731  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=86.04 (best=N/A)
æ­¥æ•° 32,768: Reward=86.04, Best=17.31@32768, Sharpness=1.2730, Î»_max=-42.3053
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.480  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.332  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.025  â”‚
â”‚  Epoch                2    Train         0s  12%    approx_kl         0.021  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.209  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s   6%    importance        0.995  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.809  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               42.143    episode_length               91.411  â”‚
â”‚  x_position                   -7.474    x_velocity                  -48.774  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=1026.70 (best=17.31@32768)
æ­¥æ•° 65,536: Reward=1026.70, Best=42.14@65536, Sharpness=1.2830, Î»_max=-39.6524
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 11.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.036  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.286  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.357  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                3    Train         0s  12%    approx_kl         0.014  â”‚
â”‚  Uptime             25s      Forwaâ€¦      0s   2%    clipfrac          0.156  â”‚
â”‚  Remainiâ€¦         2m 9s      Learn       0s   6%    importance        0.997  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.885  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               77.529    episode_length              140.241  â”‚
â”‚  x_position                  -13.707    x_velocity                  -61.959  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=11.22 (best=42.14@65536)
æ­¥æ•° 98,304: Reward=11.22, Best=77.53@98304, Sharpness=1.2905, Î»_max=-34.4118
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.038  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.279  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.375  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         0s  12%    approx_kl         0.012  â”‚
â”‚  Uptime             35s      Forwaâ€¦      0s   2%    clipfrac          0.143  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.909  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               71.048    episode_length              152.754  â”‚
â”‚  x_position                  -23.558    x_velocity                  -80.896  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=46.83 (best=77.53@98304)
æ­¥æ•° 131,072: Reward=46.83, Best=77.53@98304, Sharpness=1.3455, Î»_max=-37.0024
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.248  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.402  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                5    Train         0s  12%    approx_kl         0.010  â”‚
â”‚  Uptime             45s      Forwaâ€¦      0s   2%    clipfrac          0.114  â”‚
â”‚  Remainiâ€¦        1m 44s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.915  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               80.368    episode_length              160.977  â”‚
â”‚  x_position                  -21.103    x_velocity                  -79.759  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=84.80 (best=77.53@98304)
æ­¥æ•° 163,840: Reward=84.80, Best=80.37@163840, Sharpness=1.3199, Î»_max=-37.2803
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.223  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.424  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         0s  12%    approx_kl         0.009  â”‚
â”‚  Uptime             55s      Forwaâ€¦      0s   2%    clipfrac          0.110  â”‚
â”‚  Remainiâ€¦        1m 37s      Learn       0s   6%    importance        0.998  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              109.211    episode_length              190.203  â”‚
â”‚  x_position                  -19.773    x_velocity                  -79.989  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=350.32 (best=80.37@163840)
æ­¥æ•° 196,608: Reward=350.32, Best=109.21@196608, Sharpness=1.3279, Î»_max=-31.8914
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.193  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.443  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         0s  10%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 6s      Forwaâ€¦      0s   2%    clipfrac          0.096  â”‚
â”‚  Remainiâ€¦        1m 22s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              107.041    episode_length              185.812  â”‚
â”‚  x_position                  -15.689    x_velocity                  -77.792  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=117.97 (best=109.21@196608)
æ­¥æ•° 229,376: Reward=117.97, Best=109.21@196608, Sharpness=1.4538, Î»_max=-24.5241
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.178  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.460  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         0s  10%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 15s      Forwaâ€¦      0s   2%    clipfrac          0.082  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              119.417    episode_length              198.878  â”‚
â”‚  x_position                  -13.690    x_velocity                  -78.413  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=804.18 (best=109.21@196608)
æ­¥æ•° 262,144: Reward=804.18, Best=119.42@262144, Sharpness=1.3014, Î»_max=-24.8207
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.038  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.163  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.478  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         0s  10%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 27s      Forwaâ€¦      0s   2%    clipfrac          0.063  â”‚
â”‚  Remainiâ€¦        1m 11s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              140.720    episode_length              214.504  â”‚
â”‚  x_position                   -5.001    x_velocity                  -72.650  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=63.30 (best=119.42@262144)
æ­¥æ•° 294,912: Reward=63.30, Best=140.72@294912, Sharpness=1.3974, Î»_max=-22.7593
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.153  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.492  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         0s  10%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 37s      Forwaâ€¦      0s   2%    clipfrac          0.060  â”‚
â”‚  Remainiâ€¦           54s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.899  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              132.837    episode_length              211.514  â”‚
â”‚  x_position                   -6.896    x_velocity                  -77.558  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=76.02 (best=140.72@294912)
æ­¥æ•° 327,680: Reward=76.02, Best=140.72@294912, Sharpness=1.3625, Î»_max=-29.1842
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.152  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.502  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  10%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 47s      Forwaâ€¦      0s   2%    clipfrac          0.047  â”‚
â”‚  Remainiâ€¦           41s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              131.684    episode_length              210.129  â”‚
â”‚  x_position                   -4.308    x_velocity                  -77.339  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=918.37 (best=140.72@294912)
æ­¥æ•° 360,448: Reward=918.37, Best=140.72@294912, Sharpness=1.3670, Î»_max=-19.3783
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.042  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.156  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.508  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         1s  14%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 59s      Forwaâ€¦      0s   2%    clipfrac          0.037  â”‚
â”‚  Remainiâ€¦           38s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.889  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              121.881    episode_length              204.831  â”‚
â”‚  x_position                   -9.316    x_velocity                  -81.864  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=48.36 (best=140.72@294912)
æ­¥æ•° 393,216: Reward=48.36, Best=140.72@294912, Sharpness=1.3059, Î»_max=-29.5683
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.037  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.158  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.513  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         1s  14%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 9s      Forwaâ€¦      0s   2%    clipfrac          0.023  â”‚
â”‚  Remainiâ€¦           23s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.878  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              148.929    episode_length              226.456  â”‚
â”‚  x_position                   -0.272    x_velocity                  -76.328  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=52.32 (best=140.72@294912)
æ­¥æ•° 425,984: Reward=52.32, Best=148.93@425984, Sharpness=1.3414, Î»_max=-27.9976
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.050  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.171  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.516  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.014  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.881  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              139.093    episode_length              217.961  â”‚
â”‚  x_position                   -8.647    x_velocity                  -77.716  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=71.50 (best=148.93@425984)
æ­¥æ•° 458,752: Reward=71.50, Best=148.93@425984, Sharpness=1.2968, Î»_max=-33.1435
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.059  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.221  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.517  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.840  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              214.600    episode_length              280.554  â”‚
â”‚  x_position                   20.321    x_velocity                  -64.468  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=65.57 (best=148.93@425984)
æ­¥æ•° 491,520: Reward=65.57, Best=214.60@491520, Sharpness=1.3903, Î»_max=-20.9875
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.082  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.213  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.517  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 39s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.842  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              217.079    episode_length              291.674  â”‚
â”‚  x_position                    5.589    x_velocity                  -73.045  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=1167.32 (best=214.60@491520)
æ­¥æ•° 524,288: Reward=1167.32, Best=217.08@524288, Sharpness=1.3899, Î»_max=-23.8370

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 8_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_8/vec_stats.npz
[J&R] base_task=8, new_task=8_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_8/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 6.2%  GPU: 0.0%  DRAM: 0.2%   VRAM: 0.8%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.449  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.396  â”‚
â”‚  SPS               7.8K      Misc        0s   0%    old_approx_kl     0.063  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.048  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.387  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   0%    importance        0.984  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.471  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.953    episode_length               47.661  â”‚
â”‚  x_position                   -2.465    x_velocity                  -35.467  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=126.67 (best=N/A)
æ­¥æ•° 32,768: Reward=126.67, Best=11.95@32768, Sharpness=2.0495, Î»_max=-50.7213
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.507  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          11.421  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                2    Train         0s  16%    approx_kl         0.028  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.258  â”‚
â”‚  Remainiâ€¦        2m 10s      Learn       0s  12%    importance        0.997  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.798  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               19.569    episode_length               70.134  â”‚
â”‚  x_position                   -7.790    x_velocity                  -50.213  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=43.56 (best=11.95@32768)
æ­¥æ•° 65,536: Reward=43.56, Best=19.57@65536, Sharpness=1.8858, Î»_max=-53.4624
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.455  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          11.442  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.026  â”‚
â”‚  Epoch                3    Train         0s  16%    approx_kl         0.025  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.242  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s  12%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.862  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               17.213    episode_length               90.515  â”‚
â”‚  x_position                  -16.445    x_velocity                  -72.852  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=21.27 (best=19.57@65536)
æ­¥æ•° 98,304: Reward=21.27, Best=19.57@65536, Sharpness=1.8551, Î»_max=-56.4601
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.363  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          11.463  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                4    Train         0s  16%    approx_kl         0.019  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.205  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.868  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.320    episode_length              104.163  â”‚
â”‚  x_position                  -18.766    x_velocity                  -74.320  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=14.26 (best=19.57@65536)
æ­¥æ•° 131,072: Reward=14.26, Best=29.32@131072, Sharpness=1.8690, Î»_max=-63.2455
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         3s  76%    value_loss        0.286  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          11.482  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                5    Train         0s  16%    approx_kl         0.014  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.165  â”‚
â”‚  Remainiâ€¦        1m 38s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.852  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               32.930    episode_length              111.096  â”‚
â”‚  x_position                  -19.521    x_velocity                  -77.604  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-6.07 (best=29.32@131072)
æ­¥æ•° 163,840: Reward=-6.07, Best=32.93@163840, Sharpness=1.8481, Î»_max=-51.8668
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.236  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          11.499  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                6    Train         1s  16%    approx_kl         0.015  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   2%    clipfrac          0.157  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       0s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.823  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               25.263    episode_length              107.503  â”‚
â”‚  x_position                  -20.926    x_velocity                  -81.698  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-8.59 (best=32.93@163840)
æ­¥æ•° 196,608: Reward=-8.59, Best=32.93@163840, Sharpness=1.8604, Î»_max=-55.5779
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.205  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.513  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         1s  11%    approx_kl         0.012  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.141  â”‚
â”‚  Remainiâ€¦        1m 21s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.808  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               37.600    episode_length              113.220  â”‚
â”‚  x_position                  -15.624    x_velocity                  -75.045  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-7.80 (best=32.93@163840)
æ­¥æ•° 229,376: Reward=-7.80, Best=37.60@229376, Sharpness=1.9088, Î»_max=-39.5156
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.167  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.529  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                8    Train         1s  11%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.133  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.804  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.131    episode_length              106.812  â”‚
â”‚  x_position                  -15.897    x_velocity                  -76.141  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-11.03 (best=37.60@229376)
æ­¥æ•° 262,144: Reward=-11.03, Best=37.60@229376, Sharpness=1.8798, Î»_max=-36.7570
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.153  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.542  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                9    Train         1s  11%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 22s      Forwaâ€¦      0s   2%    clipfrac          0.101  â”‚
â”‚  Remainiâ€¦           58s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.808  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               26.656    episode_length              101.114  â”‚
â”‚  x_position                  -13.895    x_velocity                  -73.948  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-14.52 (best=37.60@229376)
æ­¥æ•° 294,912: Reward=-14.52, Best=37.60@229376, Sharpness=1.8181, Î»_max=-26.8912
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.148  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.555  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         1s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.092  â”‚
â”‚  Remainiâ€¦           51s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.803  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               28.460    episode_length              109.243  â”‚
â”‚  x_position                  -17.320    x_velocity                  -80.229  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-12.15 (best=37.60@229376)
æ­¥æ•° 327,680: Reward=-12.15, Best=37.60@229376, Sharpness=1.8968, Î»_max=-52.7564
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.147  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.566  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 42s      Forwaâ€¦      0s   2%    clipfrac          0.070  â”‚
â”‚  Remainiâ€¦           43s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.774  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.847    episode_length              106.346  â”‚
â”‚  x_position                  -18.756    x_velocity                  -80.960  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-16.84 (best=37.60@229376)
æ­¥æ•° 360,448: Reward=-16.84, Best=37.60@229376, Sharpness=1.8495, Î»_max=-35.8391
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.138  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.573  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         1s  14%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 52s      Forwaâ€¦      0s   2%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.803  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               28.308    episode_length              108.068  â”‚
â”‚  x_position                  -17.366    x_velocity                  -79.212  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-17.64 (best=37.60@229376)
æ­¥æ•° 393,216: Reward=-17.64, Best=37.60@229376, Sharpness=1.7719, Î»_max=-48.1082
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.151  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.575  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  14%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 1s      Forwaâ€¦      0s   2%    clipfrac          0.029  â”‚
â”‚  Remainiâ€¦           22s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.785  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               24.661    episode_length              103.912  â”‚
â”‚  x_position                  -17.515    x_velocity                  -78.725  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-22.24 (best=37.60@229376)
æ­¥æ•° 425,984: Reward=-22.24, Best=37.60@229376, Sharpness=1.7462, Î»_max=17.8805
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.154  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.577  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   2%    clipfrac          0.018  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.785  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               23.329    episode_length              101.411  â”‚
â”‚  x_position                  -16.534    x_velocity                  -77.567  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-23.90 (best=37.60@229376)
æ­¥æ•° 458,752: Reward=-23.90, Best=37.60@229376, Sharpness=1.8309, Î»_max=-56.7881
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.020  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.171  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.578  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   2%    clipfrac          0.002  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.750  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               20.768    episode_length              100.870  â”‚
â”‚  x_position                  -12.314    x_velocity                  -79.589  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-25.15 (best=37.60@229376)
æ­¥æ•° 491,520: Reward=-25.15, Best=37.60@229376, Sharpness=2.1334, Î»_max=-42.2500
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.185  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.579  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 30s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.705  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.978    episode_length              106.279  â”‚
â”‚  x_position                  -11.544    x_velocity                  -74.759  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-26.76 (best=37.60@229376)
æ­¥æ•° 524,288: Reward=-26.76, Best=37.60@229376, Sharpness=1.8236, Î»_max=-53.0541

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 8_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_8/vec_stats.npz
[J&R] base_task=8, new_task=8_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_8/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 5.6%  GPU: 0.0%  DRAM: 0.2%   VRAM: 0.8%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        2.489  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          23.248  â”‚
â”‚  SPS               8.4K      Misc        0s   0%    old_approx_kl     0.035  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.034  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.256  â”‚
â”‚  Remainiâ€¦           55s      Learn       0s   0%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.260  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.712    episode_length               18.718  â”‚
â”‚  x_position                   -1.981    x_velocity                  -26.322  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-8.31 (best=N/A)
æ­¥æ•° 32,768: Reward=-8.31, Best=-7.71@32768, Sharpness=3.7633, Î»_max=30.8828
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        1.147  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          23.284  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         0s  12%    approx_kl         0.019  â”‚
â”‚  Uptime             13s      Forwaâ€¦      0s   2%    clipfrac          0.176  â”‚
â”‚  Remainiâ€¦         2m 0s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.356  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.417    episode_length               19.134  â”‚
â”‚  x_position                   -2.191    x_velocity                  -27.442  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-11.41 (best=-7.71@32768)
æ­¥æ•° 65,536: Reward=-11.41, Best=-7.71@32768, Sharpness=2.8156, Î»_max=20.5608
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.832  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          23.332  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         0s  12%    approx_kl         0.017  â”‚
â”‚  Uptime             22s      Forwaâ€¦      0s   2%    clipfrac          0.161  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.195  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.102    episode_length               19.180  â”‚
â”‚  x_position                   -2.204    x_velocity                  -27.173  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-16.43 (best=-7.71@32768)
æ­¥æ•° 98,304: Reward=-16.43, Best=-7.71@32768, Sharpness=1.9624, Î»_max=11.2698
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.686  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          23.372  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         0s  12%    approx_kl         0.014  â”‚
â”‚  Uptime             32s      Forwaâ€¦      0s   2%    clipfrac          0.136  â”‚
â”‚  Remainiâ€¦        1m 49s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.135  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.412    episode_length               18.788  â”‚
â”‚  x_position                   -2.079    x_velocity                  -26.092  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-9.29 (best=-7.71@32768)
æ­¥æ•° 131,072: Reward=-9.29, Best=-7.41@131072, Sharpness=1.6468, Î»_max=11.1624
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  79%    value_loss        0.590  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          23.407  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         0s  12%    approx_kl         0.012  â”‚
â”‚  Uptime             42s      Forwaâ€¦      0s   2%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.074  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.132    episode_length               19.035  â”‚
â”‚  x_position                   -2.122    x_velocity                  -26.058  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-3.19 (best=-7.41@131072)
æ­¥æ•° 163,840: Reward=-3.19, Best=-7.13@163840, Sharpness=1.6030, Î»_max=11.3380
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.558  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          23.449  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         0s  12%    approx_kl         0.010  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.108  â”‚
â”‚  Remainiâ€¦        1m 30s      Learn       0s   6%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.053  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.094    episode_length               18.467  â”‚
â”‚  x_position                   -1.970    x_velocity                  -24.455  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-0.94 (best=-7.13@163840)
æ­¥æ•° 196,608: Reward=-0.94, Best=-6.09@196608, Sharpness=1.6805, Î»_max=9.7684
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 5.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.513  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          23.474  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         0s  11%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 1s      Forwaâ€¦      0s   2%    clipfrac          0.103  â”‚
â”‚  Remainiâ€¦        1m 16s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.019  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.740    episode_length               19.865  â”‚
â”‚  x_position                   -2.203    x_velocity                  -25.491  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=3.23 (best=-6.09@196608)
æ­¥æ•° 229,376: Reward=3.23, Best=-5.74@229376, Sharpness=1.6098, Î»_max=-8.6102
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.492  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          23.493  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         0s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 11s      Forwaâ€¦      0s   2%    clipfrac          0.084  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.061  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.108    episode_length               20.048  â”‚
â”‚  x_position                   -2.172    x_velocity                  -25.041  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=16.43 (best=-5.74@229376)
æ­¥æ•° 262,144: Reward=16.43, Best=-5.11@262144, Sharpness=1.8085, Î»_max=-5.5347
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 5.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.487  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          23.507  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch                9    Train         0s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 20s      Forwaâ€¦      0s   2%    clipfrac          0.064  â”‚
â”‚  Remainiâ€¦           58s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.113  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.775    episode_length               21.014  â”‚
â”‚  x_position                   -2.373    x_velocity                  -25.668  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-62.17 (best=-5.11@262144)
æ­¥æ•° 294,912: Reward=-62.17, Best=-4.78@294912, Sharpness=1.9691, Î»_max=5.1836
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 5.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.480  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          23.518  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               10    Train         0s  11%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   2%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦           52s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.153  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.233    episode_length               21.380  â”‚
â”‚  x_position                   -2.333    x_velocity                  -25.490  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=16.63 (best=-4.78@294912)
æ­¥æ•° 327,680: Reward=16.63, Best=-4.23@327680, Sharpness=1.7327, Î»_max=-6.2651
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 5.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.475  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          23.526  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 40s      Forwaâ€¦      0s   2%    clipfrac          0.049  â”‚
â”‚  Remainiâ€¦           41s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.166  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.010    episode_length               21.825  â”‚
â”‚  x_position                   -2.455    x_velocity                  -25.709  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-14.33 (best=-4.23@327680)
æ­¥æ•° 360,448: Reward=-14.33, Best=-4.01@360448, Sharpness=1.8941, Î»_max=9.9748
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.018  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.550  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          23.534  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  13%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.030  â”‚
â”‚  Remainiâ€¦           32s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.221  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.626    episode_length               22.841  â”‚
â”‚  x_position                   -2.609    x_velocity                  -26.336  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-28.31 (best=-4.01@360448)
æ­¥æ•° 393,216: Reward=-28.31, Best=-3.63@393216, Sharpness=1.5008, Î»_max=5.3173
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.512  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          23.541  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  13%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           23s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.216  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.852    episode_length               23.884  â”‚
â”‚  x_position                   -2.747    x_velocity                  -26.599  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-28.80 (best=-3.63@393216)
æ­¥æ•° 425,984: Reward=-28.80, Best=-2.85@425984, Sharpness=1.9953, Î»_max=-7.8670
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.562  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          23.544  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  13%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.010  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.203  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.933    episode_length               24.454  â”‚
â”‚  x_position                   -2.966    x_velocity                  -27.247  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=16.42 (best=-2.85@425984)
æ­¥æ•° 458,752: Reward=16.42, Best=-2.85@425984, Sharpness=1.7161, Î»_max=0.0541
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.586  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          23.546  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.175  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.687    episode_length               24.894  â”‚
â”‚  x_position                   -2.945    x_velocity                  -27.438  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-24.79 (best=-2.85@425984)
æ­¥æ•° 491,520: Reward=-24.79, Best=-2.69@491520, Sharpness=1.8211, Î»_max=-8.3378
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.018  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.560  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          23.546  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.133  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.041    episode_length               25.401  â”‚
â”‚  x_position                   -3.137    x_velocity                  -28.297  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-17.31 (best=-2.69@491520)
æ­¥æ•° 524,288: Reward=-17.31, Best=-2.69@491520, Sharpness=1.8605, Î»_max=6.1470

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 8_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 8 step sweep å®Œæˆã€‚
