==========================================
[Jump & Retrain] Walker2d task 3 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 10:54:03 EST 2025
èŠ‚ç‚¹: node4
==========================================
[Base] task=3, env=Walker2d-v4, best_model=final_model.pt, best_reward=2246.50, train_seed=203
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_3/vec_stats.npz
[J&R] base_task=3, new_task=3_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_3/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 0.1%  DRAM: 0.3%   VRAM: 2.3%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.292  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.450  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.024  â”‚
â”‚  Uptime             13s      Forwaâ€¦      0s   0%    clipfrac          0.267  â”‚
â”‚  Remainiâ€¦         3m 9s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.595  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.970    episode_length               56.372  â”‚
â”‚  x_position                   -9.012    x_velocity                  -68.054  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=319.38 (best=N/A)
æ­¥æ•° 32,768: Reward=319.38, Best=-11.97@32768, Sharpness=1.2813, Î»_max=-29.8061
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.6%  DRAM: 0.4%   VRAM: 2.9%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         5s  68%    value_loss        0.547  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.480  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                2    Train         1s  21%    approx_kl         0.017  â”‚
â”‚  Uptime             27s      Forwaâ€¦      0s   5%    clipfrac          0.187  â”‚
â”‚  Remainiâ€¦         3m 1s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.864  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.787    episode_length               89.604  â”‚
â”‚  x_position                  -12.952    x_velocity                  -73.350  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=962.52 (best=-11.97@32768)
æ­¥æ•° 65,536: Reward=962.52, Best=15.79@65536, Sharpness=1.2737, Î»_max=-33.3546
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         5s  68%    value_loss        0.428  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.504  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         1s  21%    approx_kl         0.014  â”‚
â”‚  Uptime             40s      Forwaâ€¦      0s   5%    clipfrac          0.167  â”‚
â”‚  Remainiâ€¦        2m 50s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               53.022    episode_length              126.620  â”‚
â”‚  x_position                  -14.215    x_velocity                  -72.935  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=432.07 (best=15.79@65536)
æ­¥æ•° 98,304: Reward=432.07, Best=53.02@98304, Sharpness=1.2963, Î»_max=-33.6870
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 17.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         5s  68%    value_loss        0.309  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.525  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         1s  21%    approx_kl         0.012  â”‚
â”‚  Uptime             56s      Forwaâ€¦      0s   5%    clipfrac          0.139  â”‚
â”‚  Remainiâ€¦        2m 59s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               58.871    episode_length              137.112  â”‚
â”‚  x_position                  -17.036    x_velocity                  -77.527  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=1168.73 (best=53.02@98304)
æ­¥æ•° 131,072: Reward=1168.73, Best=58.87@131072, Sharpness=1.2753, Î»_max=-34.0159
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         5s  68%    value_loss        0.252  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.541  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         1s  21%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 13s      Forwaâ€¦      0s   5%    clipfrac          0.117  â”‚
â”‚  Remainiâ€¦        2m 46s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.909  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               74.752    episode_length              153.378  â”‚
â”‚  x_position                  -16.007    x_velocity                  -77.831  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=1239.03 (best=58.87@131072)
æ­¥æ•° 163,840: Reward=1239.03, Best=74.75@163840, Sharpness=1.2840, Î»_max=-35.8999
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  78%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   8%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        11s  68%    value_loss        0.200  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.560  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         3s  21%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   5%    clipfrac          0.114  â”‚
â”‚  Remainiâ€¦        2m 44s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   2%    explained_varâ€¦    0.911  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               81.429    episode_length              168.712  â”‚
â”‚  x_position                  -22.826    x_velocity                  -86.404  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=272.78 (best=74.75@163840)
æ­¥æ•° 196,608: Reward=272.78, Best=81.43@196608, Sharpness=1.2988, Î»_max=-32.7730
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 16.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.163  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.580  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         3s  17%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 46s      Forwaâ€¦      0s   3%    clipfrac          0.093  â”‚
â”‚  Remainiâ€¦         2m 8s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              100.344    episode_length              186.452  â”‚
â”‚  x_position                  -20.365    x_velocity                  -85.140  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=416.08 (best=81.43@196608)
æ­¥æ•° 229,376: Reward=416.08, Best=100.34@229376, Sharpness=1.2985, Î»_max=-33.7595
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.147  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.595  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         3s  17%    approx_kl         0.006  â”‚
â”‚  Uptime           2m 3s      Forwaâ€¦      0s   3%    clipfrac          0.074  â”‚
â”‚  Remainiâ€¦        1m 59s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              111.728    episode_length              198.417  â”‚
â”‚  x_position                  -23.186    x_velocity                  -85.659  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=307.34 (best=100.34@229376)
æ­¥æ•° 262,144: Reward=307.34, Best=111.73@262144, Sharpness=1.3315, Î»_max=-32.4081
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.4%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 19.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.135  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.608  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         3s  17%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 17s      Forwaâ€¦      0s   3%    clipfrac          0.074  â”‚
â”‚  Remainiâ€¦        1m 31s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              136.882    episode_length              223.225  â”‚
â”‚  x_position                  -19.920    x_velocity                  -85.187  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=1176.36 (best=111.73@262144)
æ­¥æ•° 294,912: Reward=1176.36, Best=136.88@294912, Sharpness=1.3641, Î»_max=-33.2819
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.2%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        11s  74%    value_loss        0.132  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.621  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               10    Train         3s  17%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 34s      Forwaâ€¦      0s   3%    clipfrac          0.057  â”‚
â”‚  Remainiâ€¦        1m 25s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              146.574    episode_length              239.245  â”‚
â”‚  x_position                  -24.704    x_velocity                  -91.427  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=1209.04 (best=136.88@294912)
æ­¥æ•° 327,680: Reward=1209.04, Best=146.57@327680, Sharpness=1.2972, Î»_max=-22.4309
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        15s  74%    value_loss        0.125  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.627  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               11    Train         3s  17%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 50s      Forwaâ€¦      0s   3%    clipfrac          0.042  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              167.354    episode_length              258.969  â”‚
â”‚  x_position                  -29.164    x_velocity                  -90.273  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=480.34 (best=146.57@327680)
æ­¥æ•° 360,448: Reward=480.34, Best=167.35@360448, Sharpness=1.2782, Î»_max=-33.7842
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.118  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          12.635  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         3s  15%    approx_kl         0.004  â”‚
â”‚  Uptime           3m 4s      Forwaâ€¦      0s   3%    clipfrac          0.035  â”‚
â”‚  Remainiâ€¦           45s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              176.354    episode_length              272.353  â”‚
â”‚  x_position                  -33.124    x_velocity                  -94.592  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=1271.70 (best=167.35@360448)
æ­¥æ•° 393,216: Reward=1271.70, Best=176.35@393216, Sharpness=1.3383, Î»_max=-21.1712
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.124  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          12.640  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  15%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 19s      Forwaâ€¦      0s   3%    clipfrac          0.026  â”‚
â”‚  Remainiâ€¦           34s      Learn       1s   4%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              211.916    episode_length              308.195  â”‚
â”‚  x_position                  -33.363    x_velocity                  -94.679  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=808.99 (best=176.35@393216)
æ­¥æ•° 425,984: Reward=808.99, Best=211.92@425984, Sharpness=1.3269, Î»_max=-34.9707
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.8%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.123  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          12.643  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         3s  15%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 37s      Forwaâ€¦      0s   3%    clipfrac          0.019  â”‚
â”‚  Remainiâ€¦           22s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.897  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              209.986    episode_length              302.247  â”‚
â”‚  x_position                  -30.079    x_velocity                  -90.698  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=1244.22 (best=211.92@425984)
æ­¥æ•° 458,752: Reward=1244.22, Best=211.92@425984, Sharpness=1.3295, Î»_max=-35.6760
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env        15s  77%    value_loss        0.145  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          12.644  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 54s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.872  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              190.716    episode_length              296.153  â”‚
â”‚  x_position                  -48.547    x_velocity                 -103.907  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=676.12 (best=211.92@425984)
æ­¥æ•° 491,520: Reward=676.12, Best=211.92@425984, Sharpness=1.2704, Î»_max=-27.4331
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     23s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env        21s  77%    value_loss        0.141  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          12.645  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         4s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 11s      Forwaâ€¦      1s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.865  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              241.807    episode_length              342.468  â”‚
â”‚  x_position                  -27.805    x_velocity                  -98.890  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=1269.06 (best=211.92@425984)
æ­¥æ•° 524,288: Reward=1269.06, Best=241.81@524288, Sharpness=1.4038, Î»_max=-22.6608

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 3_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_3/vec_stats.npz
[J&R] base_task=3, new_task=3_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_3/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 5.3%  GPU: 0.0%  DRAM: 0.2%   VRAM: 1.6%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.8%  DRAM: 0.3%   VRAM: 2.9%  â”‚
â”‚                                 25.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.305  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.362  â”‚
â”‚  SPS               4.3K      Misc        0s   0%    old_approx_kl     0.033  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.027  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.281  â”‚
â”‚  Remainiâ€¦        1m 49s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.621  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -16.518    episode_length               55.262  â”‚
â”‚  x_position                   -9.635    x_velocity                  -71.499  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=68.68 (best=N/A)
æ­¥æ•° 32,768: Reward=68.68, Best=-16.52@32768, Sharpness=1.2318, Î»_max=-23.9594
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.557  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.392  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                2    Train         1s  14%    approx_kl         0.017  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.202  â”‚
â”‚  Remainiâ€¦        3m 27s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.857  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               16.481    episode_length               88.761  â”‚
â”‚  x_position                  -12.202    x_velocity                  -71.818  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-19.39 (best=-16.52@32768)
æ­¥æ•° 65,536: Reward=-19.39, Best=16.48@65536, Sharpness=1.2271, Î»_max=-22.4151
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 19.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.377  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.409  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                3    Train         1s  14%    approx_kl         0.014  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   2%    clipfrac          0.171  â”‚
â”‚  Remainiâ€¦        2m 54s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               55.395    episode_length              123.023  â”‚
â”‚  x_position                  -11.681    x_velocity                  -66.986  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=39.29 (best=16.48@65536)
æ­¥æ•° 98,304: Reward=39.29, Best=55.40@98304, Sharpness=1.2507, Î»_max=-22.0684
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.310  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.430  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         1s  14%    approx_kl         0.011  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.137  â”‚
â”‚  Remainiâ€¦        2m 51s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.891  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               50.128    episode_length              127.393  â”‚
â”‚  x_position                  -16.254    x_velocity                  -76.607  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-37.94 (best=55.40@98304)
æ­¥æ•° 131,072: Reward=-37.94, Best=55.40@98304, Sharpness=1.2233, Î»_max=-26.4212
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.6%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 20.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.234  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.444  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  14%    approx_kl         0.010  â”‚
â”‚  Uptime           1m 6s      Forwaâ€¦      0s   2%    clipfrac          0.127  â”‚
â”‚  Remainiâ€¦        2m 24s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               75.923    episode_length              156.232  â”‚
â”‚  x_position                  -19.399    x_velocity                  -79.499  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-28.86 (best=55.40@98304)
æ­¥æ•° 163,840: Reward=-28.86, Best=75.92@163840, Sharpness=1.3872, Î»_max=-22.6558
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.184  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.458  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         2s  14%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 23s      Forwaâ€¦      0s   2%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦        2m 34s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               87.454    episode_length              174.209  â”‚
â”‚  x_position                  -22.281    x_velocity                  -85.858  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-22.73 (best=75.92@163840)
æ­¥æ•° 196,608: Reward=-22.73, Best=87.45@196608, Sharpness=1.2719, Î»_max=-24.2349
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.7%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        12s  80%    value_loss        0.149  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          12.478  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  13%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 37s      Forwaâ€¦      0s   2%    clipfrac          0.098  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.912  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              104.380    episode_length              190.128  â”‚
â”‚  x_position                  -21.137    x_velocity                  -84.765  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-22.03 (best=87.45@196608)
æ­¥æ•° 229,376: Reward=-22.03, Best=104.38@229376, Sharpness=1.2971, Î»_max=-26.4287
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 19.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        12s  80%    value_loss        0.140  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          12.496  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         2s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 52s      Forwaâ€¦      0s   2%    clipfrac          0.085  â”‚
â”‚  Remainiâ€¦        1m 45s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.907  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              131.681    episode_length              221.733  â”‚
â”‚  x_position                  -27.938    x_velocity                  -88.902  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-22.11 (best=104.38@229376)
æ­¥æ•° 262,144: Reward=-22.11, Best=131.68@262144, Sharpness=1.2639, Î»_max=-26.4164
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.4%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 19.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        12s  80%    value_loss        0.131  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          12.513  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         2s  13%    approx_kl         0.007  â”‚
â”‚  Uptime           2m 7s      Forwaâ€¦      0s   2%    clipfrac          0.079  â”‚
â”‚  Remainiâ€¦        1m 34s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.909  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              145.599    episode_length              232.517  â”‚
â”‚  x_position                  -24.763    x_velocity                  -85.717  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-21.16 (best=131.68@262144)
æ­¥æ•° 294,912: Reward=-21.16, Best=145.60@294912, Sharpness=1.2609, Î»_max=-29.8852
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        12s  80%    value_loss        0.120  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          12.527  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         2s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 24s      Forwaâ€¦      0s   2%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              158.836    episode_length              244.266  â”‚
â”‚  x_position                  -20.340    x_velocity                  -84.169  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-22.72 (best=145.60@294912)
æ­¥æ•° 327,680: Reward=-22.72, Best=158.84@327680, Sharpness=1.2742, Î»_max=-25.5919
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env        16s  80%    value_loss        0.125  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          12.536  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         3s  13%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 37s      Forwaâ€¦      0s   2%    clipfrac          0.051  â”‚
â”‚  Remainiâ€¦           58s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              166.548    episode_length              253.241  â”‚
â”‚  x_position                  -21.402    x_velocity                  -85.386  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-22.48 (best=158.84@327680)
æ­¥æ•° 360,448: Reward=-22.48, Best=166.55@360448, Sharpness=1.2698, Î»_max=-23.3686
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env        16s  68%    value_loss        0.119  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.543  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  22%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 53s      Forwaâ€¦      0s   4%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           51s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              194.542    episode_length              287.807  â”‚
â”‚  x_position                  -42.940    x_velocity                  -91.779  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-25.32 (best=166.55@360448)
æ­¥æ•° 393,216: Reward=-25.32, Best=194.54@393216, Sharpness=1.2541, Î»_max=-24.8583
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        16s  68%    value_loss        0.117  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.548  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         3s  22%    approx_kl         0.003  â”‚
â”‚  Uptime           3m 8s      Forwaâ€¦      0s   4%    clipfrac          0.023  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              231.826    episode_length              327.630  â”‚
â”‚  x_position                  -41.071    x_velocity                  -94.116  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-24.02 (best=194.54@393216)
æ­¥æ•° 425,984: Reward=-24.02, Best=231.83@425984, Sharpness=1.4327, Î»_max=-27.2494
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env        16s  68%    value_loss        0.119  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.551  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         3s  22%    approx_kl         0.001  â”‚
â”‚  Uptime          3m 23s      Forwaâ€¦      0s   4%    clipfrac          0.006  â”‚
â”‚  Remainiâ€¦           19s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.889  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              258.559    episode_length              353.577  â”‚
â”‚  x_position                  -44.755    x_velocity                  -93.191  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-22.19 (best=231.83@425984)
æ­¥æ•° 458,752: Reward=-22.19, Best=258.56@458752, Sharpness=1.3989, Î»_max=-21.7922
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env        16s  68%    value_loss        0.147  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.552  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  22%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 38s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.864  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              273.343    episode_length              358.347  â”‚
â”‚  x_position                  -15.404    x_velocity                  -83.154  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-22.13 (best=258.56@458752)
æ­¥æ•° 491,520: Reward=-22.13, Best=273.34@491520, Sharpness=1.3566, Î»_max=-21.8613
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.7%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     25s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   6%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        23s  68%    value_loss        0.142  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.552  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         4s  22%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 54s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.860  â”‚
â”‚                              Misc        1s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              253.491    episode_length              348.614  â”‚
â”‚  x_position                  -37.638    x_velocity                  -93.319  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-22.24 (best=273.34@491520)
æ­¥æ•° 524,288: Reward=-22.24, Best=273.34@491520, Sharpness=1.4016, Î»_max=-22.3882

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 3_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_3/vec_stats.npz
[J&R] base_task=3, new_task=3_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_3/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 0.0%  DRAM: 0.3%   VRAM: 2.9%  â”‚
â”‚                                 24.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.281  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.093  â”‚
â”‚  SPS               4.7K      Misc        0s   0%    old_approx_kl     0.040  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.032  â”‚
â”‚  Uptime              6s      Forwaâ€¦      0s   0%    clipfrac          0.305  â”‚
â”‚  Remainiâ€¦        1m 38s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.511  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.561    episode_length               53.182  â”‚
â”‚  x_position                   -6.518    x_velocity                  -56.474  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=125.05 (best=N/A)
æ­¥æ•° 32,768: Reward=125.05, Best=-3.56@32768, Sharpness=1.2736, Î»_max=-25.4722
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         5s  78%    value_loss        0.456  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.124  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                2    Train         0s  14%    approx_kl         0.018  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.202  â”‚
â”‚  Remainiâ€¦        3m 40s      Learn       0s   7%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.859  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.108    episode_length               86.722  â”‚
â”‚  x_position                   -8.280    x_velocity                  -57.167  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=1010.19 (best=-3.56@32768)
æ­¥æ•° 65,536: Reward=1010.19, Best=29.11@65536, Sharpness=1.2780, Î»_max=-31.7499
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         5s  78%    value_loss        0.362  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.147  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                3    Train         0s  14%    approx_kl         0.016  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.181  â”‚
â”‚  Remainiâ€¦        3m 57s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               60.621    episode_length              125.310  â”‚
â”‚  x_position                  -10.938    x_velocity                  -64.038  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=277.37 (best=29.11@65536)
æ­¥æ•° 98,304: Reward=277.37, Best=60.62@98304, Sharpness=1.2488, Î»_max=-29.0846
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         5s  78%    value_loss        0.317  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.170  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         0s  14%    approx_kl         0.013  â”‚
â”‚  Uptime             59s      Forwaâ€¦      0s   2%    clipfrac          0.160  â”‚
â”‚  Remainiâ€¦         3m 7s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               59.785    episode_length              134.424  â”‚
â”‚  x_position                  -14.462    x_velocity                  -73.938  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=1009.95 (best=60.62@98304)
æ­¥æ•° 131,072: Reward=1009.95, Best=60.62@98304, Sharpness=1.2760, Î»_max=-29.8985
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         5s  78%    value_loss        0.267  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.186  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                5    Train         0s  14%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 16s      Forwaâ€¦      0s   2%    clipfrac          0.142  â”‚
â”‚  Remainiâ€¦        2m 52s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.899  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               89.005    episode_length              159.698  â”‚
â”‚  x_position                  -11.869    x_velocity                  -69.859  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=158.19 (best=60.62@98304)
æ­¥æ•° 163,840: Reward=158.19, Best=89.00@163840, Sharpness=1.2855, Î»_max=-28.3828
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env        11s  78%    value_loss        0.204  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.201  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         1s  14%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 32s      Forwaâ€¦      0s   2%    clipfrac          0.128  â”‚
â”‚  Remainiâ€¦        2m 27s      Learn       1s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              103.060    episode_length              182.752  â”‚
â”‚  x_position                  -14.567    x_velocity                  -78.741  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=1010.11 (best=89.00@163840)
æ­¥æ•° 196,608: Reward=1010.11, Best=103.06@196608, Sharpness=1.2530, Î»_max=-31.1824
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.4%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env        11s  79%    value_loss        0.171  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          12.217  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         1s  13%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.099  â”‚
â”‚  Remainiâ€¦        2m 30s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              102.731    episode_length              185.295  â”‚
â”‚  x_position                  -19.679    x_velocity                  -81.600  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=218.26 (best=103.06@196608)
æ­¥æ•° 229,376: Reward=218.26, Best=103.06@196608, Sharpness=1.2445, Î»_max=-29.1122
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        11s  79%    value_loss        0.139  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          12.232  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s  13%    approx_kl         0.008  â”‚
â”‚  Uptime           2m 7s      Forwaâ€¦      0s   2%    clipfrac          0.101  â”‚
â”‚  Remainiâ€¦        1m 59s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              138.288    episode_length              215.452  â”‚
â”‚  x_position                  -13.108    x_velocity                  -76.041  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=1011.84 (best=103.06@196608)
æ­¥æ•° 262,144: Reward=1011.84, Best=138.29@262144, Sharpness=1.2827, Î»_max=-24.1942
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env        11s  79%    value_loss        0.133  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          12.246  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 25s      Forwaâ€¦      0s   2%    clipfrac          0.077  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       1s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              158.885    episode_length              238.612  â”‚
â”‚  x_position                  -18.532    x_velocity                  -78.486  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=319.10 (best=138.29@262144)
æ­¥æ•° 294,912: Reward=319.10, Best=158.89@294912, Sharpness=1.2652, Î»_max=-27.1705
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.4%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     12s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        11s  79%    value_loss        0.114  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          12.259  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 41s      Forwaâ€¦      0s   2%    clipfrac          0.067  â”‚
â”‚  Remainiâ€¦        1m 25s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              151.194    episode_length              237.757  â”‚
â”‚  x_position                  -22.731    x_velocity                  -85.325  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=144.36 (best=158.89@294912)
æ­¥æ•° 327,680: Reward=144.36, Best=158.89@294912, Sharpness=1.2842, Î»_max=-25.8328
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 1.8%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 19.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env        16s  79%    value_loss        0.125  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          12.270  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  13%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 55s      Forwaâ€¦      0s   2%    clipfrac          0.044  â”‚
â”‚  Remainiâ€¦           58s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              145.359    episode_length              235.529  â”‚
â”‚  x_position                  -23.775    x_velocity                  -88.942  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=1015.81 (best=158.89@294912)
æ­¥æ•° 360,448: Reward=1015.81, Best=158.89@294912, Sharpness=1.4016, Î»_max=-23.6073
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        16s  81%    value_loss        0.125  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.277  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         2s  11%    approx_kl         0.003  â”‚
â”‚  Uptime          3m 12s      Forwaâ€¦      0s   2%    clipfrac          0.032  â”‚
â”‚  Remainiâ€¦           52s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              181.601    episode_length              269.757  â”‚
â”‚  x_position                  -26.553    x_velocity                  -86.751  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=1023.83 (best=158.89@294912)
æ­¥æ•° 393,216: Reward=1023.83, Best=181.60@393216, Sharpness=1.2756, Î»_max=-27.1396
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        16s  81%    value_loss        0.112  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.284  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         2s  11%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 28s      Forwaâ€¦      0s   2%    clipfrac          0.017  â”‚
â”‚  Remainiâ€¦           37s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              173.578    episode_length              252.783  â”‚
â”‚  x_position                  -13.287    x_velocity                  -77.887  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=158.21 (best=181.60@393216)
æ­¥æ•° 425,984: Reward=158.21, Best=181.60@393216, Sharpness=1.2587, Î»_max=-26.6526
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 19.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env        16s  81%    value_loss        0.123  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.287  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  11%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 43s      Forwaâ€¦      0s   2%    clipfrac          0.015  â”‚
â”‚  Remainiâ€¦           18s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              198.699    episode_length              273.596  â”‚
â”‚  x_position                   -5.507    x_velocity                  -73.470  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=1036.77 (best=181.60@393216)
æ­¥æ•° 458,752: Reward=1036.77, Best=198.70@458752, Sharpness=1.3361, Î»_max=-21.3713
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env        16s  81%    value_loss        0.131  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.288  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  11%    approx_kl         0.000  â”‚
â”‚  Uptime           4m 1s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            4s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              205.417    episode_length              295.255  â”‚
â”‚  x_position                  -37.144    x_velocity                  -88.300  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=161.93 (best=198.70@458752)
æ­¥æ•° 491,520: Reward=161.93, Best=205.42@491520, Sharpness=1.2524, Î»_max=-27.4633
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     22s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.039  â”‚
â”‚  Params          135.3K      Env        20s  81%    value_loss        0.141  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.289  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  11%    approx_kl         0.000  â”‚
â”‚  Uptime          4m 16s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.871  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              220.134    episode_length              293.980  â”‚
â”‚  x_position                  -28.810    x_velocity                  -72.314  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=1042.22 (best=205.42@491520)
æ­¥æ•° 524,288: Reward=1042.22, Best=220.13@524288, Sharpness=1.2577, Î»_max=-21.0324

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 3_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_3/vec_stats.npz
[J&R] base_task=3, new_task=3_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_3/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 0.2%  DRAM: 0.3%   VRAM: 2.9%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.042  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.230  â”‚
â”‚  SPS               4.7K      Misc        0s   0%    old_approx_kl     0.050  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.046  â”‚
â”‚  Uptime              6s      Forwaâ€¦      0s   0%    clipfrac          0.382  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.675  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.437    episode_length               46.306  â”‚
â”‚  x_position                   -6.053    x_velocity                  -47.505  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=5.01 (best=N/A)
æ­¥æ•° 32,768: Reward=5.01, Best=-1.44@32768, Sharpness=1.9829, Î»_max=-125.6553
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  92%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         5s  84%    value_loss        0.663  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.258  â”‚
â”‚  SPS               1.8K      Misc        0s   0%    old_approx_kl     0.037  â”‚
â”‚  Epoch                2    Train         0s   7%    approx_kl         0.034  â”‚
â”‚  Uptime             25s      Forwaâ€¦      0s   1%    clipfrac          0.290  â”‚
â”‚  Remainiâ€¦         4m 0s      Learn       0s   7%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.740  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.629    episode_length               58.714  â”‚
â”‚  x_position                  -10.244    x_velocity                  -60.050  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=155.75 (best=-1.44@32768)
æ­¥æ•° 65,536: Reward=155.75, Best=-1.44@32768, Sharpness=2.5970, Î»_max=-135.4283
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  92%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         5s  84%    value_loss        0.526  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.281  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.023  â”‚
â”‚  Epoch                3    Train         0s   7%    approx_kl         0.024  â”‚
â”‚  Uptime             36s      Forwaâ€¦      0s   1%    clipfrac          0.242  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.736  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.871    episode_length               67.858  â”‚
â”‚  x_position                  -14.281    x_velocity                  -66.649  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=1516.10 (best=-1.44@32768)
æ­¥æ•° 98,304: Reward=1516.10, Best=0.87@98304, Sharpness=2.3284, Î»_max=-98.4144
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡        CPU: 9.6%  GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  92%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         5s  84%    value_loss        0.421  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.307  â”‚
â”‚  SPS               1.7K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                4    Train         0s   7%    approx_kl         0.020  â”‚
â”‚  Uptime             55s      Forwaâ€¦      0s   1%    clipfrac          0.223  â”‚
â”‚  Remainiâ€¦        3m 41s      Learn       0s   7%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.760  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                9.565    episode_length               77.750  â”‚
â”‚  x_position                  -15.863    x_velocity                  -67.794  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-8.99 (best=0.87@98304)
æ­¥æ•° 131,072: Reward=-8.99, Best=9.56@131072, Sharpness=2.2504, Î»_max=-124.5009
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  92%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         5s  84%    value_loss        0.374  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          11.319  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                5    Train         0s   7%    approx_kl         0.019  â”‚
â”‚  Uptime           1m 7s      Forwaâ€¦      0s   1%    clipfrac          0.207  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.768  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               12.414    episode_length               82.248  â”‚
â”‚  x_position                  -17.580    x_velocity                  -69.420  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-9.52 (best=9.56@131072)
æ­¥æ•° 163,840: Reward=-9.52, Best=12.41@163840, Sharpness=2.2502, Î»_max=-102.2516
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  92%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.005  â”‚
â”‚  Params          135.3K      Env        10s  84%    value_loss        0.342  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          11.332  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                6    Train         1s   7%    approx_kl         0.016  â”‚
â”‚  Uptime          1m 18s      Forwaâ€¦      0s   1%    clipfrac          0.183  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.806  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.827    episode_length               85.445  â”‚
â”‚  x_position                  -17.247    x_velocity                  -69.189  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-10.11 (best=12.41@163840)
æ­¥æ•° 196,608: Reward=-10.11, Best=15.83@196608, Sharpness=2.1004, Î»_max=-130.0717
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.328  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.349  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                7    Train         1s  10%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   2%    clipfrac          0.159  â”‚
â”‚  Remainiâ€¦        1m 41s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.816  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               17.727    episode_length               91.333  â”‚
â”‚  x_position                  -22.598    x_velocity                  -73.145  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-12.79 (best=15.83@196608)
æ­¥æ•° 229,376: Reward=-12.79, Best=17.73@229376, Sharpness=2.1070, Î»_max=-96.5438
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.304  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.361  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                8    Train         1s  10%    approx_kl         0.013  â”‚
â”‚  Uptime          1m 42s      Forwaâ€¦      0s   2%    clipfrac          0.155  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.824  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               20.163    episode_length               94.200  â”‚
â”‚  x_position                  -24.711    x_velocity                  -73.561  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-13.03 (best=17.73@229376)
æ­¥æ•° 262,144: Reward=-13.03, Best=20.16@262144, Sharpness=1.9906, Î»_max=-111.9904
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.302  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.372  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                9    Train         1s  10%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 54s      Forwaâ€¦      0s   2%    clipfrac          0.121  â”‚
â”‚  Remainiâ€¦        1m 13s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.823  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               19.285    episode_length               93.606  â”‚
â”‚  x_position                  -25.659    x_velocity                  -73.848  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-12.96 (best=20.16@262144)
æ­¥æ•° 294,912: Reward=-12.96, Best=20.16@262144, Sharpness=2.0192, Î»_max=-134.7872
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     11s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.273  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.385  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch               10    Train         1s  10%    approx_kl         0.009  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   2%    clipfrac          0.110  â”‚
â”‚  Remainiâ€¦        1m 32s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               36.415    episode_length              108.269  â”‚
â”‚  x_position                  -25.432    x_velocity                  -71.301  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-13.45 (best=20.16@262144)
æ­¥æ•° 327,680: Reward=-13.45, Best=36.42@327680, Sharpness=2.1193, Î»_max=-122.5605
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.4%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env        15s  81%    value_loss        0.273  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.391  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               11    Train         2s  10%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 28s      Forwaâ€¦      0s   2%    clipfrac          0.088  â”‚
â”‚  Remainiâ€¦        1m 12s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.817  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               36.592    episode_length              114.351  â”‚
â”‚  x_position                  -33.014    x_velocity                  -77.173  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=1127.09 (best=36.42@327680)
æ­¥æ•° 360,448: Reward=1127.09, Best=36.59@360448, Sharpness=2.0492, Î»_max=-119.5855
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env        15s  76%    value_loss        0.253  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.394  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               12    Train         2s  16%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 43s      Forwaâ€¦      0s   3%    clipfrac          0.059  â”‚
â”‚  Remainiâ€¦           48s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.825  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               54.388    episode_length              131.352  â”‚
â”‚  x_position                  -34.482    x_velocity                  -76.286  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-12.89 (best=36.59@360448)
æ­¥æ•° 393,216: Reward=-12.89, Best=54.39@393216, Sharpness=2.0728, Î»_max=-137.1483
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 1.8%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env        15s  76%    value_loss        0.260  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.396  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         2s  16%    approx_kl         0.004  â”‚
â”‚  Uptime           3m 0s      Forwaâ€¦      0s   3%    clipfrac          0.038  â”‚
â”‚  Remainiâ€¦           38s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.791  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               45.823    episode_length              118.183  â”‚
â”‚  x_position                  -31.630    x_velocity                  -71.754  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-15.97 (best=54.39@393216)
æ­¥æ•° 425,984: Reward=-15.97, Best=54.39@393216, Sharpness=1.9905, Î»_max=-135.8286
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.018  â”‚
â”‚  Params          135.3K      Env        15s  76%    value_loss        0.281  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.399  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  16%    approx_kl         0.002  â”‚
â”‚  Uptime          3m 12s      Forwaâ€¦      0s   3%    clipfrac          0.021  â”‚
â”‚  Remainiâ€¦           14s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.761  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               57.239    episode_length              133.903  â”‚
â”‚  x_position                  -38.610    x_velocity                  -75.972  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=1305.34 (best=54.39@393216)
æ­¥æ•° 458,752: Reward=1305.34, Best=57.24@458752, Sharpness=2.0370, Î»_max=-114.4737
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 11.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env        15s  76%    value_loss        0.270  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.399  â”‚
â”‚  SPS               1.6K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  16%    approx_kl         0.001  â”‚
â”‚  Uptime          3m 33s      Forwaâ€¦      0s   3%    clipfrac          0.002  â”‚
â”‚  Remainiâ€¦            5s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.783  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               56.734    episode_length              132.722  â”‚
â”‚  x_position                  -38.244    x_velocity                  -75.303  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-9.98 (best=57.24@458752)
æ­¥æ•° 491,520: Reward=-9.98, Best=57.24@458752, Sharpness=2.2328, Î»_max=-112.7064
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 19.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     22s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.022  â”‚
â”‚  Params          135.3K      Env        20s  76%    value_loss        0.289  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.399  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  16%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 45s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.738  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               69.572    episode_length              146.647  â”‚
â”‚  x_position                  -40.277    x_velocity                  -76.316  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-8.24 (best=57.24@458752)
æ­¥æ•° 524,288: Reward=-8.24, Best=69.57@524288, Sharpness=2.2835, Î»_max=-107.8386

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 3_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_3/vec_stats.npz
[J&R] base_task=3, new_task=3_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_3/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 0.1%  DRAM: 0.3%   VRAM: 2.9%  â”‚
â”‚                                 22.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env         4s   0%    value_loss        3.874  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          22.632  â”‚
â”‚  SPS               5.8K      Misc        0s   0%    old_approx_kl     0.065  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.060  â”‚
â”‚  Uptime              5s      Forwaâ€¦      0s   0%    clipfrac          0.344  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.020  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.745    episode_length               18.984  â”‚
â”‚  x_position                   -2.011    x_velocity                  -27.621  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-19.72 (best=N/A)
æ­¥æ•° 32,768: Reward=-19.72, Best=-8.74@32768, Sharpness=2.1803, Î»_max=30.9181
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         4s  84%    value_loss        1.704  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          22.683  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                2    Train         0s   8%    approx_kl         0.028  â”‚
â”‚  Uptime             21s      Forwaâ€¦      0s   1%    clipfrac          0.232  â”‚
â”‚  Remainiâ€¦        3m 27s      Learn       0s   4%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.271  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.254    episode_length               20.895  â”‚
â”‚  x_position                   -2.299    x_velocity                  -28.031  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-18.65 (best=-8.74@32768)
æ­¥æ•° 65,536: Reward=-18.65, Best=-7.25@65536, Sharpness=2.1592, Î»_max=28.1897
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         4s  84%    value_loss        1.222  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          22.720  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                3    Train         0s   8%    approx_kl         0.022  â”‚
â”‚  Uptime             38s      Forwaâ€¦      0s   1%    clipfrac          0.191  â”‚
â”‚  Remainiâ€¦        3m 34s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.396  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.943    episode_length               22.514  â”‚
â”‚  x_position                   -2.523    x_velocity                  -28.330  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-9.96 (best=-7.25@65536)
æ­¥æ•° 98,304: Reward=-9.96, Best=-5.94@98304, Sharpness=1.7368, Î»_max=26.0705
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         4s  84%    value_loss        0.982  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          22.749  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                4    Train         0s   8%    approx_kl         0.019  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   1%    clipfrac          0.176  â”‚
â”‚  Remainiâ€¦        2m 56s      Learn       0s   4%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.413  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.982    episode_length               24.403  â”‚
â”‚  x_position                   -2.864    x_velocity                  -30.247  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-15.93 (best=-5.94@98304)
æ­¥æ•° 131,072: Reward=-15.93, Best=-5.94@98304, Sharpness=2.0703, Î»_max=14.0319
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.7%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 18.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         4s  84%    value_loss        0.860  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          22.778  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                5    Train         0s   8%    approx_kl         0.018  â”‚
â”‚  Uptime           1m 7s      Forwaâ€¦      0s   1%    clipfrac          0.165  â”‚
â”‚  Remainiâ€¦        2m 14s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.282  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.220    episode_length               27.179  â”‚
â”‚  x_position                   -3.475    x_velocity                  -32.245  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-15.62 (best=-5.94@98304)
æ­¥æ•° 163,840: Reward=-15.62, Best=-5.22@163840, Sharpness=1.9115, Î»_max=18.0534
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env        10s  84%    value_loss        0.776  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          22.809  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                6    Train         1s   8%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 23s      Forwaâ€¦      0s   1%    clipfrac          0.142  â”‚
â”‚  Remainiâ€¦        2m 29s      Learn       0s   4%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.259  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.550    episode_length               27.908  â”‚
â”‚  x_position                   -3.608    x_velocity                  -32.300  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-4.95 (best=-5.22@163840)
æ­¥æ•° 196,608: Reward=-4.95, Best=-4.55@196608, Sharpness=1.8675, Î»_max=18.5759
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.737  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          22.835  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                7    Train         1s  10%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 36s      Forwaâ€¦      0s   2%    clipfrac          0.124  â”‚
â”‚  Remainiâ€¦        1m 46s      Learn       0s   9%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.287  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.028    episode_length               29.556  â”‚
â”‚  x_position                   -3.928    x_velocity                  -33.417  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-15.31 (best=-4.55@196608)
æ­¥æ•° 229,376: Reward=-15.31, Best=-4.03@229376, Sharpness=1.7772, Î»_max=17.5252
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.700  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          22.856  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                8    Train         1s  10%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 52s      Forwaâ€¦      0s   2%    clipfrac          0.111  â”‚
â”‚  Remainiâ€¦        1m 52s      Learn       0s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.184  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.828    episode_length               30.618  â”‚
â”‚  x_position                   -4.035    x_velocity                  -33.272  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-85.72 (best=-4.03@229376)
æ­¥æ•° 262,144: Reward=-85.72, Best=-2.83@262144, Sharpness=2.1232, Î»_max=12.3032
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.675  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          22.875  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                9    Train         1s  10%    approx_kl         0.009  â”‚
â”‚  Uptime           2m 9s      Forwaâ€¦      0s   2%    clipfrac          0.098  â”‚
â”‚  Remainiâ€¦        1m 47s      Learn       0s   9%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.119  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.197    episode_length               33.004  â”‚
â”‚  x_position                   -4.635    x_velocity                  -36.015  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-31.17 (best=-2.83@262144)
æ­¥æ•° 294,912: Reward=-31.17, Best=-2.83@262144, Sharpness=2.0905, Î»_max=16.1799
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env        10s  81%    value_loss        0.668  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          22.890  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         1s  10%    approx_kl         0.008  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   2%    clipfrac          0.082  â”‚
â”‚  Remainiâ€¦           59s      Learn       0s   9%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.052  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.186    episode_length               35.639  â”‚
â”‚  x_position                   -5.163    x_velocity                  -37.623  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=63.63 (best=-2.83@262144)
æ­¥æ•° 327,680: Reward=63.63, Best=-2.19@327680, Sharpness=1.9805, Î»_max=16.8370
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env        14s  81%    value_loss        0.706  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          22.900  â”‚
â”‚  SPS               1.9K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  10%    approx_kl         0.006  â”‚
â”‚  Uptime          2m 38s      Forwaâ€¦      0s   2%    clipfrac          0.059  â”‚
â”‚  Remainiâ€¦        1m 12s      Learn       1s   9%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.001  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.630    episode_length               36.044  â”‚
â”‚  x_position                   -4.946    x_velocity                  -36.470  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=28.60 (best=-2.19@327680)
æ­¥æ•° 360,448: Reward=28.60, Best=-0.63@360448, Sharpness=1.6873, Î»_max=15.3855
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env        14s  85%    value_loss        0.719  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          22.908  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         1s   8%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 54s      Forwaâ€¦      0s   1%    clipfrac          0.041  â”‚
â”‚  Remainiâ€¦           53s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.004  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.180    episode_length               39.813  â”‚
â”‚  x_position                   -5.998    x_velocity                  -39.767  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=18.45 (best=-0.63@360448)
æ­¥æ•° 393,216: Reward=18.45, Best=-0.18@393216, Sharpness=1.9349, Î»_max=-15.9485
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env        14s  85%    value_loss        0.726  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          22.912  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s   8%    approx_kl         0.003  â”‚
â”‚  Uptime           3m 6s      Forwaâ€¦      0s   1%    clipfrac          0.028  â”‚
â”‚  Remainiâ€¦           26s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.015  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.555    episode_length               41.626  â”‚
â”‚  x_position                   -6.515    x_velocity                  -41.945  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=421.89 (best=-0.18@393216)
æ­¥æ•° 425,984: Reward=421.89, Best=-0.18@393216, Sharpness=2.0133, Î»_max=13.4725
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.4%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env        14s  85%    value_loss        0.704  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          22.914  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s   8%    approx_kl         0.001  â”‚
â”‚  Uptime          3m 22s      Forwaâ€¦      0s   1%    clipfrac          0.009  â”‚
â”‚  Remainiâ€¦           20s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.007  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.364    episode_length               41.750  â”‚
â”‚  x_position                   -6.194    x_velocity                  -41.151  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-13.00 (best=-0.18@393216)
æ­¥æ•° 458,752: Reward=-13.00, Best=0.36@458752, Sharpness=1.5130, Î»_max=-14.0915
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     16s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env        14s  85%    value_loss        0.751  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          22.915  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s   8%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 35s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.069  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.353    episode_length               41.494  â”‚
â”‚  x_position                   -6.429    x_velocity                  -41.612  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-30.58 (best=0.36@458752)
æ­¥æ•° 491,520: Reward=-30.58, Best=0.36@458752, Sharpness=1.6395, Î»_max=12.8904
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 3.3%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     20s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env        19s  85%    value_loss        0.766  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          22.916  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s   8%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 48s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.059  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.565    episode_length               43.458  â”‚
â”‚  x_position                   -6.622    x_velocity                  -42.647  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-30.43 (best=0.36@458752)
æ­¥æ•° 524,288: Reward=-30.43, Best=0.56@524288, Sharpness=1.8263, Î»_max=-12.9231

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 3_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 3 step sweep å®Œæˆã€‚
