==========================================
[Jump & Retrain] Walker2d task 9 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 10:54:03 EST 2025
èŠ‚ç‚¹: node10
==========================================
[Base] task=9, env=Walker2d-v4, best_model=final_model.pt, best_reward=1900.83, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_9/vec_stats.npz
[J&R] base_task=9, new_task=9_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_9/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 0.4%  DRAM: 0.3%   VRAM: 1.2%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.132  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.227  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.022  â”‚
â”‚  Uptime             11s      Forwaâ€¦      0s   0%    clipfrac          0.251  â”‚
â”‚  Remainiâ€¦        2m 40s      Learn       0s   0%    importance        0.991  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.363  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.885    episode_length               55.333  â”‚
â”‚  x_position                   -7.455    x_velocity                  -56.933  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=42.28 (best=N/A)
æ­¥æ•° 32,768: Reward=42.28, Best=-1.89@32768, Sharpness=1.2501, Î»_max=-25.4145
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 1.5%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  74%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  10%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         3s  62%    value_loss        0.573  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.263  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                2    Train         1s  25%    approx_kl         0.017  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   4%    clipfrac          0.188  â”‚
â”‚  Remainiâ€¦        2m 59s      Learn       0s   7%    importance        0.998  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.825  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.398    episode_length               85.188  â”‚
â”‚  x_position                  -12.877    x_velocity                  -69.342  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-23.45 (best=-1.89@32768)
æ­¥æ•° 65,536: Reward=-23.45, Best=15.40@65536, Sharpness=1.2916, Î»_max=-10.9609
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  74%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  10%    policy_loss      -0.036  â”‚
â”‚  Params          135.3K      Env         3s  62%    value_loss        0.409  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.286  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                3    Train         1s  25%    approx_kl         0.013  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   4%    clipfrac          0.158  â”‚
â”‚  Remainiâ€¦        2m 40s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               37.694    episode_length              134.135  â”‚
â”‚  x_position                  -29.307    x_velocity                  -95.738  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-17.26 (best=15.40@65536)
æ­¥æ•° 98,304: Reward=-17.26, Best=37.69@98304, Sharpness=1.2916, Î»_max=-30.9335
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  74%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  10%    policy_loss      -0.041  â”‚
â”‚  Params          135.3K      Env         3s  62%    value_loss        0.355  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.309  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         1s  25%    approx_kl         0.012  â”‚
â”‚  Uptime             50s      Forwaâ€¦      0s   4%    clipfrac          0.151  â”‚
â”‚  Remainiâ€¦        2m 22s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.914  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               37.511    episode_length              145.836  â”‚
â”‚  x_position                  -40.129    x_velocity                 -107.559  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-10.90 (best=37.69@98304)
æ­¥æ•° 131,072: Reward=-10.90, Best=37.69@98304, Sharpness=1.2561, Î»_max=-17.2715
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  74%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  10%    policy_loss      -0.040  â”‚
â”‚  Params          135.3K      Env         3s  62%    value_loss        0.298  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.325  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  25%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 1s      Forwaâ€¦      0s   4%    clipfrac          0.114  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       0s   7%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.920  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               57.808    episode_length              166.943  â”‚
â”‚  x_position                  -45.632    x_velocity                 -108.257  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-9.62 (best=37.69@98304)
æ­¥æ•° 163,840: Reward=-9.62, Best=57.81@163840, Sharpness=1.2512, Î»_max=-19.5185
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  74%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  10%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         7s  62%    value_loss        0.245  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.340  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         2s  25%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 17s      Forwaâ€¦      0s   4%    clipfrac          0.098  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.917  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               63.369    episode_length              174.362  â”‚
â”‚  x_position                  -52.470    x_velocity                 -110.072  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-20.82 (best=57.81@163840)
æ­¥æ•° 196,608: Reward=-20.82, Best=63.37@196608, Sharpness=1.4514, Î»_max=8.7583
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env         7s  79%    value_loss        0.210  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.353  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                7    Train         2s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 32s      Forwaâ€¦      0s   2%    clipfrac          0.088  â”‚
â”‚  Remainiâ€¦         2m 4s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               72.160    episode_length              190.740  â”‚
â”‚  x_position                  -58.161    x_velocity                 -117.576  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-3.15 (best=63.37@196608)
æ­¥æ•° 229,376: Reward=-3.15, Best=72.16@229376, Sharpness=1.3421, Î»_max=-13.1331
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 17.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         7s  79%    value_loss        0.198  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.362  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch                8    Train         2s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 44s      Forwaâ€¦      0s   2%    clipfrac          0.063  â”‚
â”‚  Remainiâ€¦        1m 27s      Learn       1s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.913  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               75.991    episode_length              192.386  â”‚
â”‚  x_position                  -61.745    x_velocity                 -115.381  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-3.82 (best=72.16@229376)
æ­¥æ•° 262,144: Reward=-3.82, Best=75.99@262144, Sharpness=1.3600, Î»_max=-16.3440
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.045  â”‚
â”‚  Params          135.3K      Env         7s  79%    value_loss        0.187  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.369  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch                9    Train         2s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 58s      Forwaâ€¦      0s   2%    clipfrac          0.056  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       1s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.903  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               97.182    episode_length              214.851  â”‚
â”‚  x_position                  -69.945    x_velocity                 -116.530  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-22.11 (best=75.99@262144)
æ­¥æ•° 294,912: Reward=-22.11, Best=97.18@294912, Sharpness=1.2883, Î»_max=-17.3350
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      8s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         7s  79%    value_loss        0.126  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.373  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         2s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 13s      Forwaâ€¦      0s   2%    clipfrac          0.058  â”‚
â”‚  Remainiâ€¦        1m 15s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              130.748    episode_length              249.833  â”‚
â”‚  x_position                  -80.545    x_velocity                 -117.763  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-5.83 (best=97.18@294912)
æ­¥æ•° 327,680: Reward=-5.83, Best=130.75@327680, Sharpness=1.3745, Î»_max=-20.1959
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.037  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.127  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.377  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         3s  13%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 28s      Forwaâ€¦      0s   2%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦         1m 5s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.892  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              161.643    episode_length              270.353  â”‚
â”‚  x_position                  -82.752    x_velocity                 -107.279  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-7.69 (best=130.75@327680)
æ­¥æ•° 360,448: Reward=-7.69, Best=161.64@360448, Sharpness=1.5397, Î»_max=-20.4547
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.029  â”‚
â”‚  Params          135.3K      Env        12s  73%    value_loss        0.109  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.380  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         3s  17%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 43s      Forwaâ€¦      0s   3%    clipfrac          0.026  â”‚
â”‚  Remainiâ€¦           46s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.882  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              198.911    episode_length              328.590  â”‚
â”‚  x_position                 -123.222    x_velocity                 -127.933  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-8.65 (best=161.64@360448)
æ­¥æ•° 393,216: Reward=-8.65, Best=198.91@393216, Sharpness=1.3776, Î»_max=-18.3707
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.047  â”‚
â”‚  Params          135.3K      Env        12s  73%    value_loss        0.110  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.384  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         3s  17%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 56s      Forwaâ€¦      0s   3%    clipfrac          0.025  â”‚
â”‚  Remainiâ€¦           28s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.888  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              196.343    episode_length              311.000  â”‚
â”‚  x_position                  -98.958    x_velocity                 -113.000  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-7.12 (best=198.91@393216)
æ­¥æ•° 425,984: Reward=-7.12, Best=198.91@393216, Sharpness=1.4787, Î»_max=-16.8971
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.050  â”‚
â”‚  Params          135.3K      Env        12s  73%    value_loss        0.117  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.387  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               14    Train         3s  17%    approx_kl         0.001  â”‚
â”‚  Uptime           3m 9s      Forwaâ€¦      0s   3%    clipfrac          0.002  â”‚
â”‚  Remainiâ€¦           17s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.858  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              222.389    episode_length              346.059  â”‚
â”‚  x_position                 -149.955    x_velocity                 -121.826  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-9.63 (best=198.91@393216)
æ­¥æ•° 458,752: Reward=-9.63, Best=222.39@458752, Sharpness=1.3575, Î»_max=-18.2548
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env        12s  73%    value_loss        0.105  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.388  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         3s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 23s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              281.226    episode_length              424.429  â”‚
â”‚  x_position                 -158.514    x_velocity                 -140.945  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-4.70 (best=222.39@458752)
æ­¥æ•° 491,520: Reward=-4.70, Best=281.23@491520, Sharpness=1.3259, Î»_max=-14.8791
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env        16s  73%    value_loss        0.099  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.388  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         4s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 37s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.777  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              224.499    episode_length              358.421  â”‚
â”‚  x_position                 -170.171    x_velocity                 -132.021  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-4.37 (best=281.23@491520)
æ­¥æ•° 524,288: Reward=-4.37, Best=281.23@491520, Sharpness=1.3407, Î»_max=-17.7414

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 9_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_9/vec_stats.npz
[J&R] base_task=9, new_task=9_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_9/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.4%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 24.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         5s   0%    value_loss        1.181  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.144  â”‚
â”‚  SPS               5.0K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              6s      Forwaâ€¦      0s   0%    clipfrac          0.267  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.343  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.699    episode_length               55.348  â”‚
â”‚  x_position                   -7.534    x_velocity                  -57.762  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=39.32 (best=N/A)
æ­¥æ•° 32,768: Reward=39.32, Best=-2.70@32768, Sharpness=1.2819, Î»_max=0.6678
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 1.4%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         5s  83%    value_loss        0.567  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.179  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         0s   8%    approx_kl         0.016  â”‚
â”‚  Uptime             21s      Forwaâ€¦      0s   1%    clipfrac          0.190  â”‚
â”‚  Remainiâ€¦        3m 13s      Learn       0s   4%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.838  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.250    episode_length               86.173  â”‚
â”‚  x_position                  -13.366    x_velocity                  -70.470  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-10.10 (best=-2.70@32768)
æ­¥æ•° 65,536: Reward=-10.10, Best=15.25@65536, Sharpness=1.2459, Î»_max=-22.2825
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.039  â”‚
â”‚  Params          135.3K      Env         5s  83%    value_loss        0.453  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.212  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                3    Train         0s   8%    approx_kl         0.013  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   1%    clipfrac          0.157  â”‚
â”‚  Remainiâ€¦        2m 39s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.864  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               34.275    episode_length              131.717  â”‚
â”‚  x_position                  -29.297    x_velocity                  -96.752  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=1.89 (best=15.25@65536)
æ­¥æ•° 98,304: Reward=1.89, Best=34.28@98304, Sharpness=1.2586, Î»_max=-20.7643
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.040  â”‚
â”‚  Params          135.3K      Env         5s  83%    value_loss        0.331  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.243  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                4    Train         0s   8%    approx_kl         0.010  â”‚
â”‚  Uptime             48s      Forwaâ€¦      0s   1%    clipfrac          0.127  â”‚
â”‚  Remainiâ€¦        2m 35s      Learn       0s   4%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               32.911    episode_length              142.137  â”‚
â”‚  x_position                  -38.150    x_velocity                 -108.483  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=0.30 (best=34.28@98304)
æ­¥æ•° 131,072: Reward=0.30, Best=34.28@98304, Sharpness=1.2210, Î»_max=-17.9309
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      5s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env         5s  83%    value_loss        0.281  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.267  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         0s   8%    approx_kl         0.009  â”‚
â”‚  Uptime             59s      Forwaâ€¦      0s   1%    clipfrac          0.117  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       0s   4%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.911  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               54.172    episode_length              163.154  â”‚
â”‚  x_position                  -43.789    x_velocity                 -108.125  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-13.91 (best=34.28@98304)
æ­¥æ•° 163,840: Reward=-13.91, Best=54.17@163840, Sharpness=1.3648, Î»_max=-16.6140
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         9s  83%    value_loss        0.243  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.285  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         1s   8%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   1%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s   4%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.921  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               64.017    episode_length              177.606  â”‚
â”‚  x_position                  -48.541    x_velocity                 -112.656  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-17.36 (best=54.17@163840)
æ­¥æ•° 196,608: Reward=-17.36, Best=64.02@196608, Sharpness=1.2849, Î»_max=-15.1151
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         9s  71%    value_loss        0.219  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.300  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                7    Train         1s  20%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 23s      Forwaâ€¦      0s   3%    clipfrac          0.085  â”‚
â”‚  Remainiâ€¦        1m 31s      Learn       0s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.918  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               76.124    episode_length              191.267  â”‚
â”‚  x_position                  -60.897    x_velocity                 -114.138  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-16.93 (best=64.02@196608)
æ­¥æ•° 229,376: Reward=-16.93, Best=76.12@229376, Sharpness=1.3167, Î»_max=-12.2589
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         9s  71%    value_loss        0.184  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.318  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         1s  20%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 34s      Forwaâ€¦      0s   3%    clipfrac          0.072  â”‚
â”‚  Remainiâ€¦        1m 17s      Learn       0s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.916  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               88.036    episode_length              203.646  â”‚
â”‚  x_position                  -57.420    x_velocity                 -114.538  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-19.17 (best=76.12@229376)
æ­¥æ•° 262,144: Reward=-19.17, Best=88.04@262144, Sharpness=1.3582, Î»_max=-14.9356
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         9s  71%    value_loss        0.168  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.327  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch                9    Train         1s  20%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 49s      Forwaâ€¦      0s   3%    clipfrac          0.057  â”‚
â”‚  Remainiâ€¦        1m 32s      Learn       0s   9%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.910  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               94.736    episode_length              220.422  â”‚
â”‚  x_position                  -75.808    x_velocity                 -124.526  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-17.36 (best=88.04@262144)
æ­¥æ•° 294,912: Reward=-17.36, Best=94.74@294912, Sharpness=1.3712, Î»_max=-16.8586
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 1.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         9s  71%    value_loss        0.126  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.331  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  20%    approx_kl         0.005  â”‚
â”‚  Uptime           2m 4s      Forwaâ€¦      0s   3%    clipfrac          0.059  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       0s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.906  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              146.177    episode_length              269.762  â”‚
â”‚  x_position                  -95.489    x_velocity                 -122.163  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-16.58 (best=94.74@294912)
æ­¥æ•° 327,680: Reward=-16.58, Best=146.18@327680, Sharpness=1.2780, Î»_max=-13.4926
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 18.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  79%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env        14s  71%    value_loss        0.112  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.338  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  20%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   3%    clipfrac          0.046  â”‚
â”‚  Remainiâ€¦         1m 4s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              158.855    episode_length              289.500  â”‚
â”‚  x_position                 -112.974    x_velocity                 -129.118  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-21.82 (best=146.18@327680)
æ­¥æ•° 360,448: Reward=-21.82, Best=158.85@360448, Sharpness=1.2335, Î»_max=-14.9579
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.119  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.344  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         2s  16%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   3%    clipfrac          0.025  â”‚
â”‚  Remainiâ€¦           39s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.897  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              147.065    episode_length              276.581  â”‚
â”‚  x_position                 -103.159    x_velocity                 -128.055  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-19.38 (best=158.85@360448)
æ­¥æ•° 393,216: Reward=-19.38, Best=158.85@360448, Sharpness=1.2975, Î»_max=-13.5193
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 1.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.103  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.348  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         2s  16%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 45s      Forwaâ€¦      0s   3%    clipfrac          0.021  â”‚
â”‚  Remainiâ€¦           31s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.878  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              239.086    episode_length              382.710  â”‚
â”‚  x_position                 -187.498    x_velocity                 -141.598  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-18.74 (best=158.85@360448)
æ­¥æ•° 425,984: Reward=-18.74, Best=239.09@425984, Sharpness=1.3001, Î»_max=14.4107
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.099  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.351  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  16%    approx_kl         0.002  â”‚
â”‚  Uptime           3m 0s      Forwaâ€¦      0s   3%    clipfrac          0.017  â”‚
â”‚  Remainiâ€¦           18s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.872  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              265.918    episode_length              392.480  â”‚
â”‚  x_position                 -127.020    x_velocity                 -124.478  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-18.71 (best=239.09@425984)
æ­¥æ•° 458,752: Reward=-18.71, Best=265.92@458752, Sharpness=1.3763, Î»_max=-9.8996
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     15s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env        14s  75%    value_loss        0.110  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.352  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  16%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 12s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.814  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              269.415    episode_length              427.000  â”‚
â”‚  x_position                 -228.676    x_velocity                 -155.332  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-14.56 (best=265.92@458752)
æ­¥æ•° 491,520: Reward=-14.56, Best=269.42@491520, Sharpness=1.4347, Î»_max=-11.4756
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     19s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.044  â”‚
â”‚  Params          135.3K      Env        18s  75%    value_loss        0.115  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.352  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  16%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 24s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.813  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              422.251    episode_length              554.917  â”‚
â”‚  x_position                 -222.313    x_velocity                 -129.711  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-13.56 (best=269.42@491520)
æ­¥æ•° 524,288: Reward=-13.56, Best=422.25@524288, Sharpness=1.2619, Î»_max=-16.1931

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 9_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_9/vec_stats.npz
[J&R] base_task=9, new_task=9_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_9/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.0%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 23.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         4s   0%    value_loss        1.191  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.885  â”‚
â”‚  SPS               6.0K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              5s      Forwaâ€¦      0s   0%    clipfrac          0.266  â”‚
â”‚  Remainiâ€¦        1m 18s      Learn       0s   0%    importance        0.993  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.500  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.449    episode_length               55.357  â”‚
â”‚  x_position                   -7.784    x_velocity                  -60.523  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=5.14 (best=N/A)
æ­¥æ•° 32,768: Reward=5.14, Best=-5.45@32768, Sharpness=1.3490, Î»_max=-53.8115
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         4s  78%    value_loss        0.642  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.924  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         0s  13%    approx_kl         0.017  â”‚
â”‚  Uptime             16s      Forwaâ€¦      0s   2%    clipfrac          0.189  â”‚
â”‚  Remainiâ€¦        2m 31s      Learn       0s  12%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.835  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                5.714    episode_length               84.411  â”‚
â”‚  x_position                  -15.110    x_velocity                  -78.261  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-21.37 (best=-5.45@32768)
æ­¥æ•° 65,536: Reward=-21.37, Best=5.71@65536, Sharpness=1.3629, Î»_max=-48.0949
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.039  â”‚
â”‚  Params          135.3K      Env         4s  78%    value_loss        0.477  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.950  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                3    Train         0s  13%    approx_kl         0.013  â”‚
â”‚  Uptime             28s      Forwaâ€¦      0s   2%    clipfrac          0.155  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.886  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.731    episode_length              117.308  â”‚
â”‚  x_position                  -30.235    x_velocity                 -100.971  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-13.45 (best=5.71@65536)
æ­¥æ•° 98,304: Reward=-13.45, Best=15.73@98304, Sharpness=1.3946, Î»_max=-34.5917
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env         4s  78%    value_loss        0.391  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.979  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                4    Train         0s  13%    approx_kl         0.012  â”‚
â”‚  Uptime             41s      Forwaâ€¦      0s   2%    clipfrac          0.147  â”‚
â”‚  Remainiâ€¦        2m 22s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.900  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.622    episode_length              129.475  â”‚
â”‚  x_position                  -37.008    x_velocity                 -106.182  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-11.25 (best=15.73@98304)
æ­¥æ•° 131,072: Reward=-11.25, Best=22.62@131072, Sharpness=1.3682, Î»_max=-28.5977
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.036  â”‚
â”‚  Params          135.3K      Env         4s  78%    value_loss        0.344  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.005  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                5    Train         0s  13%    approx_kl         0.010  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦        1m 57s      Learn       0s  12%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.904  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               36.123    episode_length              144.335  â”‚
â”‚  x_position                  -42.223    x_velocity                 -107.465  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-10.66 (best=22.62@131072)
æ­¥æ•° 163,840: Reward=-10.66, Best=36.12@163840, Sharpness=1.4250, Î»_max=-29.4547
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         8s  78%    value_loss        0.288  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.030  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                6    Train         1s  13%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.102  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       1s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.901  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               38.927    episode_length              154.868  â”‚
â”‚  x_position                  -51.144    x_velocity                 -115.138  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-14.79 (best=36.12@163840)
æ­¥æ•° 196,608: Reward=-14.79, Best=38.93@196608, Sharpness=1.4532, Î»_max=-25.0888
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.254  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.050  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                7    Train         1s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 18s      Forwaâ€¦      0s   2%    clipfrac          0.085  â”‚
â”‚  Remainiâ€¦         2m 0s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               58.053    episode_length              173.031  â”‚
â”‚  x_position                  -59.626    x_velocity                 -114.081  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-17.82 (best=38.93@196608)
æ­¥æ•° 229,376: Reward=-17.82, Best=58.05@229376, Sharpness=1.3957, Î»_max=-8.3250
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.231  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.061  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                8    Train         1s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 30s      Forwaâ€¦      0s   2%    clipfrac          0.079  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               64.819    episode_length              190.170  â”‚
â”‚  x_position                  -72.608    x_velocity                 -124.366  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-22.28 (best=58.05@229376)
æ­¥æ•° 262,144: Reward=-22.28, Best=64.82@262144, Sharpness=1.4097, Î»_max=-30.2742
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.198  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.070  â”‚
â”‚  SPS               2.2K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 45s      Forwaâ€¦      0s   2%    clipfrac          0.070  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.895  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              102.150    episode_length              229.340  â”‚
â”‚  x_position                  -87.046    x_velocity                 -126.003  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-19.65 (best=64.82@262144)
æ­¥æ•° 294,912: Reward=-19.65, Best=102.15@294912, Sharpness=1.3728, Î»_max=-23.1312
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         8s  80%    value_loss        0.191  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.077  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  11%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 58s      Forwaâ€¦      0s   2%    clipfrac          0.056  â”‚
â”‚  Remainiâ€¦         1m 8s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.892  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              108.287    episode_length              236.298  â”‚
â”‚  x_position                  -87.446    x_velocity                 -126.783  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-21.78 (best=102.15@294912)
æ­¥æ•° 327,680: Reward=-21.78, Best=108.29@327680, Sharpness=1.3040, Î»_max=-24.2647
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 1.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env        13s  80%    value_loss        0.175  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.083  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 12s      Forwaâ€¦      0s   2%    clipfrac          0.044  â”‚
â”‚  Remainiâ€¦           59s      Learn       1s   9%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.878  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              143.991    episode_length              283.492  â”‚
â”‚  x_position                 -117.748    x_velocity                 -138.029  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-18.22 (best=108.29@327680)
æ­¥æ•° 360,448: Reward=-18.22, Best=143.99@360448, Sharpness=1.4477, Î»_max=-29.4534
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 1.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.036  â”‚
â”‚  Params          135.3K      Env        13s  85%    value_loss        0.161  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          12.088  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s   8%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 26s      Forwaâ€¦      0s   1%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           46s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.876  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              177.138    episode_length              312.554  â”‚
â”‚  x_position                 -121.518    x_velocity                 -133.799  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-19.19 (best=143.99@360448)
æ­¥æ•° 393,216: Reward=-19.19, Best=177.14@393216, Sharpness=1.3842, Î»_max=-34.8549
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.038  â”‚
â”‚  Params          135.3K      Env        13s  85%    value_loss        0.161  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          12.091  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               13    Train         1s   8%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 39s      Forwaâ€¦      0s   1%    clipfrac          0.010  â”‚
â”‚  Remainiâ€¦           29s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.867  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              188.336    episode_length              330.098  â”‚
â”‚  x_position                 -145.664    x_velocity                 -140.054  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-18.29 (best=177.14@393216)
æ­¥æ•° 425,984: Reward=-18.29, Best=188.34@425984, Sharpness=1.4243, Î»_max=-37.3128
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 1.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.034  â”‚
â”‚  Params          135.3K      Env        13s  85%    value_loss        0.153  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          12.093  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s   8%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 55s      Forwaâ€¦      0s   1%    clipfrac          0.007  â”‚
â”‚  Remainiâ€¦           20s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.842  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              196.895    episode_length              345.205  â”‚
â”‚  x_position                 -155.602    x_velocity                 -146.513  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-19.40 (best=188.34@425984)
æ­¥æ•° 458,752: Reward=-19.40, Best=196.90@458752, Sharpness=1.4959, Î»_max=24.3339
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 18.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.040  â”‚
â”‚  Params          135.3K      Env        13s  85%    value_loss        0.161  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          12.094  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s   8%    approx_kl         0.000  â”‚
â”‚  Uptime           3m 8s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.829  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              285.696    episode_length              434.514  â”‚
â”‚  x_position                 -194.968    x_velocity                 -146.560  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-17.29 (best=196.90@458752)
æ­¥æ•° 491,520: Reward=-17.29, Best=285.70@491520, Sharpness=1.6038, Î»_max=-39.5361
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     20s  91%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env        18s  85%    value_loss        0.170  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          12.094  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s   8%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 20s      Forwaâ€¦      0s   1%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.775  â”‚
â”‚                              Misc        0s   1%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              283.409    episode_length              441.833  â”‚
â”‚  x_position                 -252.348    x_velocity                 -156.124  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-23.67 (best=285.70@491520)
æ­¥æ•° 524,288: Reward=-23.67, Best=285.70@491520, Sharpness=1.4611, Î»_max=-32.2253

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 9_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_9/vec_stats.npz
[J&R] base_task=9, new_task=9_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_9/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 1.6%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 20.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.351  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.062  â”‚
â”‚  SPS               6.4K      Misc        0s   0%    old_approx_kl     0.058  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.047  â”‚
â”‚  Uptime              5s      Forwaâ€¦      0s   0%    clipfrac          0.393  â”‚
â”‚  Remainiâ€¦        1m 13s      Learn       0s   0%    importance        0.989  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.564  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                5.651    episode_length               35.310  â”‚
â”‚  x_position                   -2.067    x_velocity                  -29.487  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=10.51 (best=N/A)
æ­¥æ•° 32,768: Reward=10.51, Best=5.65@32768, Sharpness=2.5834, Î»_max=-116.8578
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.9%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         3s  70%    value_loss        0.653  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.094  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                2    Train         1s  22%    approx_kl         0.028  â”‚
â”‚  Uptime             17s      Forwaâ€¦      0s   4%    clipfrac          0.275  â”‚
â”‚  Remainiâ€¦        2m 47s      Learn       0s  11%    importance        0.998  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.693  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.111    episode_length               49.901  â”‚
â”‚  x_position                   -4.691    x_velocity                  -38.546  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=23.36 (best=5.65@32768)
æ­¥æ•° 65,536: Reward=23.36, Best=11.11@65536, Sharpness=2.5043, Î»_max=-108.9060
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         3s  70%    value_loss        0.563  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.116  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.025  â”‚
â”‚  Epoch                3    Train         1s  22%    approx_kl         0.023  â”‚
â”‚  Uptime             29s      Forwaâ€¦      0s   4%    clipfrac          0.236  â”‚
â”‚  Remainiâ€¦        2m 23s      Learn       0s  11%    importance        0.998  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.778  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               14.197    episode_length               70.684  â”‚
â”‚  x_position                  -10.241    x_velocity                  -56.143  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-48.58 (best=11.11@65536)
æ­¥æ•° 98,304: Reward=-48.58, Best=14.20@98304, Sharpness=2.6804, Î»_max=-105.3637
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         3s  70%    value_loss        0.435  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.145  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                4    Train         1s  22%    approx_kl         0.018  â”‚
â”‚  Uptime             42s      Forwaâ€¦      0s   4%    clipfrac          0.203  â”‚
â”‚  Remainiâ€¦        2m 20s      Learn       0s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.819  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.876    episode_length               77.543  â”‚
â”‚  x_position                  -13.252    x_velocity                  -65.288  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-62.17 (best=14.20@98304)
æ­¥æ•° 131,072: Reward=-62.17, Best=14.20@98304, Sharpness=2.4319, Î»_max=-79.7857
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         3s  70%    value_loss        0.346  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          11.166  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                5    Train         1s  22%    approx_kl         0.016  â”‚
â”‚  Uptime             58s      Forwaâ€¦      0s   4%    clipfrac          0.180  â”‚
â”‚  Remainiâ€¦        2m 49s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.839  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               16.594    episode_length               81.888  â”‚
â”‚  x_position                  -12.977    x_velocity                  -64.894  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-31.32 (best=14.20@98304)
æ­¥æ•° 163,840: Reward=-31.32, Best=16.59@163840, Sharpness=3.0402, Î»_max=-93.2022
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  77%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         8s  70%    value_loss        0.279  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          11.187  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                6    Train         1s  22%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   4%    clipfrac          0.167  â”‚
â”‚  Remainiâ€¦         2m 5s      Learn       0s  11%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.850  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               18.947    episode_length               81.763  â”‚
â”‚  x_position                  -12.702    x_velocity                  -62.417  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-63.28 (best=16.59@163840)
æ­¥æ•° 196,608: Reward=-63.28, Best=18.95@196608, Sharpness=2.5631, Î»_max=-97.7828
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 18.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         8s  83%    value_loss        0.260  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.211  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                7    Train         1s   9%    approx_kl         0.014  â”‚
â”‚  Uptime          1m 24s      Forwaâ€¦      0s   1%    clipfrac          0.156  â”‚
â”‚  Remainiâ€¦        1m 42s      Learn       0s   5%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.853  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               19.347    episode_length               83.761  â”‚
â”‚  x_position                  -12.709    x_velocity                  -64.006  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-50.22 (best=18.95@196608)
æ­¥æ•° 229,376: Reward=-50.22, Best=19.35@229376, Sharpness=2.6549, Î»_max=-67.4044
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         8s  83%    value_loss        0.227  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.235  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                8    Train         1s   9%    approx_kl         0.011  â”‚
â”‚  Uptime          1m 36s      Forwaâ€¦      0s   1%    clipfrac          0.130  â”‚
â”‚  Remainiâ€¦        1m 25s      Learn       0s   5%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.860  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               23.116    episode_length               83.727  â”‚
â”‚  x_position                  -10.926    x_velocity                  -60.203  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-73.43 (best=19.35@229376)
æ­¥æ•° 262,144: Reward=-73.43, Best=23.12@262144, Sharpness=2.4518, Î»_max=-75.9318
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env         8s  83%    value_loss        0.220  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.256  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                9    Train         1s   9%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 48s      Forwaâ€¦      0s   1%    clipfrac          0.123  â”‚
â”‚  Remainiâ€¦        1m 14s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.857  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               21.010    episode_length               88.351  â”‚
â”‚  x_position                  -14.135    x_velocity                  -66.909  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=5.24 (best=23.12@262144)
æ­¥æ•° 294,912: Reward=5.24, Best=23.12@262144, Sharpness=2.4792, Î»_max=-71.3554
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.016  â”‚
â”‚  Params          135.3K      Env         8s  83%    value_loss        0.216  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.272  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               10    Train         1s   9%    approx_kl         0.008  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   1%    clipfrac          0.097  â”‚
â”‚  Remainiâ€¦         1m 5s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.854  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               27.574    episode_length               91.287  â”‚
â”‚  x_position                  -11.486    x_velocity                  -63.267  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-52.64 (best=23.12@262144)
æ­¥æ•° 327,680: Reward=-52.64, Best=27.57@327680, Sharpness=2.5958, Î»_max=-73.1984
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env        12s  83%    value_loss        0.211  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.286  â”‚
â”‚  SPS               2.0K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               11    Train         2s   9%    approx_kl         0.007  â”‚
â”‚  Uptime          2m 17s      Forwaâ€¦      0s   1%    clipfrac          0.080  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       1s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.847  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               31.863    episode_length               96.423  â”‚
â”‚  x_position                  -13.649    x_velocity                  -64.090  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-65.97 (best=27.57@327680)
æ­¥æ•° 360,448: Reward=-65.97, Best=31.86@360448, Sharpness=2.5042, Î»_max=-69.5052
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.023  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.215  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          11.296  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         2s  17%    approx_kl         0.005  â”‚
â”‚  Uptime          2m 28s      Forwaâ€¦      0s   4%    clipfrac          0.055  â”‚
â”‚  Remainiâ€¦           38s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.843  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               34.415    episode_length               98.636  â”‚
â”‚  x_position                  -12.078    x_velocity                  -63.741  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-89.82 (best=31.86@360448)
æ­¥æ•° 393,216: Reward=-89.82, Best=34.42@393216, Sharpness=2.5768, Î»_max=-61.5369
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 17.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.012  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.215  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          11.303  â”‚
â”‚  SPS               2.7K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         2s  17%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 40s      Forwaâ€¦      0s   4%    clipfrac          0.030  â”‚
â”‚  Remainiâ€¦           26s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.841  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               32.870    episode_length              100.578  â”‚
â”‚  x_position                  -14.192    x_velocity                  -67.219  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-109.76 (best=34.42@393216)
æ­¥æ•° 425,984: Reward=-109.76, Best=34.42@393216, Sharpness=2.6306, Î»_max=14.0140
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.025  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.236  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          11.307  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  17%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 51s      Forwaâ€¦      0s   4%    clipfrac          0.015  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               40.339    episode_length              104.792  â”‚
â”‚  x_position                  -13.831    x_velocity                  -63.943  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-63.17 (best=34.42@393216)
æ­¥æ•° 458,752: Reward=-63.17, Best=40.34@458752, Sharpness=2.5108, Î»_max=-87.1618
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.030  â”‚
â”‚  Params          135.3K      Env        12s  76%    value_loss        0.238  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          11.308  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               15    Train         2s  17%    approx_kl         0.001  â”‚
â”‚  Uptime           3m 5s      Forwaâ€¦      0s   4%    clipfrac          0.003  â”‚
â”‚  Remainiâ€¦            3s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.806  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               41.965    episode_length              103.413  â”‚
â”‚  x_position                  -13.000    x_velocity                  -60.944  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-81.98 (best=40.34@458752)
æ­¥æ•° 491,520: Reward=-81.98, Best=41.97@491520, Sharpness=2.6184, Î»_max=-79.4348
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     18s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.049  â”‚
â”‚  Params          135.3K      Env        17s  76%    value_loss        0.281  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          11.308  â”‚
â”‚  SPS               2.5K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 17s      Forwaâ€¦      0s   4%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.768  â”‚
â”‚                              Misc        0s   4%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               44.746    episode_length              107.638  â”‚
â”‚  x_position                  -14.190    x_velocity                  -62.367  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-115.66 (best=41.97@491520)
æ­¥æ•° 524,288: Reward=-115.66, Best=44.75@524288, Sharpness=2.4481, Î»_max=-90.6050

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 9_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_9/vec_stats.npz
[J&R] base_task=9, new_task=9_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_9/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.9%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 23.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.014  â”‚
â”‚  Params          135.3K      Env         4s   0%    value_loss        4.524  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          21.900  â”‚
â”‚  SPS               6.4K      Misc        0s   0%    old_approx_kl     0.058  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.056  â”‚
â”‚  Uptime              5s      Forwaâ€¦      0s   0%    clipfrac          0.349  â”‚
â”‚  Remainiâ€¦        1m 12s      Learn       0s   0%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.078  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.848    episode_length               15.386  â”‚
â”‚  x_position                   -1.340    x_velocity                  -23.148  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-12.26 (best=N/A)
æ­¥æ•° 32,768: Reward=-12.26, Best=-7.85@32768, Sharpness=2.8428, Î»_max=29.0136
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 15.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         4s  81%    value_loss        1.916  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          21.950  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.029  â”‚
â”‚  Epoch                2    Train         0s   9%    approx_kl         0.027  â”‚
â”‚  Uptime             18s      Forwaâ€¦      0s   2%    clipfrac          0.232  â”‚
â”‚  Remainiâ€¦         3m 3s      Learn       0s  15%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.335  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.713    episode_length               18.448  â”‚
â”‚  x_position                   -1.828    x_velocity                  -26.057  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-9.64 (best=-7.85@32768)
æ­¥æ•° 65,536: Reward=-9.64, Best=-7.71@65536, Sharpness=2.2730, Î»_max=12.3135
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         4s  81%    value_loss        1.196  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          21.997  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                3    Train         0s   9%    approx_kl         0.019  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.188  â”‚
â”‚  Remainiâ€¦        2m 53s      Learn       0s  15%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.372  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -7.327    episode_length               19.552  â”‚
â”‚  x_position                   -2.039    x_velocity                  -26.769  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-13.23 (best=-7.71@65536)
æ­¥æ•° 98,304: Reward=-13.23, Best=-7.33@98304, Sharpness=2.2308, Î»_max=13.7912
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         4s  81%    value_loss        0.943  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          22.039  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                4    Train         0s   9%    approx_kl         0.017  â”‚
â”‚  Uptime             44s      Forwaâ€¦      0s   2%    clipfrac          0.170  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s  15%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.376  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.329    episode_length               20.519  â”‚
â”‚  x_position                   -2.094    x_velocity                  -26.733  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-2.87 (best=-7.33@98304)
æ­¥æ•° 131,072: Reward=-2.87, Best=-6.33@131072, Sharpness=2.5701, Î»_max=2.7798
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 1.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         4s  81%    value_loss        0.786  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          22.070  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                5    Train         0s   9%    approx_kl         0.014  â”‚
â”‚  Uptime             59s      Forwaâ€¦      0s   2%    clipfrac          0.145  â”‚
â”‚  Remainiâ€¦        2m 27s      Learn       0s  15%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.281  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.752    episode_length               21.406  â”‚
â”‚  x_position                   -2.217    x_velocity                  -27.038  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-0.93 (best=-6.33@131072)
æ­¥æ•° 163,840: Reward=-0.93, Best=-5.75@163840, Sharpness=2.6362, Î»_max=-14.5684
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 18.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  90%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.750  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          22.092  â”‚
â”‚  SPS               2.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                6    Train         1s   9%    approx_kl         0.013  â”‚
â”‚  Uptime          1m 13s      Forwaâ€¦      0s   2%    clipfrac          0.139  â”‚
â”‚  Remainiâ€¦        2m 10s      Learn       1s  15%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.210  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.297    episode_length               22.805  â”‚
â”‚  x_position                   -2.457    x_velocity                  -27.974  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-5.56 (best=-5.75@163840)
æ­¥æ•° 196,608: Reward=-5.56, Best=-5.30@196608, Sharpness=2.3875, Î»_max=11.0240
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 18.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         9s  83%    value_loss        0.670  â”‚
â”‚  Steps           229.4K      Copy        0s   1%    entropy          22.115  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         1s  11%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 25s      Forwaâ€¦      0s   2%    clipfrac          0.115  â”‚
â”‚  Remainiâ€¦        1m 34s      Learn       1s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.205  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.808    episode_length               24.765  â”‚
â”‚  x_position                   -2.758    x_velocity                  -29.434  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-6.54 (best=-5.30@196608)
æ­¥æ•° 229,376: Reward=-6.54, Best=-4.81@229376, Sharpness=2.7527, Î»_max=4.4827
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 16.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         9s  83%    value_loss        0.624  â”‚
â”‚  Steps           262.1K      Copy        0s   1%    entropy          22.141  â”‚
â”‚  SPS               2.1K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                8    Train         1s  11%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 40s      Forwaâ€¦      0s   2%    clipfrac          0.095  â”‚
â”‚  Remainiâ€¦        1m 50s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.182  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.186    episode_length               24.871  â”‚
â”‚  x_position                   -2.741    x_velocity                  -28.916  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-9.32 (best=-4.81@229376)
æ­¥æ•° 262,144: Reward=-9.32, Best=-4.19@262144, Sharpness=2.6889, Î»_max=-15.5817
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         9s  83%    value_loss        0.593  â”‚
â”‚  Steps           294.9K      Copy        0s   1%    entropy          22.162  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                9    Train         1s  11%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 51s      Forwaâ€¦      0s   2%    clipfrac          0.076  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       1s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.136  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.154    episode_length               24.419  â”‚
â”‚  x_position                   -2.619    x_velocity                  -28.436  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-6.93 (best=-4.19@262144)
æ­¥æ•° 294,912: Reward=-6.93, Best=-4.15@294912, Sharpness=2.0537, Î»_max=-13.1802
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 2.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         9s  83%    value_loss        0.559  â”‚
â”‚  Steps           327.7K      Copy        0s   1%    entropy          22.177  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime           2m 5s      Forwaâ€¦      0s   2%    clipfrac          0.062  â”‚
â”‚  Remainiâ€¦        1m 11s      Learn       1s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.158  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.920    episode_length               26.227  â”‚
â”‚  x_position                   -2.931    x_velocity                  -30.000  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-5.27 (best=-4.15@294912)
æ­¥æ•° 327,680: Reward=-5.27, Best=-3.92@327680, Sharpness=2.2789, Î»_max=9.8665
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   3%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env        12s  83%    value_loss        0.566  â”‚
â”‚  Steps           360.4K      Copy        0s   1%    entropy          22.188  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.004  â”‚
â”‚  Uptime          2m 16s      Forwaâ€¦      0s   2%    clipfrac          0.044  â”‚
â”‚  Remainiâ€¦           47s      Learn       1s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.132  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.777    episode_length               27.528  â”‚
â”‚  x_position                   -3.260    x_velocity                  -31.150  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-2.68 (best=-3.92@327680)
æ­¥æ•° 360,448: Reward=-2.68, Best=-3.78@360448, Sharpness=2.1325, Î»_max=-1.0946
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.540  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          22.197  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  14%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 27s      Forwaâ€¦      0s   3%    clipfrac          0.029  â”‚
â”‚  Remainiâ€¦           34s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.136  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.479    episode_length               27.944  â”‚
â”‚  x_position                   -3.257    x_velocity                  -31.265  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=0.54 (best=-3.78@360448)
æ­¥æ•° 393,216: Reward=0.54, Best=-3.48@393216, Sharpness=2.4538, Î»_max=-11.4715
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.548  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          22.202  â”‚
â”‚  SPS               2.4K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         1s  14%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 41s      Forwaâ€¦      0s   3%    clipfrac          0.024  â”‚
â”‚  Remainiâ€¦           31s      Learn       1s  13%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.068  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.411    episode_length               27.411  â”‚
â”‚  x_position                   -3.113    x_velocity                  -30.668  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-12.07 (best=-3.48@393216)
æ­¥æ•° 425,984: Reward=-12.07, Best=-3.41@425984, Sharpness=2.3615, Î»_max=-12.9778
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.559  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          22.205  â”‚
â”‚  SPS               2.6K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  14%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 53s      Forwaâ€¦      0s   3%    clipfrac          0.012  â”‚
â”‚  Remainiâ€¦           15s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.089  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.452    episode_length               29.292  â”‚
â”‚  x_position                   -3.574    x_velocity                  -32.579  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-10.16 (best=-3.41@425984)
æ­¥æ•° 458,752: Reward=-10.16, Best=-3.41@425984, Sharpness=2.5275, Î»_max=10.2373
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.598  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          22.206  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  14%    approx_kl         0.000  â”‚
â”‚  Uptime           3m 4s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.107  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.984    episode_length               28.549  â”‚
â”‚  x_position                   -3.357    x_velocity                  -31.373  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-1.69 (best=-3.41@425984)
æ­¥æ•° 491,520: Reward=-1.69, Best=-2.98@491520, Sharpness=2.1345, Î»_max=-13.8257
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     17s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env        16s  77%    value_loss        0.588  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          22.206  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          3m 15s      Forwaâ€¦      0s   3%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       2s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦   -0.193  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.048    episode_length               28.393  â”‚
â”‚  x_position                   -3.351    x_velocity                  -31.282  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-11.15 (best=-2.98@491520)
æ­¥æ•° 524,288: Reward=-11.15, Best=-2.98@491520, Sharpness=2.2953, Î»_max=-12.2184

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 9_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 9 step sweep å®Œæˆã€‚
