==========================================
[Jump & Retrain] Walker2d task 10 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 10:54:03 EST 2025
èŠ‚ç‚¹: node11
==========================================
[Base] task=10, env=Walker2d-v4, best_model=final_model.pt, best_reward=2811.39, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_10/vec_stats.npz
[J&R] base_task=10, new_task=10_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_10/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.0%  DRAM: 0.3%   VRAM: 1.2%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.201  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.573  â”‚
â”‚  SPS               3.8K      Misc        0s   0%    old_approx_kl     0.033  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              8s      Forwaâ€¦      0s   0%    clipfrac          0.252  â”‚
â”‚  Remainiâ€¦         2m 4s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.497  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.998    episode_length               57.679  â”‚
â”‚  x_position                   -8.541    x_velocity                  -69.375  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=93.34 (best=N/A)
æ­¥æ•° 32,768: Reward=93.34, Best=-12.00@32768, Sharpness=1.3891, Î»_max=-52.7215
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.0%  DRAM: 0.4%   VRAM: 1.4%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         3s  55%    value_loss        0.686  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.611  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                2    Train         1s  31%    approx_kl         0.019  â”‚
â”‚  Uptime             18s      Forwaâ€¦      0s   6%    clipfrac          0.217  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s  12%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.806  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.348    episode_length               90.381  â”‚
â”‚  x_position                  -14.389    x_velocity                  -78.552  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-20.71 (best=-12.00@32768)
æ­¥æ•° 65,536: Reward=-20.71, Best=11.35@65536, Sharpness=1.4025, Î»_max=-54.9423
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         3s  55%    value_loss        0.502  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.644  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                3    Train         1s  31%    approx_kl         0.016  â”‚
â”‚  Uptime             28s      Forwaâ€¦      0s   6%    clipfrac          0.191  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       0s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.841  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                3.968    episode_length               96.186  â”‚
â”‚  x_position                  -20.536    x_velocity                  -91.705  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-16.17 (best=11.35@65536)
æ­¥æ•° 98,304: Reward=-16.17, Best=11.35@65536, Sharpness=1.3717, Î»_max=-54.1349
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         3s  55%    value_loss        0.317  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.682  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                4    Train         1s  31%    approx_kl         0.010  â”‚
â”‚  Uptime             37s      Forwaâ€¦      0s   6%    clipfrac          0.133  â”‚
â”‚  Remainiâ€¦        1m 49s      Learn       0s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.770  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.941    episode_length               81.717  â”‚
â”‚  x_position                  -19.391    x_velocity                  -88.221  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-18.66 (best=11.35@65536)
æ­¥æ•° 131,072: Reward=-18.66, Best=11.35@65536, Sharpness=1.4086, Î»_max=-53.9485
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      4s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  55%    value_loss        0.217  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.715  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  31%    approx_kl         0.010  â”‚
â”‚  Uptime             47s      Forwaâ€¦      0s   6%    clipfrac          0.123  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.627  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.779    episode_length               80.203  â”‚
â”‚  x_position                  -20.167    x_velocity                  -88.554  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-17.48 (best=11.35@65536)
æ­¥æ•° 163,840: Reward=-17.48, Best=11.35@65536, Sharpness=1.4271, Î»_max=-48.2844
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  68%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s  11%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         6s  55%    value_loss        0.152  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.743  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         2s  31%    approx_kl         0.009  â”‚
â”‚  Uptime             57s      Forwaâ€¦      0s   6%    clipfrac          0.119  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       1s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.600  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.120    episode_length               78.063  â”‚
â”‚  x_position                  -20.467    x_velocity                  -88.766  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-10.66 (best=11.35@65536)
æ­¥æ•° 196,608: Reward=-10.66, Best=11.35@65536, Sharpness=1.4267, Î»_max=-46.0574
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.141  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.764  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  13%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 6s      Forwaâ€¦      0s   2%    clipfrac          0.113  â”‚
â”‚  Remainiâ€¦        1m 19s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.661  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.087    episode_length               78.860  â”‚
â”‚  x_position                  -20.795    x_velocity                  -90.528  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-6.89 (best=11.35@65536)
æ­¥æ•° 229,376: Reward=-6.89, Best=11.35@65536, Sharpness=1.4625, Î»_max=-46.6680
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.149  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.776  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         2s  13%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 16s      Forwaâ€¦      0s   2%    clipfrac          0.095  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.651  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.300    episode_length               83.851  â”‚
â”‚  x_position                  -22.756    x_velocity                  -93.707  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-5.75 (best=11.35@65536)
æ­¥æ•° 262,144: Reward=-5.75, Best=11.35@65536, Sharpness=1.4496, Î»_max=-44.9792
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.007  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.147  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.793  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         2s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 26s      Forwaâ€¦      0s   2%    clipfrac          0.080  â”‚
â”‚  Remainiâ€¦         1m 1s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.711  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.526    episode_length               83.774  â”‚
â”‚  x_position                  -23.479    x_velocity                  -95.858  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-9.33 (best=11.35@65536)
æ­¥æ•° 294,912: Reward=-9.33, Best=11.35@65536, Sharpness=1.4339, Î»_max=-43.9342
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 5.2%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.165  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.806  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         2s  13%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   2%    clipfrac          0.078  â”‚
â”‚  Remainiâ€¦           49s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.772  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -9.378    episode_length               91.864  â”‚
â”‚  x_position                  -25.981    x_velocity                 -100.757  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-15.19 (best=11.35@65536)
æ­¥æ•° 327,680: Reward=-15.19, Best=11.35@65536, Sharpness=1.4933, Î»_max=-44.2387
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 5.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.191  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.815  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               11    Train         2s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 45s      Forwaâ€¦      0s   2%    clipfrac          0.059  â”‚
â”‚  Remainiâ€¦           41s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.801  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.539    episode_length              103.436  â”‚
â”‚  x_position                  -29.661    x_velocity                 -105.430  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-16.61 (best=11.35@65536)
æ­¥æ•° 360,448: Reward=-16.61, Best=11.35@65536, Sharpness=1.4861, Î»_max=-43.8732
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.027  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.205  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.821  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         2s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 55s      Forwaâ€¦      0s   2%    clipfrac          0.054  â”‚
â”‚  Remainiâ€¦           32s      Learn       1s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.827  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                0.846    episode_length              108.965  â”‚
â”‚  x_position                  -30.888    x_velocity                 -107.546  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-17.33 (best=11.35@65536)
æ­¥æ•° 393,216: Reward=-17.33, Best=11.35@65536, Sharpness=1.4538, Î»_max=-40.0267
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.259  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.824  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         2s  15%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 5s      Forwaâ€¦      0s   2%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.833  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.129    episode_length              120.365  â”‚
â”‚  x_position                  -32.619    x_velocity                 -109.605  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-18.36 (best=11.35@65536)
æ­¥æ•° 425,984: Reward=-18.36, Best=11.35@65536, Sharpness=1.4386, Î»_max=-42.8937
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.015  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.233  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.827  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         2s  15%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 14s      Forwaâ€¦      0s   2%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s  12%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.849  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               14.365    episode_length              127.456  â”‚
â”‚  x_position                  -36.645    x_velocity                 -112.422  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-16.13 (best=11.35@65536)
æ­¥æ•° 458,752: Reward=-16.13, Best=14.37@458752, Sharpness=1.5063, Î»_max=-33.6949
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.034  â”‚
â”‚  Params          135.3K      Env         9s  77%    value_loss        0.321  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.828  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               15    Train         2s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 25s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.807  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               30.418    episode_length              144.776  â”‚
â”‚  x_position                  -40.440    x_velocity                 -113.599  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-15.69 (best=14.37@458752)
æ­¥æ•° 491,520: Reward=-15.69, Best=30.42@491520, Sharpness=1.4413, Î»_max=-36.0540
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     14s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   4%    policy_loss       0.079  â”‚
â”‚  Params          135.3K      Env        12s  77%    value_loss        0.375  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.828  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         3s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 35s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  12%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.763  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               51.622    episode_length              157.121  â”‚
â”‚  x_position                  -37.066    x_velocity                 -104.678  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-15.37 (best=30.42@491520)
æ­¥æ•° 524,288: Reward=-15.37, Best=51.62@524288, Sharpness=1.6698, Î»_max=-29.7687

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 10_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_10/vec_stats.npz
[J&R] base_task=10, new_task=10_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_10/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.189  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.479  â”‚
â”‚  SPS               8.5K      Misc        0s   0%    old_approx_kl     0.032  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.023  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.254  â”‚
â”‚  Remainiâ€¦           55s      Learn       0s   0%    importance        0.991  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.469  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.512    episode_length               55.594  â”‚
â”‚  x_position                   -8.121    x_velocity                  -63.815  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=71.78 (best=N/A)
æ­¥æ•° 32,768: Reward=71.78, Best=-8.51@32768, Sharpness=1.3913, Î»_max=-55.6725
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.6%  DRAM: 0.4%   VRAM: 1.5%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.660  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.513  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                2    Train         0s  16%    approx_kl         0.022  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.236  â”‚
â”‚  Remainiâ€¦        2m 14s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.788  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                7.875    episode_length               93.526  â”‚
â”‚  x_position                  -16.630    x_velocity                  -85.157  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-17.07 (best=-8.51@32768)
æ­¥æ•° 65,536: Reward=-17.07, Best=7.87@65536, Sharpness=1.4182, Î»_max=-53.8176
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.479  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.542  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                3    Train         0s  16%    approx_kl         0.014  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.175  â”‚
â”‚  Remainiâ€¦         2m 2s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.818  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                1.764    episode_length               96.131  â”‚
â”‚  x_position                  -21.338    x_velocity                  -93.856  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-18.11 (best=7.87@65536)
æ­¥æ•° 98,304: Reward=-18.11, Best=7.87@65536, Sharpness=1.4185, Î»_max=-52.3467
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.295  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.570  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                4    Train         0s  16%    approx_kl         0.012  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.146  â”‚
â”‚  Remainiâ€¦        1m 48s      Learn       0s  11%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.722  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.214    episode_length               81.120  â”‚
â”‚  x_position                  -19.858    x_velocity                  -88.903  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-22.00 (best=7.87@65536)
æ­¥æ•° 131,072: Reward=-22.00, Best=7.87@65536, Sharpness=1.4314, Î»_max=-56.9631
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.7%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         2s  76%    value_loss        0.186  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.600  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         0s  16%    approx_kl         0.011  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.134  â”‚
â”‚  Remainiâ€¦        1m 38s      Learn       0s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.560  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.077    episode_length               73.981  â”‚
â”‚  x_position                  -18.263    x_velocity                  -84.664  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-13.06 (best=7.87@65536)
æ­¥æ•° 163,840: Reward=-13.06, Best=7.87@65536, Sharpness=1.4375, Î»_max=-52.5193
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         5s  76%    value_loss        0.141  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.633  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                6    Train         1s  16%    approx_kl         0.008  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.105  â”‚
â”‚  Remainiâ€¦        1m 28s      Learn       0s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.518  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.403    episode_length               76.181  â”‚
â”‚  x_position                  -20.218    x_velocity                  -88.180  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-13.92 (best=7.87@65536)
æ­¥æ•° 196,608: Reward=-13.92, Best=7.87@65536, Sharpness=1.4086, Î»_max=-50.8876
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.134  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.663  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                7    Train         1s  12%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.096  â”‚
â”‚  Remainiâ€¦        1m 17s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.574  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.719    episode_length               77.500  â”‚
â”‚  x_position                  -20.112    x_velocity                  -88.808  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-11.47 (best=7.87@65536)
æ­¥æ•° 229,376: Reward=-11.47, Best=7.87@65536, Sharpness=1.4202, Î»_max=-44.5198
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.131  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.679  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s  12%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 11s      Forwaâ€¦      0s   2%    clipfrac          0.094  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.644  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.830    episode_length               79.310  â”‚
â”‚  x_position                  -21.157    x_velocity                  -90.722  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-12.23 (best=7.87@65536)
æ­¥æ•° 262,144: Reward=-12.23, Best=7.87@65536, Sharpness=1.4677, Î»_max=-38.6811
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.149  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.694  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch                9    Train         1s  12%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.071  â”‚
â”‚  Remainiâ€¦           58s      Learn       0s   7%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.690  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.772    episode_length               82.199  â”‚
â”‚  x_position                  -22.569    x_velocity                  -93.538  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-6.85 (best=7.87@65536)
æ­¥æ•° 294,912: Reward=-6.85, Best=7.87@65536, Sharpness=1.4378, Î»_max=-42.4285
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.6%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env         5s  79%    value_loss        0.172  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.710  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         1s  12%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.081  â”‚
â”‚  Remainiâ€¦           53s      Learn       0s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.766  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.554    episode_length               87.645  â”‚
â”‚  x_position                  -24.468    x_velocity                  -97.740  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-8.80 (best=7.87@65536)
æ­¥æ•° 327,680: Reward=-8.80, Best=7.87@65536, Sharpness=1.4759, Î»_max=-44.2652
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.022  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.197  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.721  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         1s  12%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.075  â”‚
â”‚  Remainiâ€¦           41s      Learn       0s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.811  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -6.434    episode_length               94.696  â”‚
â”‚  x_position                  -26.641    x_velocity                 -100.634  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-3.94 (best=7.87@65536)
æ­¥æ•° 360,448: Reward=-3.94, Best=7.87@65536, Sharpness=1.4353, Î»_max=-35.9425
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 5.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.013  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.232  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.727  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               12    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 51s      Forwaâ€¦      0s   2%    clipfrac          0.073  â”‚
â”‚  Remainiâ€¦           31s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.833  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.255    episode_length              104.004  â”‚
â”‚  x_position                  -29.617    x_velocity                 -106.716  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-6.55 (best=7.87@65536)
æ­¥æ•° 393,216: Reward=-6.55, Best=7.87@65536, Sharpness=1.4803, Î»_max=-40.5469
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.041  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.269  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.730  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         1s  11%    approx_kl         0.004  â”‚
â”‚  Uptime           2m 1s      Forwaâ€¦      0s   2%    clipfrac          0.048  â”‚
â”‚  Remainiâ€¦           22s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.841  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               10.132    episode_length              122.511  â”‚
â”‚  x_position                  -34.635    x_velocity                 -111.742  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-18.51 (best=7.87@65536)
æ­¥æ•° 425,984: Reward=-18.51, Best=10.13@425984, Sharpness=1.4650, Î»_max=-34.9038
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.018  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.295  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.733  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  11%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 11s      Forwaâ€¦      0s   2%    clipfrac          0.025  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.840  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.356    episode_length              138.039  â”‚
â”‚  x_position                  -36.413    x_velocity                 -107.965  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-20.79 (best=10.13@425984)
æ­¥æ•° 458,752: Reward=-20.79, Best=29.36@458752, Sharpness=1.5031, Î»_max=-23.8798
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.043  â”‚
â”‚  Params          135.3K      Env         9s  81%    value_loss        0.314  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.734  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  11%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 21s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.803  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               45.976    episode_length              155.804  â”‚
â”‚  x_position                  -36.578    x_velocity                 -109.017  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-19.24 (best=29.36@458752)
æ­¥æ•° 491,520: Reward=-19.24, Best=45.98@491520, Sharpness=1.5106, Î»_max=-29.0511
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.035  â”‚
â”‚  Params          135.3K      Env        12s  81%    value_loss        0.350  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.735  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  11%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.756  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               53.369    episode_length              159.930  â”‚
â”‚  x_position                  -36.344    x_velocity                 -105.728  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-29.46 (best=45.98@491520)
æ­¥æ•° 524,288: Reward=-29.46, Best=53.37@524288, Sharpness=1.5369, Î»_max=-29.9288

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 10_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_10/vec_stats.npz
[J&R] base_task=10, new_task=10_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_10/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 5.7%  GPU: 0.0%  DRAM: 0.2%   VRAM: 0.8%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.215  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.195  â”‚
â”‚  SPS               8.3K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.263  â”‚
â”‚  Remainiâ€¦           56s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.468  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -8.328    episode_length               52.500  â”‚
â”‚  x_position                   -6.999    x_velocity                  -60.554  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=175.72 (best=N/A)
æ­¥æ•° 32,768: Reward=175.72, Best=-8.33@32768, Sharpness=1.5151, Î»_max=-71.4960
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.588  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.225  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.020  â”‚
â”‚  Epoch                2    Train         0s  11%    approx_kl         0.017  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.196  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s   6%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.806  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               21.023    episode_length               89.363  â”‚
â”‚  x_position                  -10.840    x_velocity                  -67.865  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-14.67 (best=-8.33@32768)
æ­¥æ•° 65,536: Reward=-14.67, Best=21.02@65536, Sharpness=1.5813, Î»_max=-72.0966
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 5.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.028  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.429  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.251  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                3    Train         0s  11%    approx_kl         0.017  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.184  â”‚
â”‚  Remainiâ€¦        1m 55s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.853  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               18.756    episode_length              100.560  â”‚
â”‚  x_position                  -16.868    x_velocity                  -81.266  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-35.80 (best=21.02@65536)
æ­¥æ•° 98,304: Reward=-35.80, Best=21.02@65536, Sharpness=1.5592, Î»_max=-74.4544
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 5.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.320  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.285  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         0s  11%    approx_kl         0.014  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.171  â”‚
â”‚  Remainiâ€¦        1m 51s      Learn       0s   6%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.847  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                7.591    episode_length               96.355  â”‚
â”‚  x_position                  -21.164    x_velocity                  -88.249  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-8.42 (best=21.02@65536)
æ­¥æ•° 131,072: Reward=-8.42, Best=21.02@65536, Sharpness=1.5089, Î»_max=-64.4224
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.020  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.242  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.319  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         0s  11%    approx_kl         0.012  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.150  â”‚
â”‚  Remainiâ€¦        1m 37s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.818  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                4.188    episode_length               92.259  â”‚
â”‚  x_position                  -21.080    x_velocity                  -87.577  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-13.54 (best=21.02@65536)
æ­¥æ•° 163,840: Reward=-13.54, Best=21.02@65536, Sharpness=1.5910, Î»_max=-70.8545
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.204  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.345  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         0s  11%    approx_kl         0.011  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.138  â”‚
â”‚  Remainiâ€¦        1m 30s      Learn       0s   6%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.793  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                2.929    episode_length               91.228  â”‚
â”‚  x_position                  -21.006    x_velocity                  -87.811  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-14.20 (best=21.02@65536)
æ­¥æ•° 196,608: Reward=-14.20, Best=21.02@65536, Sharpness=1.6452, Î»_max=-60.5171
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.177  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.373  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                7    Train         0s  12%    approx_kl         0.010  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.129  â”‚
â”‚  Remainiâ€¦        1m 19s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.806  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                7.562    episode_length               99.277  â”‚
â”‚  x_position                  -22.896    x_velocity                  -91.185  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-17.75 (best=21.02@65536)
æ­¥æ•° 229,376: Reward=-17.75, Best=21.02@65536, Sharpness=1.6239, Î»_max=-53.4813
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.000  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.179  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.394  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                8    Train         0s  12%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.116  â”‚
â”‚  Remainiâ€¦        1m 10s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.847  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               13.192    episode_length              107.468  â”‚
â”‚  x_position                  -24.621    x_velocity                  -93.703  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-20.20 (best=21.02@65536)
æ­¥æ•° 262,144: Reward=-20.20, Best=21.02@65536, Sharpness=1.6387, Î»_max=-61.8678
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.201  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.415  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                9    Train         0s  12%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.866  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               16.412    episode_length              117.412  â”‚
â”‚  x_position                  -28.722    x_velocity                 -100.376  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-15.95 (best=21.02@65536)
æ­¥æ•° 294,912: Reward=-15.95, Best=21.02@65536, Sharpness=1.7417, Î»_max=-49.9292
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.224  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.430  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         0s  12%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.080  â”‚
â”‚  Remainiâ€¦           51s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.877  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.795    episode_length              127.871  â”‚
â”‚  x_position                  -31.655    x_velocity                 -104.399  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-15.51 (best=21.02@65536)
æ­¥æ•° 327,680: Reward=-15.51, Best=22.80@327680, Sharpness=1.7464, Î»_max=-46.9922
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.243  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.445  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         1s  12%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.066  â”‚
â”‚  Remainiâ€¦           41s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.881  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               33.946    episode_length              145.647  â”‚
â”‚  x_position                  -38.036    x_velocity                 -110.933  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-14.60 (best=22.80@327680)
æ­¥æ•° 360,448: Reward=-14.60, Best=33.95@360448, Sharpness=1.6559, Î»_max=-50.2287
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.279  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.456  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               12    Train         1s  13%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.047  â”‚
â”‚  Remainiâ€¦           30s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.875  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               54.053    episode_length              160.614  â”‚
â”‚  x_position                  -36.522    x_velocity                 -105.719  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-16.96 (best=33.95@360448)
æ­¥æ•° 393,216: Reward=-16.96, Best=54.05@393216, Sharpness=1.6889, Î»_max=-52.5603
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.283  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.462  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         1s  13%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.030  â”‚
â”‚  Remainiâ€¦           21s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.868  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               72.928    episode_length              175.659  â”‚
â”‚  x_position                  -40.042    x_velocity                 -101.809  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-18.94 (best=54.05@393216)
æ­¥æ•° 425,984: Reward=-18.94, Best=72.93@425984, Sharpness=1.7988, Î»_max=-40.6987
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.307  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.465  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  13%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.007  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.852  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               88.374    episode_length              185.941  â”‚
â”‚  x_position                  -37.567    x_velocity                  -96.593  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-15.73 (best=72.93@425984)
æ­¥æ•° 458,752: Reward=-15.73, Best=88.37@458752, Sharpness=1.7741, Î»_max=-50.5633
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.288  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.466  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.849  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              103.380    episode_length              205.636  â”‚
â”‚  x_position                  -39.852    x_velocity                 -101.178  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-17.00 (best=88.37@458752)
æ­¥æ•° 491,520: Reward=-17.00, Best=103.38@491520, Sharpness=1.6377, Î»_max=-60.1977
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.048  â”‚
â”‚  Params          135.3K      Env        12s  79%    value_loss        0.370  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.466  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         1s  13%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 28s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.765  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              149.846    episode_length              246.488  â”‚
â”‚  x_position                  -48.276    x_velocity                  -95.349  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-13.63 (best=103.38@491520)
æ­¥æ•° 524,288: Reward=-13.63, Best=149.85@524288, Sharpness=1.8302, Î»_max=-42.5870

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 10_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_10/vec_stats.npz
[J&R] base_task=10, new_task=10_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_10/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 21.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.224  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.294  â”‚
â”‚  SPS               8.4K      Misc        0s   0%    old_approx_kl     0.064  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.050  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.386  â”‚
â”‚  Remainiâ€¦           55s      Learn       0s   0%    importance        0.986  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.428  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                6.814    episode_length               54.577  â”‚
â”‚  x_position                   -4.517    x_velocity                  -47.481  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=75.73 (best=N/A)
æ­¥æ•° 32,768: Reward=75.73, Best=6.81@32768, Sharpness=2.8184, Î»_max=-214.4064
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.7%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 16.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.705  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          11.328  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.039  â”‚
â”‚  Epoch                2    Train         0s  12%    approx_kl         0.038  â”‚
â”‚  Uptime             13s      Forwaâ€¦      0s   2%    clipfrac          0.307  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.763  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               19.518    episode_length               85.544  â”‚
â”‚  x_position                   -9.883    x_velocity                  -65.581  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=4.90 (best=6.81@32768)
æ­¥æ•° 65,536: Reward=4.90, Best=19.52@65536, Sharpness=2.7080, Î»_max=-214.8596
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.575  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          11.351  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.032  â”‚
â”‚  Epoch                3    Train         0s  12%    approx_kl         0.031  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.278  â”‚
â”‚  Remainiâ€¦        1m 58s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.816  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               20.169    episode_length               94.478  â”‚
â”‚  x_position                  -12.706    x_velocity                  -73.811  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-3.68 (best=19.52@65536)
æ­¥æ•° 98,304: Reward=-3.68, Best=20.17@98304, Sharpness=2.6048, Î»_max=-206.4496
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.426  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          11.375  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.026  â”‚
â”‚  Epoch                4    Train         0s  12%    approx_kl         0.025  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.243  â”‚
â”‚  Remainiâ€¦        1m 52s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.830  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.008    episode_length               94.121  â”‚
â”‚  x_position                  -14.991    x_velocity                  -78.616  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-12.60 (best=20.17@98304)
æ­¥æ•° 131,072: Reward=-12.60, Best=20.17@98304, Sharpness=2.5979, Î»_max=-201.3248
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         3s  80%    value_loss        0.375  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          11.396  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                5    Train         0s  12%    approx_kl         0.022  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.219  â”‚
â”‚  Remainiâ€¦        1m 40s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.821  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               15.154    episode_length               99.109  â”‚
â”‚  x_position                  -16.916    x_velocity                  -83.431  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-14.47 (best=20.17@98304)
æ­¥æ•° 163,840: Reward=-14.47, Best=20.17@98304, Sharpness=2.6294, Î»_max=-216.7570
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.299  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          11.414  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                6    Train         1s  12%    approx_kl         0.019  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.196  â”‚
â”‚  Remainiâ€¦        1m 27s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.810  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               13.758    episode_length               99.873  â”‚
â”‚  x_position                  -18.172    x_velocity                  -85.588  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-14.69 (best=20.17@98304)
æ­¥æ•° 196,608: Reward=-14.69, Best=20.17@98304, Sharpness=2.6039, Î»_max=-192.5969
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.258  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.433  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                7    Train         1s  15%    approx_kl         0.015  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.160  â”‚
â”‚  Remainiâ€¦        1m 19s      Learn       0s   8%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.785  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                9.477    episode_length               98.107  â”‚
â”‚  x_position                  -19.316    x_velocity                  -88.112  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-14.95 (best=20.17@98304)
æ­¥æ•° 229,376: Reward=-14.95, Best=20.17@98304, Sharpness=2.5333, Î»_max=-214.9660
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.219  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.446  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                8    Train         1s  15%    approx_kl         0.013  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.146  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       0s   8%    importance        1.003  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.754  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.176    episode_length               97.922  â”‚
â”‚  x_position                  -20.375    x_velocity                  -89.230  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-16.09 (best=20.17@98304)
æ­¥æ•° 262,144: Reward=-16.09, Best=20.17@98304, Sharpness=2.5942, Î»_max=-216.9475
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.202  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.463  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                9    Train         1s  15%    approx_kl         0.010  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.122  â”‚
â”‚  Remainiâ€¦           57s      Learn       0s   8%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.734  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                9.225    episode_length              102.542  â”‚
â”‚  x_position                  -22.356    x_velocity                  -92.776  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-15.57 (best=20.17@98304)
æ­¥æ•° 294,912: Reward=-15.57, Best=20.17@98304, Sharpness=2.6349, Î»_max=-189.6351
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.195  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.478  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch               10    Train         1s  15%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦           51s      Learn       0s   8%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.727  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                9.556    episode_length              100.861  â”‚
â”‚  x_position                  -21.834    x_velocity                  -90.774  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-16.29 (best=20.17@98304)
æ­¥æ•° 327,680: Reward=-16.29, Best=20.17@98304, Sharpness=2.5211, Î»_max=-201.0707
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.018  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.196  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.488  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.075  â”‚
â”‚  Remainiâ€¦           42s      Learn       0s   8%    importance        1.002  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.747  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                5.932    episode_length               99.260  â”‚
â”‚  x_position                  -23.226    x_velocity                  -92.804  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-19.46 (best=20.17@98304)
æ­¥æ•° 360,448: Reward=-19.46, Best=20.17@98304, Sharpness=2.5501, Î»_max=-201.7354
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.006  â”‚
â”‚  Params          135.3K      Env         9s  82%    value_loss        0.195  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          11.495  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               12    Train         1s  10%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.064  â”‚
â”‚  Remainiâ€¦           31s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.746  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               13.140    episode_length              109.970  â”‚
â”‚  x_position                  -26.806    x_velocity                  -96.250  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-21.36 (best=20.17@98304)
æ­¥æ•° 393,216: Reward=-21.36, Best=20.17@98304, Sharpness=2.5794, Î»_max=-216.1592
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.011  â”‚
â”‚  Params          135.3K      Env         9s  82%    value_loss        0.197  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          11.500  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  10%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.033  â”‚
â”‚  Remainiâ€¦           20s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.722  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.708    episode_length              106.069  â”‚
â”‚  x_position                  -24.719    x_velocity                  -96.802  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-17.16 (best=20.17@98304)
æ­¥æ•° 425,984: Reward=-17.16, Best=20.17@98304, Sharpness=2.4544, Î»_max=-226.9718
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 5.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.031  â”‚
â”‚  Params          135.3K      Env         9s  82%    value_loss        0.220  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          11.503  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  10%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 9s      Forwaâ€¦      0s   2%    clipfrac          0.014  â”‚
â”‚  Remainiâ€¦           12s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.711  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.311    episode_length              107.721  â”‚
â”‚  x_position                  -26.011    x_velocity                  -95.842  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-20.28 (best=20.17@98304)
æ­¥æ•° 458,752: Reward=-20.28, Best=20.17@98304, Sharpness=2.6184, Î»_max=-214.3522
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 15.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.019  â”‚
â”‚  Params          135.3K      Env         9s  82%    value_loss        0.234  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          11.505  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  10%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 19s      Forwaâ€¦      0s   2%    clipfrac          0.001  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.708  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               11.857    episode_length              109.815  â”‚
â”‚  x_position                  -27.330    x_velocity                  -97.378  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-15.00 (best=20.17@98304)
æ­¥æ•° 491,520: Reward=-15.00, Best=20.17@98304, Sharpness=2.6077, Î»_max=-204.3324
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.4%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  89%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.020  â”‚
â”‚  Params          135.3K      Env        12s  82%    value_loss        0.229  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          11.506  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  10%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.674  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               12.774    episode_length              109.269  â”‚
â”‚  x_position                  -26.973    x_velocity                  -95.917  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-19.45 (best=20.17@98304)
æ­¥æ•° 524,288: Reward=-19.45, Best=20.17@98304, Sharpness=2.5402, Î»_max=-100.5406

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 10_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_10/vec_stats.npz
[J&R] base_task=10, new_task=10_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_10/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 5.8%  GPU: 0.0%  DRAM: 0.2%   VRAM: 0.8%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.012  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        3.342  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          23.225  â”‚
â”‚  SPS               7.7K      Misc        0s   0%    old_approx_kl     0.082  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.074  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.363  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   0%    importance        0.992  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.113  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.636    episode_length               17.520  â”‚
â”‚  x_position                   -1.497    x_velocity                  -22.056  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-4.95 (best=N/A)
æ­¥æ•° 32,768: Reward=-4.95, Best=-4.64@32768, Sharpness=3.0341, Î»_max=-28.6841
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.6%  â”‚
â”‚                                 17.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        1.541  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          23.261  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.036  â”‚
â”‚  Epoch                2    Train         0s  14%    approx_kl         0.032  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.237  â”‚
â”‚  Remainiâ€¦        2m 10s      Learn       0s  10%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.239  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.545    episode_length               21.729  â”‚
â”‚  x_position                   -2.226    x_velocity                  -25.150  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-20.21 (best=-4.64@32768)
æ­¥æ•° 65,536: Reward=-20.21, Best=-3.54@65536, Sharpness=3.0023, Î»_max=-20.4147
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.8%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        1.187  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          23.296  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.024  â”‚
â”‚  Epoch                3    Train         0s  14%    approx_kl         0.024  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.200  â”‚
â”‚  Remainiâ€¦         2m 2s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.092  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.215    episode_length               24.235  â”‚
â”‚  x_position                   -2.679    x_velocity                  -26.312  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-17.12 (best=-3.54@65536)
æ­¥æ•° 98,304: Reward=-17.12, Best=-2.21@98304, Sharpness=2.8425, Î»_max=-16.0812
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        1.047  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          23.331  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.023  â”‚
â”‚  Epoch                4    Train         0s  14%    approx_kl         0.021  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.182  â”‚
â”‚  Remainiâ€¦        1m 48s      Learn       0s  10%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.024  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.207    episode_length               26.782  â”‚
â”‚  x_position                   -3.072    x_velocity                  -27.837  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-14.43 (best=-2.21@98304)
æ­¥æ•° 131,072: Reward=-14.43, Best=-1.21@131072, Sharpness=3.3914, Î»_max=-2.8458
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         3s  78%    value_loss        0.976  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          23.362  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                5    Train         0s  14%    approx_kl         0.019  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.164  â”‚
â”‚  Remainiâ€¦        1m 35s      Learn       0s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.075  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.290    episode_length               30.111  â”‚
â”‚  x_position                   -3.836    x_velocity                  -30.229  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-32.01 (best=-1.21@131072)
æ­¥æ•° 163,840: Reward=-32.01, Best=-0.29@163840, Sharpness=2.4339, Î»_max=-11.5476
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         6s  78%    value_loss        0.929  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          23.394  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                6    Train         1s  14%    approx_kl         0.016  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.151  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       0s  10%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.122  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                2.114    episode_length               34.664  â”‚
â”‚  x_position                   -4.483    x_velocity                  -32.353  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-26.49 (best=-0.29@163840)
æ­¥æ•° 196,608: Reward=-26.49, Best=2.11@196608, Sharpness=2.9913, Î»_max=8.3888
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.845  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          23.413  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                7    Train         1s  12%    approx_kl         0.013  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.130  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.102  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                2.050    episode_length               36.575  â”‚
â”‚  x_position                   -5.020    x_velocity                  -34.317  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-17.89 (best=2.11@196608)
æ­¥æ•° 229,376: Reward=-17.89, Best=2.11@196608, Sharpness=3.8833, Î»_max=-5.2110
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.7%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.837  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          23.429  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                8    Train         1s  12%    approx_kl         0.012  â”‚
â”‚  Uptime          1m 11s      Forwaâ€¦      0s   2%    clipfrac          0.118  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.155  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                3.929    episode_length               39.942  â”‚
â”‚  x_position                   -5.670    x_velocity                  -35.786  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-8.62 (best=2.11@196608)
æ­¥æ•° 262,144: Reward=-8.62, Best=3.93@262144, Sharpness=2.6115, Î»_max=-13.9055
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.1%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.882  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          23.446  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                9    Train         1s  12%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.089  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.166  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                6.478    episode_length               44.446  â”‚
â”‚  x_position                   -6.374    x_velocity                  -37.715  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=57.45 (best=3.93@262144)
æ­¥æ•° 294,912: Reward=57.45, Best=6.48@294912, Sharpness=2.5710, Î»_max=-20.8544
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.3%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         6s  79%    value_loss        0.843  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          23.458  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               10    Train         1s  12%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.078  â”‚
â”‚  Remainiâ€¦           51s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.188  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                6.459    episode_length               45.682  â”‚
â”‚  x_position                   -6.632    x_velocity                  -38.962  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-3.15 (best=6.48@294912)
æ­¥æ•° 327,680: Reward=-3.15, Best=6.48@294912, Sharpness=3.7551, Î»_max=-17.5138
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.9%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         9s  79%    value_loss        0.784  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          23.463  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         1s  12%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.053  â”‚
â”‚  Remainiâ€¦           41s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.137  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.474    episode_length               49.853  â”‚
â”‚  x_position                   -7.588    x_velocity                  -41.095  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-20.20 (best=6.48@294912)
æ­¥æ•° 360,448: Reward=-20.20, Best=8.47@360448, Sharpness=2.4619, Î»_max=-11.0243
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.803  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          23.470  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  17%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.036  â”‚
â”‚  Remainiâ€¦           30s      Learn       1s  16%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.155  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                6.498    episode_length               49.601  â”‚
â”‚  x_position                   -7.830    x_velocity                  -42.820  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-42.04 (best=8.47@360448)
æ­¥æ•° 393,216: Reward=-42.04, Best=8.47@360448, Sharpness=2.8492, Î»_max=10.7984
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.016  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.813  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          23.474  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               13    Train         1s  17%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.017  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s  16%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.110  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.858    episode_length               52.677  â”‚
â”‚  x_position                   -8.268    x_velocity                  -43.518  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-19.22 (best=8.47@360448)
æ­¥æ•° 425,984: Reward=-19.22, Best=8.86@425984, Sharpness=3.6710, Î»_max=-14.3648
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.014  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.797  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          23.477  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  17%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.003  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s  16%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.116  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.909    episode_length               53.167  â”‚
â”‚  x_position                   -8.475    x_velocity                  -43.954  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=321.59 (best=8.86@425984)
æ­¥æ•° 458,752: Reward=321.59, Best=8.91@458752, Sharpness=3.2129, Î»_max=-9.0801
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.5%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.021  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.834  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          23.478  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  16%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.040  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                8.827    episode_length               51.927  â”‚
â”‚  x_position                   -8.100    x_velocity                  -42.805  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-36.54 (best=8.91@458752)
æ­¥æ•° 491,520: Reward=-36.54, Best=8.91@458752, Sharpness=2.0568, Î»_max=10.4436
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.2%  DRAM: 0.4%   VRAM: 1.7%  â”‚
â”‚                                 12.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.017  â”‚
â”‚  Params          135.3K      Env        12s  73%    value_loss        0.828  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          23.478  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 31s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  16%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.023  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                9.291    episode_length               55.126  â”‚
â”‚  x_position                   -9.427    x_velocity                  -45.520  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-71.81 (best=8.91@458752)
æ­¥æ•° 524,288: Reward=-71.81, Best=9.29@524288, Sharpness=3.0673, Î»_max=10.5688

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 10_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 10 step sweep å®Œæˆã€‚
