==========================================
[Jump & Retrain] Walker2d task 13 | step_sizes=0 5 15 45 135
æ—¶é—´: Thu Dec 11 11:07:51 EST 2025
èŠ‚ç‚¹: node12
==========================================
[Base] task=13, env=Walker2d-v4, best_model=final_model.pt, best_reward=1687.48, train_seed=200
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_13/vec_stats.npz
[J&R] base_task=13, new_task=13_jr0_s0.00, step_size=0.0, extra_steps=500000, rng_seed=12345
[J&R] ä» models/controlled_task_13/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡             CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 1.3%  DRAM: 0.3%   VRAM: 1.1%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.197  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.086  â”‚
â”‚  SPS               4.1K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         1s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              7s      Forwaâ€¦      0s   0%    clipfrac          0.262  â”‚
â”‚  Remainiâ€¦        1m 52s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.211  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               16.781    episode_length               56.400  â”‚
â”‚  x_position                   -3.460    x_velocity                  -39.321  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=156.35 (best=N/A)
æ­¥æ•° 32,768: Reward=156.35, Best=16.78@32768, Sharpness=1.2417, Î»_max=-24.7521
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 2.5%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  67%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         2s  57%    value_loss        0.612  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          12.123  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                2    Train         1s  32%    approx_kl         0.018  â”‚
â”‚  Uptime             18s      Forwaâ€¦      0s   5%    clipfrac          0.200  â”‚
â”‚  Remainiâ€¦        2m 15s      Learn       0s  16%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.826  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               36.091    episode_length               91.827  â”‚
â”‚  x_position                   -8.565    x_velocity                  -55.245  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=488.64 (best=16.78@32768)
æ­¥æ•° 65,536: Reward=488.64, Best=36.09@65536, Sharpness=1.2604, Î»_max=-23.5671
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  67%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         2s  57%    value_loss        0.333  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          12.151  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.015  â”‚
â”‚  Epoch                3    Train         1s  32%    approx_kl         0.013  â”‚
â”‚  Uptime             28s      Forwaâ€¦      0s   5%    clipfrac          0.159  â”‚
â”‚  Remainiâ€¦        2m 11s      Learn       0s  16%    importance        0.998  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.896  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               88.157    episode_length              150.859  â”‚
â”‚  x_position                  -13.795    x_velocity                  -61.894  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=110.76 (best=36.09@65536)
æ­¥æ•° 98,304: Reward=110.76, Best=88.16@98304, Sharpness=1.2397, Î»_max=-24.2577
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  67%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         2s  57%    value_loss        0.274  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          12.175  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         1s  32%    approx_kl         0.013  â”‚
â”‚  Uptime             38s      Forwaâ€¦      0s   5%    clipfrac          0.152  â”‚
â”‚  Remainiâ€¦        1m 50s      Learn       0s  16%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.925  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               88.087    episode_length              162.840  â”‚
â”‚  x_position                  -17.144    x_velocity                  -73.885  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=149.20 (best=88.16@98304)
æ­¥æ•° 131,072: Reward=149.20, Best=88.16@98304, Sharpness=1.2672, Î»_max=-24.3414
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  67%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         2s  57%    value_loss        0.228  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          12.201  â”‚
â”‚  SPS               3.8K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                5    Train         1s  32%    approx_kl         0.009  â”‚
â”‚  Uptime             47s      Forwaâ€¦      0s   5%    clipfrac          0.113  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       0s  16%    importance        0.999  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               93.017    episode_length              179.833  â”‚
â”‚  x_position                  -19.531    x_velocity                  -85.858  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=96.66 (best=88.16@98304)
æ­¥æ•° 163,840: Reward=96.66, Best=93.02@163840, Sharpness=1.2889, Î»_max=-25.2637
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 15.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  67%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   8%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         6s  57%    value_loss        0.186  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          12.221  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         2s  32%    approx_kl         0.009  â”‚
â”‚  Uptime             57s      Forwaâ€¦      0s   5%    clipfrac          0.111  â”‚
â”‚  Remainiâ€¦        1m 30s      Learn       1s  16%    importance        1.000  â”‚
â”‚                              Copy        0s   3%    explained_varâ€¦    0.928  â”‚
â”‚                              Misc        0s   5%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              132.721    episode_length              216.953  â”‚
â”‚  x_position                  -15.783    x_velocity                  -83.072  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=81.78 (best=93.02@163840)
æ­¥æ•° 196,608: Reward=81.78, Best=132.72@196608, Sharpness=1.2684, Î»_max=-25.4041
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.148  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.242  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         2s  13%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 7s      Forwaâ€¦      0s   2%    clipfrac          0.096  â”‚
â”‚  Remainiâ€¦        1m 22s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.928  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              144.298    episode_length              234.848  â”‚
â”‚  x_position                  -18.764    x_velocity                  -89.296  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=73.23 (best=132.72@196608)
æ­¥æ•° 229,376: Reward=73.23, Best=144.30@229376, Sharpness=1.3092, Î»_max=-26.4419
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.7%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.141  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.268  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                8    Train         2s  13%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 17s      Forwaâ€¦      0s   2%    clipfrac          0.088  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              143.831    episode_length              234.655  â”‚
â”‚  x_position                  -16.135    x_velocity                  -89.573  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=61.26 (best=144.30@229376)
æ­¥æ•° 262,144: Reward=61.26, Best=144.30@229376, Sharpness=1.2874, Î»_max=-27.0130
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 5.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.021  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.124  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.288  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch                9    Train         2s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 26s      Forwaâ€¦      0s   2%    clipfrac          0.060  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.925  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              150.786    episode_length              246.360  â”‚
â”‚  x_position                  -18.389    x_velocity                  -94.261  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=71.97 (best=144.30@229376)
æ­¥æ•° 294,912: Reward=71.97, Best=150.79@294912, Sharpness=1.3234, Î»_max=-19.1081
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.7%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.119  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.299  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               10    Train         2s  13%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 36s      Forwaâ€¦      0s   2%    clipfrac          0.050  â”‚
â”‚  Remainiâ€¦           52s      Learn       1s   7%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.926  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              180.508    episode_length              271.165  â”‚
â”‚  x_position                  -11.752    x_velocity                  -89.214  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=68.99 (best=150.79@294912)
æ­¥æ•° 327,680: Reward=68.99, Best=180.51@327680, Sharpness=1.2910, Î»_max=-26.3448
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         8s  77%    value_loss        0.109  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.308  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         2s  13%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 46s      Forwaâ€¦      0s   2%    clipfrac          0.042  â”‚
â”‚  Remainiâ€¦           43s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              170.924    episode_length              272.097  â”‚
â”‚  x_position                  -24.737    x_velocity                  -99.720  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=66.67 (best=180.51@327680)
æ­¥æ•° 360,448: Reward=66.67, Best=180.51@327680, Sharpness=1.2884, Î»_max=-26.1916
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         8s  73%    value_loss        0.110  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          12.315  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               12    Train         2s  17%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 57s      Forwaâ€¦      0s   2%    clipfrac          0.022  â”‚
â”‚  Remainiâ€¦           33s      Learn       1s  14%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.917  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              190.493    episode_length              288.218  â”‚
â”‚  x_position                  -18.725    x_velocity                  -96.189  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=97.22 (best=180.51@327680)
æ­¥æ•° 393,216: Reward=97.22, Best=190.49@393216, Sharpness=1.2510, Î»_max=-23.2485
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         8s  73%    value_loss        0.108  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          12.322  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         2s  17%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 6s      Forwaâ€¦      0s   2%    clipfrac          0.018  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              162.723    episode_length              255.469  â”‚
â”‚  x_position                  -12.983    x_velocity                  -91.380  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=122.66 (best=190.49@393216)
æ­¥æ•° 425,984: Reward=122.66, Best=190.49@393216, Sharpness=1.2996, Î»_max=-24.2568
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.5%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         8s  73%    value_loss        0.112  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          12.325  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         2s  17%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 17s      Forwaâ€¦      0s   2%    clipfrac          0.002  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.922  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              153.994    episode_length              261.772  â”‚
â”‚  x_position                  -33.038    x_velocity                 -106.383  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=171.42 (best=190.49@393216)
æ­¥æ•° 458,752: Reward=171.42, Best=190.49@393216, Sharpness=1.2896, Î»_max=-21.7818
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.7%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.023  â”‚
â”‚  Params          135.3K      Env         8s  73%    value_loss        0.111  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          12.326  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         2s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 27s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              184.009    episode_length              291.788  â”‚
â”‚  x_position                  -35.258    x_velocity                 -106.221  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=94.19 (best=190.49@393216)
æ­¥æ•° 491,520: Reward=94.19, Best=190.49@393216, Sharpness=1.2912, Î»_max=-23.6861
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  82%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      1s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env        12s  73%    value_loss        0.113  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          12.327  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         3s  17%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 37s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  14%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.908  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              169.934    episode_length              270.320  â”‚
â”‚  x_position                  -20.935    x_velocity                  -98.940  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=92.22 (best=190.49@393216)
æ­¥æ•° 524,288: Reward=92.22, Best=190.49@393216, Sharpness=1.2845, Î»_max=-25.4114

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 13_jr0_s0.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_13/vec_stats.npz
[J&R] base_task=13, new_task=13_jr1_s5.00, step_size=5.0, extra_steps=500000, rng_seed=12346
[J&R] ä» models/controlled_task_13/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡          CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 0.8%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 22.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.002  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.154  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          12.007  â”‚
â”‚  SPS               7.3K      Misc        0s   0%    old_approx_kl     0.031  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.265  â”‚
â”‚  Remainiâ€¦         1m 3s      Learn       0s   0%    importance        0.994  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.172  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               29.852    episode_length               54.714  â”‚
â”‚  x_position                   -0.915    x_velocity                  -24.568  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=58.30 (best=N/A)
æ­¥æ•° 32,768: Reward=58.30, Best=29.85@32768, Sharpness=1.2523, Î»_max=-27.4151
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.8%  DRAM: 0.3%   VRAM: 1.5%  â”‚
â”‚                                 17.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.574  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          12.046  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.018  â”‚
â”‚  Epoch                2    Train         0s  13%    approx_kl         0.019  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.201  â”‚
â”‚  Remainiâ€¦        2m 13s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.802  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               43.794    episode_length               95.498  â”‚
â”‚  x_position                   -7.345    x_velocity                  -51.193  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=394.73 (best=29.85@32768)
æ­¥æ•° 65,536: Reward=394.73, Best=43.79@65536, Sharpness=1.2473, Î»_max=-23.7174
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.027  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.303  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          12.069  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                3    Train         0s  13%    approx_kl         0.012  â”‚
â”‚  Uptime             25s      Forwaâ€¦      0s   2%    clipfrac          0.143  â”‚
â”‚  Remainiâ€¦         2m 8s      Learn       0s  10%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.885  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               87.795    episode_length              145.778  â”‚
â”‚  x_position                  -10.046    x_velocity                  -57.198  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=466.50 (best=43.79@65536)
æ­¥æ•° 98,304: Reward=466.50, Best=87.80@98304, Sharpness=1.2966, Î»_max=-22.3039
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.038  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.254  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          12.095  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                4    Train         0s  13%    approx_kl         0.013  â”‚
â”‚  Uptime             35s      Forwaâ€¦      0s   2%    clipfrac          0.154  â”‚
â”‚  Remainiâ€¦         2m 1s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.922  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               84.999    episode_length              165.545  â”‚
â”‚  x_position                  -18.193    x_velocity                  -79.663  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=167.17 (best=87.80@98304)
æ­¥æ•° 131,072: Reward=167.17, Best=87.80@98304, Sharpness=1.3418, Î»_max=-28.2590
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 12.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         3s  77%    value_loss        0.227  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          12.117  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.012  â”‚
â”‚  Epoch                5    Train         0s  13%    approx_kl         0.011  â”‚
â”‚  Uptime             45s      Forwaâ€¦      0s   2%    clipfrac          0.132  â”‚
â”‚  Remainiâ€¦        1m 41s      Learn       0s  10%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.919  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               89.727    episode_length              178.576  â”‚
â”‚  x_position                  -20.403    x_velocity                  -87.895  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=196.68 (best=87.80@98304)
æ­¥æ•° 163,840: Reward=196.68, Best=89.73@163840, Sharpness=1.2666, Î»_max=-28.4654
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.192  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          12.133  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                6    Train         1s  13%    approx_kl         0.010  â”‚
â”‚  Uptime             55s      Forwaâ€¦      0s   2%    clipfrac          0.113  â”‚
â”‚  Remainiâ€¦        1m 31s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.923  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              131.528    episode_length              216.961  â”‚
â”‚  x_position                  -14.874    x_velocity                  -84.275  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=156.60 (best=89.73@163840)
æ­¥æ•° 196,608: Reward=156.60, Best=131.53@196608, Sharpness=1.2705, Î»_max=-23.0303
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         6s  75%    value_loss        0.151  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          12.152  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         1s  16%    approx_kl         0.008  â”‚
â”‚  Uptime           1m 5s      Forwaâ€¦      0s   2%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦        1m 22s      Learn       0s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.932  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              146.802    episode_length              233.504  â”‚
â”‚  x_position                  -19.055    x_velocity                  -85.451  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=129.00 (best=131.53@196608)
æ­¥æ•° 229,376: Reward=129.00, Best=146.80@229376, Sharpness=1.2932, Î»_max=-23.8689
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.1%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.024  â”‚
â”‚  Params          135.3K      Env         6s  75%    value_loss        0.144  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          12.171  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s  16%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 15s      Forwaâ€¦      0s   2%    clipfrac          0.076  â”‚
â”‚  Remainiâ€¦         1m 9s      Learn       0s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.928  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              144.289    episode_length              230.582  â”‚
â”‚  x_position                  -15.990    x_velocity                  -85.057  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=128.84 (best=146.80@229376)
æ­¥æ•° 262,144: Reward=128.84, Best=146.80@229376, Sharpness=1.2783, Î»_max=-29.0958
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         6s  75%    value_loss        0.126  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          12.187  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch                9    Train         1s  16%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 25s      Forwaâ€¦      0s   2%    clipfrac          0.073  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.929  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              152.917    episode_length              244.085  â”‚
â”‚  x_position                  -17.405    x_velocity                  -89.861  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=130.73 (best=146.80@229376)
æ­¥æ•° 294,912: Reward=130.73, Best=152.92@294912, Sharpness=1.2818, Î»_max=-29.1670
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.016  â”‚
â”‚  Params          135.3K      Env         6s  75%    value_loss        0.122  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          12.201  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  16%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 35s      Forwaâ€¦      0s   2%    clipfrac          0.053  â”‚
â”‚  Remainiâ€¦           53s      Learn       0s  13%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.930  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              145.774    episode_length              239.090  â”‚
â”‚  x_position                  -15.177    x_velocity                  -92.035  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=143.18 (best=152.92@294912)
æ­¥æ•° 327,680: Reward=143.18, Best=152.92@294912, Sharpness=1.2781, Î»_max=-27.6344
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  83%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         9s  75%    value_loss        0.106  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          12.210  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  16%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 45s      Forwaâ€¦      0s   2%    clipfrac          0.048  â”‚
â”‚  Remainiâ€¦           42s      Learn       1s  13%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.934  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              152.142    episode_length              249.055  â”‚
â”‚  x_position                  -20.700    x_velocity                  -95.579  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=121.51 (best=152.92@294912)
æ­¥æ•° 360,448: Reward=121.51, Best=152.92@294912, Sharpness=1.2719, Î»_max=-30.6028
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.025  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.112  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          12.216  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  15%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 54s      Forwaâ€¦      0s   2%    clipfrac          0.038  â”‚
â”‚  Remainiâ€¦           31s      Learn       1s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.932  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              153.770    episode_length              251.852  â”‚
â”‚  x_position                  -21.987    x_velocity                  -96.736  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=134.22 (best=152.92@294912)
æ­¥æ•° 393,216: Reward=134.22, Best=153.77@393216, Sharpness=1.3380, Î»_max=-22.8018
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.113  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          12.222  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               13    Train         1s  15%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 4s      Forwaâ€¦      0s   2%    clipfrac          0.028  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.927  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              162.390    episode_length              256.594  â”‚
â”‚  x_position                  -16.685    x_velocity                  -92.830  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=62.82 (best=153.77@393216)
æ­¥æ•° 425,984: Reward=62.82, Best=162.39@425984, Sharpness=1.2891, Î»_max=-25.5056
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.108  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          12.226  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  15%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 14s      Forwaâ€¦      0s   2%    clipfrac          0.009  â”‚
â”‚  Remainiâ€¦           12s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.924  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              177.371    episode_length              269.750  â”‚
â”‚  x_position                  -14.908    x_velocity                  -90.932  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=77.27 (best=162.39@425984)
æ­¥æ•° 458,752: Reward=77.27, Best=177.37@458752, Sharpness=1.3659, Î»_max=-25.3679
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.110  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          12.227  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 25s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.921  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              193.973    episode_length              279.000  â”‚
â”‚  x_position                   -9.649    x_velocity                  -83.533  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=65.56 (best=177.37@458752)
æ­¥æ•° 491,520: Reward=65.56, Best=193.97@491520, Sharpness=1.2918, Î»_max=-30.0954
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.032  â”‚
â”‚  Params          135.3K      Env        12s  78%    value_loss        0.132  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          12.228  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  15%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 35s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.905  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              185.033    episode_length              287.038  â”‚
â”‚  x_position                  -29.915    x_velocity                 -100.466  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=64.13 (best=193.97@491520)
æ­¥æ•° 524,288: Reward=64.13, Best=193.97@491520, Sharpness=1.2611, Î»_max=-27.7101

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 13_jr1_s5.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_13/vec_stats.npz
[J&R] base_task=13, new_task=13_jr2_s15.00, step_size=15.0, extra_steps=500000, rng_seed=12347
[J&R] ä» models/controlled_task_13/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡       CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        1.085  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          11.759  â”‚
â”‚  SPS               8.3K      Misc        0s   0%    old_approx_kl     0.030  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.025  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.266  â”‚
â”‚  Remainiâ€¦           56s      Learn       0s   0%    importance        0.995  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.386  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return                4.656    episode_length               54.706  â”‚
â”‚  x_position                   -4.741    x_velocity                  -49.760  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=32.32 (best=N/A)
æ­¥æ•° 32,768: Reward=32.32, Best=4.66@32768, Sharpness=1.2513, Î»_max=-30.3281
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        0.699  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          11.784  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.023  â”‚
â”‚  Epoch                2    Train         0s  11%    approx_kl         0.022  â”‚
â”‚  Uptime             13s      Forwaâ€¦      0s   2%    clipfrac          0.215  â”‚
â”‚  Remainiâ€¦        2m 11s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.854  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               22.994    episode_length               85.660  â”‚
â”‚  x_position                  -10.883    x_velocity                  -62.208  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-9.82 (best=4.66@32768)
æ­¥æ•° 65,536: Reward=-9.82, Best=22.99@65536, Sharpness=1.2450, Î»_max=-27.4712
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.031  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        0.380  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          11.802  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.019  â”‚
â”‚  Epoch                3    Train         0s  11%    approx_kl         0.017  â”‚
â”‚  Uptime             24s      Forwaâ€¦      0s   2%    clipfrac          0.184  â”‚
â”‚  Remainiâ€¦         2m 9s      Learn       0s   5%    importance        0.997  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.915  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               58.664    episode_length              129.959  â”‚
â”‚  x_position                  -15.134    x_velocity                  -70.597  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-23.33 (best=22.99@65536)
æ­¥æ•° 98,304: Reward=-23.33, Best=58.66@98304, Sharpness=1.2756, Î»_max=-28.5597
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        0.338  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          11.829  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.014  â”‚
â”‚  Epoch                4    Train         0s  11%    approx_kl         0.014  â”‚
â”‚  Uptime             34s      Forwaâ€¦      0s   2%    clipfrac          0.166  â”‚
â”‚  Remainiâ€¦        1m 57s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.932  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               60.726    episode_length              147.414  â”‚
â”‚  x_position                  -20.969    x_velocity                  -85.897  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-2.14 (best=58.66@98304)
æ­¥æ•° 131,072: Reward=-2.14, Best=60.73@131072, Sharpness=1.2705, Î»_max=-28.5488
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 2.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.017  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        0.261  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          11.858  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                5    Train         0s  11%    approx_kl         0.011  â”‚
â”‚  Uptime             45s      Forwaâ€¦      0s   2%    clipfrac          0.132  â”‚
â”‚  Remainiâ€¦        1m 42s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.938  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               90.713    episode_length              188.270  â”‚
â”‚  x_position                  -24.893    x_velocity                  -96.545  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-6.92 (best=60.73@131072)
æ­¥æ•° 163,840: Reward=-6.92, Best=90.71@163840, Sharpness=1.2640, Î»_max=-25.8061
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.018  â”‚
â”‚  Params          135.3K      Env         6s  81%    value_loss        0.208  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          11.879  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                6    Train         1s  11%    approx_kl         0.010  â”‚
â”‚  Uptime             54s      Forwaâ€¦      0s   2%    clipfrac          0.118  â”‚
â”‚  Remainiâ€¦        1m 29s      Learn       0s   5%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.936  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              128.141    episode_length              227.966  â”‚
â”‚  x_position                  -24.402    x_velocity                  -98.600  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=937.94 (best=90.71@163840)
æ­¥æ•° 196,608: Reward=937.94, Best=128.14@196608, Sharpness=1.2578, Î»_max=-25.1298
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.006  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.166  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.895  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                7    Train         1s  15%    approx_kl         0.009  â”‚
â”‚  Uptime           1m 6s      Forwaâ€¦      0s   2%    clipfrac          0.109  â”‚
â”‚  Remainiâ€¦        1m 33s      Learn       0s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.937  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              144.573    episode_length              236.585  â”‚
â”‚  x_position                  -17.845    x_velocity                  -90.739  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=920.39 (best=128.14@196608)
æ­¥æ•° 229,376: Reward=920.39, Best=144.57@229376, Sharpness=1.2377, Î»_max=-28.8005
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.140  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.914  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.007  â”‚
â”‚  Epoch                8    Train         1s  15%    approx_kl         0.007  â”‚
â”‚  Uptime          1m 17s      Forwaâ€¦      0s   2%    clipfrac          0.076  â”‚
â”‚  Remainiâ€¦        1m 24s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.939  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              130.317    episode_length              237.649  â”‚
â”‚  x_position                  -24.747    x_velocity                 -106.060  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=950.61 (best=144.57@229376)
æ­¥æ•° 262,144: Reward=950.61, Best=144.57@229376, Sharpness=1.2679, Î»_max=-23.5260
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.132  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.926  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch                9    Train         1s  15%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 28s      Forwaâ€¦      0s   2%    clipfrac          0.075  â”‚
â”‚  Remainiâ€¦         1m 8s      Learn       0s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.940  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              132.348    episode_length              233.738  â”‚
â”‚  x_position                  -21.459    x_velocity                 -100.137  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=863.49 (best=144.57@229376)
æ­¥æ•° 294,912: Reward=863.49, Best=144.57@229376, Sharpness=1.2783, Î»_max=-26.7454
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         6s  76%    value_loss        0.109  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.934  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.005  â”‚
â”‚  Epoch               10    Train         1s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 39s      Forwaâ€¦      0s   2%    clipfrac          0.061  â”‚
â”‚  Remainiâ€¦           57s      Learn       0s  10%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.937  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              159.162    episode_length              261.447  â”‚
â”‚  x_position                  -24.600    x_velocity                 -100.879  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=906.66 (best=144.57@229376)
æ­¥æ•° 327,680: Reward=906.66, Best=159.16@327680, Sharpness=1.3705, Î»_max=-23.6347
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  84%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         9s  76%    value_loss        0.106  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.942  â”‚
â”‚  SPS               3.0K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  15%    approx_kl         0.005  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.053  â”‚
â”‚  Remainiâ€¦           47s      Learn       1s  10%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.929  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              163.429    episode_length              266.692  â”‚
â”‚  x_position                  -23.945    x_velocity                 -101.830  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=925.64 (best=159.16@327680)
æ­¥æ•° 360,448: Reward=925.64, Best=163.43@360448, Sharpness=1.2441, Î»_max=-27.2490
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.014  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.103  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.948  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               12    Train         1s  14%    approx_kl         0.003  â”‚
â”‚  Uptime           2m 2s      Forwaâ€¦      0s   2%    clipfrac          0.023  â”‚
â”‚  Remainiâ€¦           38s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.930  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              163.042    episode_length              265.505  â”‚
â”‚  x_position                  -27.894    x_velocity                 -101.032  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=15.96 (best=163.43@360448)
æ­¥æ•° 393,216: Reward=15.96, Best=163.43@360448, Sharpness=1.2747, Î»_max=-26.8349
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.026  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.105  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.953  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  14%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 12s      Forwaâ€¦      0s   2%    clipfrac          0.016  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.930  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              175.847    episode_length              280.260  â”‚
â”‚  x_position                  -37.924    x_velocity                 -102.900  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=23.58 (best=163.43@360448)
æ­¥æ•° 425,984: Reward=23.58, Best=175.85@425984, Sharpness=1.3213, Î»_max=-26.1077
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.100  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.957  â”‚
â”‚  SPS               3.1K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               14    Train         1s  14%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 22s      Forwaâ€¦      0s   2%    clipfrac          0.008  â”‚
â”‚  Remainiâ€¦           13s      Learn       1s  11%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.931  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              206.776    episode_length              322.233  â”‚
â”‚  x_position                  -45.061    x_velocity                 -113.716  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=828.29 (best=175.85@425984)
æ­¥æ•° 458,752: Reward=828.29, Best=206.78@458752, Sharpness=1.2688, Î»_max=-24.0519
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.033  â”‚
â”‚  Params          135.3K      Env         9s  78%    value_loss        0.127  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.958  â”‚
â”‚  SPS               2.9K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 33s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.911  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              182.319    episode_length              294.837  â”‚
â”‚  x_position                  -31.993    x_velocity                 -110.926  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=958.29 (best=206.78@458752)
æ­¥æ•° 491,520: Reward=958.29, Best=206.78@458752, Sharpness=1.2499, Î»_max=-29.8443
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  85%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        12s  78%    value_loss        0.121  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.958  â”‚
â”‚  SPS               2.8K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               16    Train         2s  14%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 45s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s  11%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.902  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              214.974    episode_length              328.000  â”‚
â”‚  x_position                  -51.096    x_velocity                 -111.253  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=913.14 (best=206.78@458752)
æ­¥æ•° 524,288: Reward=913.14, Best=214.97@524288, Sharpness=1.3555, Î»_max=-22.2103

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 13_jr2_s15.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_13/vec_stats.npz
[J&R] base_task=13, new_task=13_jr3_s45.00, step_size=45.0, extra_steps=500000, rng_seed=12348
[J&R] ä» models/controlled_task_13/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡    CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 0.6%  DRAM: 0.3%   VRAM: 1.3%  â”‚
â”‚                                 20.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss       0.003  â”‚
â”‚  Params          135.3K      Env         2s   0%    value_loss        1.608  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          10.990  â”‚
â”‚  SPS               8.3K      Misc        0s   0%    old_approx_kl     0.052  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.048  â”‚
â”‚  Uptime              3s      Forwaâ€¦      0s   0%    clipfrac          0.390  â”‚
â”‚  Remainiâ€¦           56s      Learn       0s   0%    importance        0.996  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.634  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -10.332    episode_length               50.720  â”‚
â”‚  x_position                   -8.789    x_velocity                  -60.790  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-15.03 (best=N/A)
æ­¥æ•° 32,768: Reward=-15.03, Best=-10.33@32768, Sharpness=1.9266, Î»_max=-59.6575
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 2.9%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 15.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss       0.008  â”‚
â”‚  Params          135.3K      Env         2s  77%    value_loss        0.796  â”‚
â”‚  Steps            65.5K      Copy        0s   2%    entropy          11.028  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.043  â”‚
â”‚  Epoch                2    Train         0s  13%    approx_kl         0.041  â”‚
â”‚  Uptime             13s      Forwaâ€¦      0s   2%    clipfrac          0.326  â”‚
â”‚  Remainiâ€¦         2m 9s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.524  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.657    episode_length               61.041  â”‚
â”‚  x_position                  -15.235    x_velocity                  -73.381  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-33.70 (best=-10.33@32768)
æ­¥æ•° 65,536: Reward=-33.70, Best=-10.33@32768, Sharpness=1.9041, Î»_max=-57.7104
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.003  â”‚
â”‚  Params          135.3K      Env         2s  77%    value_loss        0.474  â”‚
â”‚  Steps            98.3K      Copy        0s   2%    entropy          11.045  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.025  â”‚
â”‚  Epoch                3    Train         0s  13%    approx_kl         0.024  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.246  â”‚
â”‚  Remainiâ€¦        1m 58s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.292  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -13.382    episode_length               64.788  â”‚
â”‚  x_position                  -18.216    x_velocity                  -77.833  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-24.61 (best=-10.33@32768)
æ­¥æ•° 98,304: Reward=-24.61, Best=-10.33@32768, Sharpness=1.9259, Î»_max=-43.9604
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.004  â”‚
â”‚  Params          135.3K      Env         2s  77%    value_loss        0.267  â”‚
â”‚  Steps           131.1K      Copy        0s   2%    entropy          11.068  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                4    Train         0s  13%    approx_kl         0.022  â”‚
â”‚  Uptime             33s      Forwaâ€¦      0s   2%    clipfrac          0.225  â”‚
â”‚  Remainiâ€¦        1m 54s      Learn       0s   8%    importance        0.999  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.101  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.992    episode_length               64.299  â”‚
â”‚  x_position                  -18.529    x_velocity                  -76.955  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=-22.19 (best=-10.33@32768)
æ­¥æ•° 131,072: Reward=-22.19, Best=-10.33@32768, Sharpness=2.9926, Î»_max=27.3844
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         2s  77%    value_loss        0.185  â”‚
â”‚  Steps           163.8K      Copy        0s   2%    entropy          11.085  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.016  â”‚
â”‚  Epoch                5    Train         0s  13%    approx_kl         0.017  â”‚
â”‚  Uptime             43s      Forwaâ€¦      0s   2%    clipfrac          0.190  â”‚
â”‚  Remainiâ€¦        1m 39s      Learn       0s   8%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.337  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -14.389    episode_length               62.943  â”‚
â”‚  x_position                  -18.639    x_velocity                  -77.001  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-10.94 (best=-10.33@32768)
æ­¥æ•° 163,840: Reward=-10.94, Best=-10.33@32768, Sharpness=3.2242, Î»_max=10.1430
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  86%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   6%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  77%    value_loss        0.132  â”‚
â”‚  Steps           196.6K      Copy        0s   2%    entropy          11.110  â”‚
â”‚  SPS               3.2K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                6    Train         1s  13%    approx_kl         0.014  â”‚
â”‚  Uptime             53s      Forwaâ€¦      0s   2%    clipfrac          0.159  â”‚
â”‚  Remainiâ€¦        1m 34s      Learn       0s   8%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.517  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -13.282    episode_length               63.561  â”‚
â”‚  x_position                  -18.547    x_velocity                  -76.509  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=-10.94 (best=-10.33@32768)
æ­¥æ•° 196,608: Reward=-10.94, Best=-10.33@32768, Sharpness=2.7512, Î»_max=33.9257
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 12.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         6s  73%    value_loss        0.108  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          11.134  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         1s  18%    approx_kl         0.012  â”‚
â”‚  Uptime           1m 3s      Forwaâ€¦      0s   2%    clipfrac          0.140  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       0s  15%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.573  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -13.583    episode_length               63.213  â”‚
â”‚  x_position                  -18.558    x_velocity                  -76.464  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-14.45 (best=-10.33@32768)
æ­¥æ•° 229,376: Reward=-14.45, Best=-10.33@32768, Sharpness=2.5689, Î»_max=43.0552
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  73%    value_loss        0.096  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          11.151  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                8    Train         1s  18%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.114  â”‚
â”‚  Remainiâ€¦         1m 8s      Learn       0s  15%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.588  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -13.438    episode_length               63.790  â”‚
â”‚  x_position                  -18.795    x_velocity                  -76.893  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-11.71 (best=-10.33@32768)
æ­¥æ•° 262,144: Reward=-11.71, Best=-10.33@32768, Sharpness=2.7201, Î»_max=38.2266
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  73%    value_loss        0.088  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          11.163  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch                9    Train         1s  18%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 22s      Forwaâ€¦      0s   2%    clipfrac          0.107  â”‚
â”‚  Remainiâ€¦         1m 2s      Learn       0s  15%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.625  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.844    episode_length               63.980  â”‚
â”‚  x_position                  -18.828    x_velocity                  -76.489  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-12.02 (best=-10.33@32768)
æ­¥æ•° 294,912: Reward=-12.02, Best=-10.33@32768, Sharpness=2.9575, Î»_max=22.3501
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      6s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  73%    value_loss        0.083  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          11.173  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.008  â”‚
â”‚  Epoch               10    Train         1s  18%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 32s      Forwaâ€¦      0s   2%    clipfrac          0.099  â”‚
â”‚  Remainiâ€¦           52s      Learn       0s  15%    importance        1.000  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.643  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.601    episode_length               63.641  â”‚
â”‚  x_position                  -18.574    x_velocity                  -75.908  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-13.01 (best=-10.33@32768)
æ­¥æ•° 327,680: Reward=-13.01, Best=-10.33@32768, Sharpness=2.6421, Î»_max=42.6611
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.1%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  81%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.008  â”‚
â”‚  Params          135.3K      Env         9s  73%    value_loss        0.087  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          11.180  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               11    Train         1s  18%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 42s      Forwaâ€¦      0s   2%    clipfrac          0.074  â”‚
â”‚  Remainiâ€¦           39s      Learn       1s  15%    importance        1.001  â”‚
â”‚                              Copy        0s   1%    explained_varâ€¦    0.604  â”‚
â”‚                              Misc        0s   3%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.549    episode_length               63.972  â”‚
â”‚  x_position                  -18.684    x_velocity                  -76.186  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-13.65 (best=-10.33@32768)
æ­¥æ•° 360,448: Reward=-13.65, Best=-10.33@32768, Sharpness=2.6881, Î»_max=35.3860
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.012  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.085  â”‚
â”‚  Steps           393.2K      Copy        0s   2%    entropy          11.189  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               12    Train         1s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 51s      Forwaâ€¦      0s   2%    clipfrac          0.068  â”‚
â”‚  Remainiâ€¦           31s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.596  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.204    episode_length               64.491  â”‚
â”‚  x_position                  -18.909    x_velocity                  -76.358  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=-10.12 (best=-10.33@32768)
æ­¥æ•° 393,216: Reward=-10.12, Best=-10.33@32768, Sharpness=2.8046, Î»_max=41.1806
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.4%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.015  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.086  â”‚
â”‚  Steps           426.0K      Copy        0s   2%    entropy          11.197  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               13    Train         1s  11%    approx_kl         0.004  â”‚
â”‚  Uptime           2m 1s      Forwaâ€¦      0s   2%    clipfrac          0.043  â”‚
â”‚  Remainiâ€¦           21s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.573  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.163    episode_length               64.469  â”‚
â”‚  x_position                  -18.816    x_velocity                  -76.295  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-12.34 (best=-10.33@32768)
æ­¥æ•° 425,984: Reward=-12.34, Best=-10.33@32768, Sharpness=2.9213, Î»_max=42.6615
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 4.1%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.088  â”‚
â”‚  Steps           458.8K      Copy        0s   2%    entropy          11.201  â”‚
â”‚  SPS               3.6K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  11%    approx_kl         0.003  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.023  â”‚
â”‚  Remainiâ€¦           11s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.595  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.862    episode_length               64.957  â”‚
â”‚  x_position                  -19.002    x_velocity                  -76.479  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-10.61 (best=-10.33@32768)
æ­¥æ•° 458,752: Reward=-10.61, Best=-10.33@32768, Sharpness=2.7654, Î»_max=41.3073
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      9s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.013  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.097  â”‚
â”‚  Steps           491.5K      Copy        0s   2%    entropy          11.202  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.001  â”‚
â”‚  Epoch               15    Train         1s  11%    approx_kl         0.001  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   2%    clipfrac          0.004  â”‚
â”‚  Remainiâ€¦            2s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.535  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -12.009    episode_length               64.822  â”‚
â”‚  x_position                  -18.921    x_velocity                  -76.492  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-8.93 (best=-10.33@32768)
æ­¥æ•° 491,520: Reward=-8.93, Best=-10.33@32768, Sharpness=2.3518, Î»_max=30.8487
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 3.5%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.019  â”‚
â”‚  Params          135.3K      Env        12s  80%    value_loss        0.103  â”‚
â”‚  Steps           524.3K      Copy        0s   2%    entropy          11.202  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  11%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 30s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   7%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.503  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return              -11.875    episode_length               65.103  â”‚
â”‚  x_position                  -19.024    x_velocity                  -76.637  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=-15.05 (best=-10.33@32768)
æ­¥æ•° 524,288: Reward=-15.05, Best=-10.33@32768, Sharpness=2.7650, Î»_max=41.5434

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 13_jr3_s45.00 å®Œæˆã€‚
[J&R] å·²ç»§æ‰¿åŸå§‹æ¨¡å‹çš„å½’ä¸€åŒ–ç»Ÿè®¡: models/controlled_task_13/vec_stats.npz
[J&R] base_task=13, new_task=13_jr4_s135.00, step_size=135.0, extra_steps=500000, rng_seed=12349
[J&R] ä» models/controlled_task_13/final_model.pt çš„æœ€ä¼˜ç‚¹è·³å‡ºï¼Œå¼€å§‹ retrain ...
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡           CPU: 0.0%  GPU: 0.0%  DRAM: 0.0%   VRAM: 0.0%  â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      0s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%                             â”‚
â”‚  Params          135.3K      Env         0s   0%                             â”‚
â”‚  Steps                0      Copy        0s   0%                             â”‚
â”‚  SPS                  0      Misc        0s   0%                             â”‚
â”‚  Epoch                0    Train         0s   0%                             â”‚
â”‚  Uptime              0s      Forwaâ€¦      0s   0%                             â”‚
â”‚  Remainiâ€¦   A hair past      Learn       0s   0%                             â”‚
â”‚               a freckle      Copy        0s   0%                             â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: 500,000
ç‰¹å¾è®¡ç®—é—´éš”: 10,000 steps
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 3.2%  DRAM: 0.3%   VRAM: 1.4%  â”‚
â”‚                                 21.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s   0%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   0%    policy_loss      -0.001  â”‚
â”‚  Params          135.3K      Env         3s   0%    value_loss        2.751  â”‚
â”‚  Steps            32.8K      Copy        0s   0%    entropy          21.232  â”‚
â”‚  SPS               7.4K      Misc        0s   0%    old_approx_kl     0.048  â”‚
â”‚  Epoch                1    Train         0s   0%    approx_kl         0.046  â”‚
â”‚  Uptime              4s      Forwaâ€¦      0s   0%    clipfrac          0.316  â”‚
â”‚  Remainiâ€¦         1m 2s      Learn       0s   0%    importance        0.998  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.072  â”‚
â”‚                              Misc        0s   0%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.477    episode_length               15.712  â”‚
â”‚  x_position                   -1.181    x_velocity                  -20.100  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 32,768: episode_return=-14.68 (best=N/A)
æ­¥æ•° 32,768: Reward=-14.68, Best=-4.48@32768, Sharpness=2.7663, Î»_max=10.6403
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.2%  DRAM: 0.3%   VRAM: 1.6%  â”‚
â”‚                                 16.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        1.428  â”‚
â”‚  Steps            65.5K      Copy        0s   1%    entropy          21.272  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.022  â”‚
â”‚  Epoch                2    Train         0s  11%    approx_kl         0.023  â”‚
â”‚  Uptime             14s      Forwaâ€¦      0s   2%    clipfrac          0.209  â”‚
â”‚  Remainiâ€¦        2m 10s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.140  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.427    episode_length               19.818  â”‚
â”‚  x_position                   -1.869    x_velocity                  -25.134  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 65,536: episode_return=-12.85 (best=-4.48@32768)
æ­¥æ•° 65,536: Reward=-12.85, Best=-4.48@32768, Sharpness=3.1447, Î»_max=-12.1737
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.2%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        1.008  â”‚
â”‚  Steps            98.3K      Copy        0s   1%    entropy          21.306  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.021  â”‚
â”‚  Epoch                3    Train         0s  11%    approx_kl         0.020  â”‚
â”‚  Uptime             23s      Forwaâ€¦      0s   2%    clipfrac          0.191  â”‚
â”‚  Remainiâ€¦        1m 53s      Learn       0s   6%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.108  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -5.580    episode_length               21.668  â”‚
â”‚  x_position                   -2.236    x_velocity                  -27.127  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 98,304: episode_return=-8.67 (best=-4.48@32768)
æ­¥æ•° 98,304: Reward=-8.67, Best=-4.48@32768, Sharpness=2.5640, Î»_max=-13.3614
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 3.9%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.010  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        0.834  â”‚
â”‚  Steps           131.1K      Copy        0s   1%    entropy          21.332  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.017  â”‚
â”‚  Epoch                4    Train         0s  11%    approx_kl         0.016  â”‚
â”‚  Uptime             32s      Forwaâ€¦      0s   2%    clipfrac          0.163  â”‚
â”‚  Remainiâ€¦        1m 45s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦   -0.033  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.903    episode_length               23.340  â”‚
â”‚  x_position                   -2.527    x_velocity                  -28.111  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 131,072: episode_return=2.35 (best=-4.48@32768)
æ­¥æ•° 131,072: Reward=2.35, Best=-4.48@32768, Sharpness=2.6510, Î»_max=-13.0582
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 3.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.9%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      3s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.011  â”‚
â”‚  Params          135.3K      Env         3s  81%    value_loss        0.746  â”‚
â”‚  Steps           163.8K      Copy        0s   1%    entropy          21.362  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.013  â”‚
â”‚  Epoch                5    Train         0s  11%    approx_kl         0.014  â”‚
â”‚  Uptime             42s      Forwaâ€¦      0s   2%    clipfrac          0.144  â”‚
â”‚  Remainiâ€¦        1m 38s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.029  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -4.277    episode_length               24.641  â”‚
â”‚  x_position                   -2.743    x_velocity                  -28.780  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 163,840: episode_return=-4.52 (best=-4.48@32768)
æ­¥æ•° 163,840: Reward=-4.52, Best=-4.28@163840, Sharpness=2.7043, Î»_max=-16.9687
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  81%    value_loss        0.685  â”‚
â”‚  Steps           196.6K      Copy        0s   1%    entropy          21.389  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                6    Train         0s  11%    approx_kl         0.012  â”‚
â”‚  Uptime             52s      Forwaâ€¦      0s   2%    clipfrac          0.127  â”‚
â”‚  Remainiâ€¦        1m 31s      Learn       0s   6%    importance        1.001  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.069  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -3.329    episode_length               24.810  â”‚
â”‚  x_position                   -2.719    x_velocity                  -27.999  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 196,608: episode_return=266.50 (best=-4.28@163840)
æ­¥æ•° 196,608: Reward=266.50, Best=-3.33@196608, Sharpness=3.4953, Î»_max=-15.4840
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0      ğŸ¡          CPU:     GPU: 3.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.009  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.655  â”‚
â”‚  Steps           229.4K      Copy        0s   2%    entropy          21.410  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.011  â”‚
â”‚  Epoch                7    Train         0s  11%    approx_kl         0.011  â”‚
â”‚  Uptime           1m 2s      Forwaâ€¦      0s   2%    clipfrac          0.109  â”‚
â”‚  Remainiâ€¦        1m 20s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.079  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.962    episode_length               26.827  â”‚
â”‚  x_position                   -3.160    x_velocity                  -29.638  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 229,376: episode_return=-12.55 (best=-3.33@196608)
æ­¥æ•° 229,376: Reward=-12.55, Best=-2.96@229376, Sharpness=2.4674, Î»_max=-3.1505
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0     ğŸ¡           CPU:     GPU: 4.6%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.007  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.616  â”‚
â”‚  Steps           262.1K      Copy        0s   2%    entropy          21.430  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.010  â”‚
â”‚  Epoch                8    Train         0s  11%    approx_kl         0.009  â”‚
â”‚  Uptime          1m 12s      Forwaâ€¦      0s   2%    clipfrac          0.100  â”‚
â”‚  Remainiâ€¦        1m 12s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.109  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.638    episode_length               27.447  â”‚
â”‚  x_position                   -3.259    x_velocity                  -29.931  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 262,144: episode_return=-2.18 (best=-2.96@229376)
æ­¥æ•° 262,144: Reward=-2.18, Best=-2.64@262144, Sharpness=2.4770, Î»_max=1.1913
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0    ğŸ¡            CPU:     GPU: 5.2%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.3%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss      -0.005  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.595  â”‚
â”‚  Steps           294.9K      Copy        0s   2%    entropy          21.444  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.009  â”‚
â”‚  Epoch                9    Train         0s  11%    approx_kl         0.008  â”‚
â”‚  Uptime          1m 21s      Forwaâ€¦      0s   2%    clipfrac          0.081  â”‚
â”‚  Remainiâ€¦         1m 0s      Learn       0s   5%    importance        0.999  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.137  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -2.237    episode_length               28.589  â”‚
â”‚  x_position                   -3.468    x_velocity                  -30.665  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 294,912: episode_return=-8.32 (best=-2.64@262144)
æ­¥æ•° 294,912: Reward=-8.32, Best=-2.24@294912, Sharpness=2.2766, Î»_max=-11.9959
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0   ğŸ¡             CPU:     GPU: 4.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.5%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate      7s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         6s  80%    value_loss        0.592  â”‚
â”‚  Steps           327.7K      Copy        0s   2%    entropy          21.456  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.006  â”‚
â”‚  Epoch               10    Train         0s  11%    approx_kl         0.006  â”‚
â”‚  Uptime          1m 31s      Forwaâ€¦      0s   2%    clipfrac          0.065  â”‚
â”‚  Remainiâ€¦           51s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.162  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.790    episode_length               29.661  â”‚
â”‚  x_position                   -3.626    x_velocity                  -31.283  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 327,680: episode_return=-13.53 (best=-2.24@294912)
æ­¥æ•° 327,680: Reward=-13.53, Best=-1.79@327680, Sharpness=3.1931, Î»_max=-13.1943
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0  ğŸ¡              CPU:     GPU: 4.3%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  88%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   5%    policy_loss       0.001  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.589  â”‚
â”‚  Steps           360.4K      Copy        0s   2%    entropy          21.468  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.004  â”‚
â”‚  Epoch               11    Train         1s  11%    approx_kl         0.004  â”‚
â”‚  Uptime          1m 41s      Forwaâ€¦      0s   2%    clipfrac          0.047  â”‚
â”‚  Remainiâ€¦           40s      Learn       0s   5%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.148  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.554    episode_length               30.879  â”‚
â”‚  x_position                   -3.903    x_velocity                  -32.259  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 360,448: episode_return=-47.12 (best=-1.79@327680)
æ­¥æ•° 360,448: Reward=-47.12, Best=-1.55@360448, Sharpness=2.9858, Î»_max=10.8010
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0 ğŸ¡               CPU:     GPU: 4.8%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.7%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.004  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.597  â”‚
â”‚  Steps           393.2K      Copy        0s   1%    entropy          21.481  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl     0.003  â”‚
â”‚  Epoch               12    Train         1s  12%    approx_kl         0.003  â”‚
â”‚  Uptime          1m 50s      Forwaâ€¦      0s   2%    clipfrac          0.032  â”‚
â”‚  Remainiâ€¦           30s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.176  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.896    episode_length               30.859  â”‚
â”‚  x_position                   -3.882    x_velocity                  -31.581  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 393,216: episode_return=65.01 (best=-1.55@360448)
æ­¥æ•° 393,216: Reward=65.01, Best=-0.90@393216, Sharpness=2.7505, Î»_max=-11.7831
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0          ğŸ¡      CPU:     GPU: 4.4%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 14.0%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.009  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.611  â”‚
â”‚  Steps           426.0K      Copy        0s   1%    entropy          21.488  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               13    Train         1s  12%    approx_kl         0.002  â”‚
â”‚  Uptime           2m 0s      Forwaâ€¦      0s   2%    clipfrac          0.021  â”‚
â”‚  Remainiâ€¦           22s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.154  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.229    episode_length               32.730  â”‚
â”‚  x_position                   -4.346    x_velocity                  -33.774  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 425,984: episode_return=-11.96 (best=-0.90@393216)
æ­¥æ•° 425,984: Reward=-11.96, Best=-0.90@393216, Sharpness=2.9489, Î»_max=-6.7084
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0         ğŸ¡       CPU:     GPU: 4.7%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.002  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.582  â”‚
â”‚  Steps           458.8K      Copy        0s   1%    entropy          21.492  â”‚
â”‚  SPS               3.4K      Misc        0s   0%    old_approx_kl     0.002  â”‚
â”‚  Epoch               14    Train         1s  12%    approx_kl         0.002  â”‚
â”‚  Uptime          2m 10s      Forwaâ€¦      0s   2%    clipfrac          0.016  â”‚
â”‚  Remainiâ€¦           11s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.170  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -1.203    episode_length               33.168  â”‚
â”‚  x_position                   -4.446    x_velocity                  -34.183  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 458,752: episode_return=-17.55 (best=-0.90@393216)
æ­¥æ•° 458,752: Reward=-17.55, Best=-0.90@393216, Sharpness=2.5164, Î»_max=-12.3330
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0        ğŸ¡        CPU:     GPU: 4.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.6%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     10s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.022  â”‚
â”‚  Params          135.3K      Env         9s  80%    value_loss        0.687  â”‚
â”‚  Steps           491.5K      Copy        0s   1%    entropy          21.494  â”‚
â”‚  SPS               3.3K      Misc        0s   0%    old_approx_kl     0.000  â”‚
â”‚  Epoch               15    Train         1s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 20s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            2s      Learn       0s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.177  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.610    episode_length               33.820  â”‚
â”‚  x_position                   -4.561    x_velocity                  -34.239  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 491,520: episode_return=-18.85 (best=-0.90@393216)
æ­¥æ•° 491,520: Reward=-18.85, Best=-0.61@491520, Sharpness=2.9928, Î»_max=-14.7660
[0;0Hâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  PufferLib 3.0       ğŸ¡         CPU:     GPU: 3.0%  DRAM: 0.3%   VRAM: 1.7%  â”‚
â”‚                                 13.8%                                        â”‚
â”‚                                                                              â”‚
â”‚  Summary          Value    Evaluate     13s  87%    Losses            Value  â”‚
â”‚  Env        Walker2d-v4      Forwaâ€¦      0s   4%    policy_loss       0.010  â”‚
â”‚  Params          135.3K      Env        12s  80%    value_loss        0.667  â”‚
â”‚  Steps           524.3K      Copy        0s   1%    entropy          21.494  â”‚
â”‚  SPS               3.5K      Misc        0s   0%    old_approx_kl    -0.000  â”‚
â”‚  Epoch               16    Train         2s  12%    approx_kl         0.000  â”‚
â”‚  Uptime          2m 29s      Forwaâ€¦      0s   2%    clipfrac          0.000  â”‚
â”‚  Remainiâ€¦            0s      Learn       1s   6%    importance        1.000  â”‚
â”‚                              Copy        0s   0%    explained_varâ€¦    0.045  â”‚
â”‚                              Misc        0s   2%                             â”‚
â”‚                                                                              â”‚
â”‚  User Stats                    Value    User Stats                    Value  â”‚
â”‚  episode_return               -0.801    episode_length               33.783  â”‚
â”‚  x_position                   -4.541    x_velocity                  -34.394  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

[Train] step 524,288: episode_return=73.02 (best=-0.61@491520)
æ­¥æ•° 524,288: Reward=73.02, Best=-0.61@491520, Sharpness=2.6053, Î»_max=-13.6690

è®­ç»ƒå®Œæˆ: 524,288 æ­¥
ç¯å¢ƒå·²å…³é—­
[J&R] ä»»åŠ¡ 13_jr4_s135.00 å®Œæˆã€‚
[Jump & Retrain] Walker2d task 13 step sweep å®Œæˆã€‚
